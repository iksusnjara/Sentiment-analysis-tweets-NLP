{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the dataset\n",
    "\n",
    "This dataset contains tweets related to US airline companies. Contributors have labeled sentiment of those tweets as positive, negative or neutral. Also, they gave a confidence estimate of sentiment labels. Dataset also includes username of tweet authors and other Twitter related data. In this project, I will concentrate only on extracting sentiment from tweeted text. I will not use airline company or any other info besides tweets themselves.\n",
    "\n",
    "Dataset available at https://www.kaggle.com/crowdflower/twitter-airline-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Tweets.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is not that much data\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# no missing data for relevant fields: airline_sentiment, airline_sentiment_confidence and text\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14404, 15)\n",
      "(14402, 15)\n",
      "(13651, 15)\n",
      "(10760, 15)\n"
     ]
    }
   ],
   "source": [
    "# seeing how much data we keep if we set cutoff value for airline_sentiment_confidence\n",
    "# we want to keep only data where we can be sure labels are correct\n",
    "\n",
    "print(data[data['airline_sentiment_confidence']>0.5].shape)\n",
    "print(data[data['airline_sentiment_confidence']>0.6].shape)\n",
    "print(data[data['airline_sentiment_confidence']>0.65].shape)\n",
    "print(data[data['airline_sentiment_confidence']>0.7].shape)\n",
    "\n",
    "\n",
    "# perhaps, 0.65 is reasonable tradeoff between label confidence and loosing too much data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13651, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['airline_sentiment_confidence']>0.65]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>airline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>Virgin America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>Virgin America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>Virgin America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>Virgin America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>Virgin America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text  \\\n",
       "0           neutral                @VirginAmerica What @dhepburn said.   \n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3          negative  @VirginAmerica it's really aggressive to blast...   \n",
       "4          negative  @VirginAmerica and it's a really big bad thing...   \n",
       "5          negative  @VirginAmerica seriously would pay $30 a fligh...   \n",
       "\n",
       "          airline  \n",
       "0  Virgin America  \n",
       "2  Virgin America  \n",
       "3  Virgin America  \n",
       "4  Virgin America  \n",
       "5  Virgin America  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keeping only text, label and company name\n",
    "\n",
    "data = data[['airline_sentiment', 'text', 'airline']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    8787\n",
      "neutral     2700\n",
      "positive    2164\n",
      "Name: airline_sentiment, dtype: int64\n",
      "\n",
      "\n",
      " negative    0.643689\n",
      "neutral     0.197788\n",
      "positive    0.158523\n",
      "Name: airline_sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# labels value counts and prpoprtions\n",
    "\n",
    "print(data['airline_sentiment'].value_counts())\n",
    "print('\\n\\n', data['airline_sentiment'].value_counts()/len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United            3555\n",
       "US Airways        2763\n",
       "American          2615\n",
       "Southwest         2223\n",
       "Delta             2030\n",
       "Virgin America     465\n",
       "Name: airline, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# airline value counts\n",
    "\n",
    "data['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 454.875x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reviews per airline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (15,3))\n",
    "sns.catplot(x = 'airline', hue = 'airline_sentiment', data = data, kind = 'count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can se that airline companies differ by quality of their reviews. Also, all tweets contain company username - that's how they are labeled by company in the first place. So, if we kept these usernames as word features, they would influence our model in unwanted way: because US Airways for example has many more bad reviews than good or neutral, our model would learn to classify tweets containing US Airways username (@USAirways) as negative, regardless of their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8787\n",
       "1    2700\n",
       "2    2164\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels to numbers\n",
    "\n",
    "labels = data['airline_sentiment'].values.copy()\n",
    "\n",
    "labels[labels=='negative'] = 0\n",
    "labels[labels=='neutral'] = 1\n",
    "labels[labels=='positive'] = 2\n",
    "\n",
    "labels = labels.astype(np.int64)\n",
    "\n",
    "# sanity check\n",
    "\n",
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@AmericanAir called executive platinum desk and got a TWO HOUR call back time... 2.5 hrs Late Flightr still no call and still stuck in Chicago\n",
      "@JetBlue Can you take @Cosmopolitan off your blacklist... trying to work :(\n",
      "@SouthwestAir it's pretty stupid and I probably won't fly it again. Plus hearing nightmare stories of overbooked flights.\n",
      "@SouthwestAir alas, it was pretty full so we had to entertain ourselves with witty repartee ...\n",
      "@united please tell CLT flight 4232 needs a gate. Waiting now for 15 mins.\n",
      "@SouthwestAir App Updated With #Passbook Support http://t.co/WrWqrUblPs via @ubergizmo\n",
      "@JetBlue I do not want to deal with your customer service agents with no practical knowledge.Provide me with a direct contact.\n",
      "@USAirways From here on out when I can at all I'm flying @Delta. Since when is a plane getting stuck in a drift for 2 hours a weather issue?\n",
      "@AmericanAir 30 minutes flight from OKC and then make us wait, 30 minutes cause the gate isn't empty.  #epicfail #poorplanning\n",
      "@SouthwestAir I also find it ridiculous that I've been tweeting to you since 3:50 AM EST and have still received no response. 9 hours?\n",
      "@USAirways after sitting on the runway for 3 hours i had to leave the airport w/o my luggage. Is this ur 1st day??\n",
      "@SouthwestAir round-trip tickets just arrived for our auction at the Post-Masters Invitational! Thanks Southwest! http://t.co/mRfBjtePef\n",
      "Sir. RT @JetBlue: Our fleet's on fleek. http://t.co/F5IXyw8XyB\n",
      "@SouthwestAir got a text my flight was Cancelled Flightled! Now what do I do :/?? Help please!!!\n",
      "@AmericanAir What happens when you combine Top Chef &amp; the beauty of San Miguel de Allende. My Late Flightst food blog.  http://t.co/7t1rDRCRe6\n",
      "@SouthwestAir LACMA on Fairfax.\n",
      "@SouthwestAir LOST Kay Chapman Designs art-luggage for important show. Won't help locate it. Terrible customer service.\n",
      "@USAirways No, they won't because after 5 hours of holding I had to give up because I couldn't borrow the phone any longer. 5 hours...\n",
      "@united I would never fly United Airlines again!\n",
      "@united thanks for ruining my wedding anniversary. Flight UA4904 from EWR to RDU is delayed by over 3 hours and will reach home the nxt day\n"
     ]
    }
   ],
   "source": [
    "# printing 20 random tweets\n",
    "\n",
    "rand = np.random.randint(0,len(data), 20)\n",
    "for i in rand:\n",
    "    print(data.iloc[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only np array\n",
    "\n",
    "texts = data['text'].values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first keeping only alfanumeric and ascii chars - to drop all smileys etc\n",
    "# dropping all of the special chars except # for hashtag - hashtags could have some meaningful info\n",
    "# dropping links\n",
    "# lowercasing everything\n",
    "\n",
    "\n",
    "# first, replacing all multiple whitespaces with single whitespace\n",
    "# also, removing all \" and ''\n",
    "\n",
    "import re\n",
    "\n",
    "whitespace_cleaner = re.compile(r'\\s+')\n",
    "quot1_cleaner = re.compile(\"\"\"'\"\"\")\n",
    "quot2_cleaner = re.compile('''\"''')\n",
    "for i in range(len(texts)):\n",
    "    texts[i] = whitespace_cleaner.sub(' ', texts[i]).strip()\n",
    "    texts[i] = quot1_cleaner.sub('', texts[i])\n",
    "    texts[i] = quot1_cleaner.sub('', texts[i])\n",
    "    \n",
    "\n",
    "texts_prep = []\n",
    "filters =['!','''\"''', '$', '%' ,'&', '(', ')', '*', '.', ',', '+', '-', '/',':',';','<','=','>',\n",
    "          '?','[',']','^','_','`','{','|','}','~','\\t','\\n', '@']\n",
    "\n",
    "for text in texts:\n",
    "    as_list = text.split(' ')\n",
    "    to_add = []\n",
    "    for item in as_list:\n",
    "        proc = []\n",
    "        if item.isalnum() or item.isascii():\n",
    "            if item.startswith('http') == False and item.startswith('@') == False:\n",
    "                x = list(item)\n",
    "                for i in x:\n",
    "                    if i not in filters:\n",
    "                        proc.append(i)\n",
    "                if '' in proc:\n",
    "                    proc.remove('')\n",
    "                to_add.append(''.join(proc).lower())\n",
    "                \n",
    "    texts_prep.append(' '.join(to_add).strip())\n",
    "                \n",
    "texts_prep = np.array(texts_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13651,), (13651,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape, texts_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:    @USAirways what is policy on changing flight to different dates once your flight has been delayed? \n",
      " PROCESSED:    what is policy on changing flight to different dates once your flight has been delayed \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united already did that at the airport and 12 hrs Late Flightr its still not here! you guys are really killing me today. trying to stay positive.. \n",
      " PROCESSED:    already did that at the airport and 12 hrs late flightr its still not here you guys are really killing me today trying to stay positive \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @USAirways when will FLT 445 get a gate at DEN? Over 20 minutes waiting with no information. \n",
      " PROCESSED:    when will flt 445 get a gate at den over 20 minutes waiting with no information \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @AmericanAir wow thats helpful. \n",
      " PROCESSED:    wow thats helpful \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united more people stranded cause you suck. Better yet, you weasel out of Flight Booking Problems rooms for people claiming weather http://t.co/Flcnnn2USD \n",
      " PROCESSED:    more people stranded cause you suck better yet you weasel out of flight booking problems rooms for people claiming weather \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united Actually, the flight was just Cancelled Flightled! http://t.co/Qf0Oc2HqeZ \n",
      " PROCESSED:    actually the flight was just cancelled flightled \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @United THANK U! Secured room for the night Thx to VERY helpful customer service rep N. Dorns.. I thanked her.. Can u 2? #goodenoughmother \n",
      " PROCESSED:    thank u secured room for the night thx to very helpful customer service rep n dorns i thanked her can u 2 #goodenoughmother \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @virginamerica.. Can you help? Left my blazer in. Kooples jacket bag at 3rd row second seat from right gate 36 T3 lax.. Flight to sfo \n",
      " PROCESSED:    can you help left my blazer in kooples jacket bag at 3rd row second seat from right gate 36 t3 lax flight to sfo \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @AmericanAir flights been Cancelled Flightled, cant get through to the desk and nothing showing online under my reservation - what do I do? \n",
      " PROCESSED:    flights been cancelled flightled cant get through to the desk and nothing showing online under my reservation  what do i do \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @JetBlue you #fail. Snow coming to DC area. Tried to get on earlier flight. You refused. Now flight 6.5 hours delayed. Greedy and foolish. \n",
      " PROCESSED:    you #fail snow coming to dc area tried to get on earlier flight you refused now flight 65 hours delayed greedy and foolish \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @United come on, reopen 1285 at ORD and clear your growing DC backlog \n",
      " PROCESSED:    come on reopen 1285 at ord and clear your growing dc backlog \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @JetBlue why dont YOU tell them to update the boards?! \n",
      " PROCESSED:    why dont you tell them to update the boards \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united can you send me another confirmation email? \n",
      " PROCESSED:    can you send me another confirmation email \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    Hey @AmericanAir why automated call me and then hang up at 4:45 am!?! And why cant I reschedule Cancelled Flighted flights via web!?! Come on!!! \n",
      " PROCESSED:    hey why automated call me and then hang up at 445 am and why cant i reschedule cancelled flighted flights via web come on \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @JetBlue Flights 1384 and 1583. I have picked up twice this week for 1583, and both times it was delayed!! ðŸ˜• \n",
      " PROCESSED:    flights 1384 and 1583 i have picked up twice this week for 1583 and both times it was delayed \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @JetBlue we now have to get off of the plane and wait another 1-2 hours for someone at the @BuffaloAirport to read the temp. #tired \n",
      " PROCESSED:    we now have to get off of the plane and wait another 12 hours for someone at the to read the temp #tired \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united been good 15yr \"friendly skies\" relationship. 2day agent told me Im \"only Canadian\" and thus not good enough for military preboard \n",
      " PROCESSED:    been good 15yr friendly skies relationship 2day agent told me im only canadian and thus not good enough for military preboard \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @SouthwestAir Beautiful, thanks a ton! \n",
      " PROCESSED:    beautiful thanks a ton \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @USAirways thank you! Its # 1875 from BWI, keep seeing different stats, from delayed to awaiting take off to delayed... \n",
      " PROCESSED:    thank you its # 1875 from bwi keep seeing different stats from delayed to awaiting take off to delayed \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @JetBlue thanks for your prompt response. I know you put safety first. Unfortunately will hit freezing rain/sleet on ride home. \n",
      " PROCESSED:    thanks for your prompt response i know you put safety first unfortunately will hit freezing rainsleet on ride home \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing  20 random tweets  before and after cleaning\n",
    "\n",
    "rand = np.random.randint(0,len(texts), 20)\n",
    "\n",
    "for i in rand:\n",
    "    print('ORIGINAL:   ', texts[i], '\\n', 'PROCESSED:   ', texts_prep[i], '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Next step is lemmatization of text. Lemmatization keeps lemma, or root of the word, but also ensuring that root belongs to the language (unlike stemming, where root does not have to be a real word in language). This way, various forms of same word (for example verbs playing, played) will be reduced to same lemma - play. This will reduce number of tokens used in model by combining words with same meaning (for example when play is verb) into single token.\n",
    "\n",
    "Lemmatization requires POS (part of speech tagging) of words, in order to be able to reduce words to appropriate lemma. POS identifies words as nouns, verbs, adjectives etc. NLTK also contains POS tagging algorithm.\n",
    "\n",
    "However, NLTK's WordNetLemmatized can't use all of the pos tags, it has only options for nouns, verbs, adjectives and adverbs. Also, these are words that come in many forms, while most other words are more or less unmutable. So, I will apply lemmatization to these kinds of words, and not to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging all words in tweets, and keeping tags only for nouns, verbs, adjectives and adverbs\n",
    "\n",
    "texts_tagged = []\n",
    "\n",
    "for text in texts_prep:\n",
    "    \n",
    "    tagged_final = []\n",
    "    \n",
    "    as_list = text.split(' ')\n",
    "    as_list = np.array(as_list)\n",
    "    # some '' are stil left in list, cleaning them with numpy where\n",
    "    where = np.where(as_list == '')\n",
    "    as_list = np.delete(as_list, where)\n",
    "    \n",
    "    tagged = nltk.pos_tag(as_list)\n",
    "    \n",
    "    for item in tagged:\n",
    "        if item[1].startswith('N'):\n",
    "            tagged_final.append((item[0],'n'))\n",
    "        elif item[1].startswith('V'):\n",
    "            tagged_final.append((item[0],'v'))\n",
    "        elif item[1].startswith('J'):\n",
    "            tagged_final.append((item[0],'a'))\n",
    "        elif item[1].startswith('R'):\n",
    "            tagged_final.append((item[0],'r'))\n",
    "        else:\n",
    "            tagged_final.append((item[0], None))\n",
    "    \n",
    "    texts_tagged.append(tagged_final)\n",
    "\n",
    "texts_tagged = np.array(texts_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13651,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tagged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'n'),\n",
       " ('didnt', 'v'),\n",
       " ('today', 'n'),\n",
       " ('must', None),\n",
       " ('mean', 'v'),\n",
       " ('i', 'n'),\n",
       " ('need', 'v'),\n",
       " ('to', None),\n",
       " ('take', 'v'),\n",
       " ('another', None),\n",
       " ('trip', 'n')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tagged[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, lemmatizing words\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "texts_lemmed = []\n",
    "\n",
    "for text in texts_tagged:\n",
    "    \n",
    "    to_add = []\n",
    "    \n",
    "    for i,j in text:\n",
    "        if j == None:\n",
    "            to_add.append(i)\n",
    "        else:\n",
    "            to_add.append(lem.lemmatize(i, pos = j))\n",
    "    \n",
    "    texts_lemmed.append(' '.join(to_add))\n",
    "    \n",
    "texts_lemmed = np.array(texts_lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL:    @USAirways whats going on with US Airways flight 805? Why diverted to Charlotte? \n",
      " PROCESSED:    whats go on with us airway flight 805 why divert to charlotte \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united hoping to get out earlier than 2/23 (only phone option) or assistance with hotel. \n",
      " PROCESSED:    hop to get out early than 223 only phone option or assistance with hotel \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @SouthwestAir #DestinationDragons Any word on winners of contest? Any chance for tix for the Provo DestinationDragons show? Fingers Crossed! \n",
      " PROCESSED:    #destinationdragons any word on winner of contest any chance for tix for the provo destinationdragons show finger cross \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united you cant say the flight is pulled in and departs in 2 mins if boarding hasnt even started! http://t.co/2IKbP8gxWi \n",
      " PROCESSED:    you cant say the flight be pull in and departs in 2 min if boarding hasnt even start \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @usairways Ive been on hold for approaching 2 hrs for an issue when I changed my ticket online. Frustrating. \n",
      " PROCESSED:    ive be on hold for approach 2 hr for an issue when i change my ticket online frustrating \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @AmericanAir I know. Just a little cold weather humor. :) \n",
      " PROCESSED:    i know just a little cold weather humor \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @AmericanAir hey ho its not me losing any money (only you) just next make sure you stick to the \"flyers rights booklet\" \n",
      " PROCESSED:    hey ho its not me lose any money only you just next make sure you stick to the flyer right booklet \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @SouthwestAir DM sent! Thanks so much for responding! Your response was so timely, I missed it! \n",
      " PROCESSED:    dm send thanks so much for respond your response be so timely i miss it \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @SouthwestAir you should know the crew today on flight #1071 AUS to PDX was awesome! #SWA \n",
      " PROCESSED:    you should know the crew today on flight #1071 au to pdx be awesome #swa \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @AmericanAir I picked the nonstop flight bc I had things to get to. Shouldâ€™ve taken diff route or airline I suppose! \n",
      " PROCESSED:    i pick the nonstop flight bc i have thing to get to take diff route or airline i suppose \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @USAirways followed! \n",
      " PROCESSED:    follow \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @USAirways 502 M-phx Im still on The plane waiting And waiting \n",
      " PROCESSED:    502 mphx im still on the plane wait and wait \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united flight #1 no luck on #standby \n",
      " PROCESSED:    flight #1 no luck on #standby \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    Oh yeah? RT @JetBlue: Our fleets on fleek. http://t.co/FTv2NWWQF1â€ \n",
      " PROCESSED:    oh yeah rt our fleet on fleek \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united Id really like to get off of this plane now. \n",
      " PROCESSED:    id really like to get off of this plane now \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @united Couldnt use the confirmed upgd cert you gave me b/c you decided to sell anyone a biz seat for $299. Why do you bother giving them? \n",
      " PROCESSED:    couldnt use the confirmed upgd cert you give me bc you decide to sell anyone a biz seat for 299 why do you bother give them \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    .@JetBlue Delete this tweet. \n",
      " PROCESSED:    jetblue delete this tweet \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @AmericanAir is that the \"record locator\"? \n",
      " PROCESSED:    be that the record locator \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @SouthwestAir Thanks for taking care of me Today! Michele rocked the customer service! Gate 25 HOU \n",
      " PROCESSED:    thanks for take care of me today michele rock the customer service gate 25 hou \n",
      "\n",
      "\n",
      "\n",
      "ORIGINAL:    @USAirways hire smarter IT people if your systems keep crashing instead of some of the mooks you man some of these airports with. #goDelta \n",
      " PROCESSED:    hire smarter it people if your system keep crash instead of some of the mooks you man some of these airport with #godelta \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing  20 random original and finally preprocessed\n",
    "\n",
    "rand = np.random.randint(0,len(texts), 20)\n",
    "\n",
    "for i in rand:\n",
    "    print('ORIGINAL:   ', texts[i], '\\n', 'PROCESSED:   ', texts_lemmed[i], '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing frequency of individidual words, to determine how many of them to keep as tokens\n",
    "\n",
    "# first, we have to add all words to single list, to count their occurences\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for i in texts_lemmed:\n",
    "    x = i.split(' ')\n",
    "    for j in x:\n",
    "        all_words.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 223800 words total\n",
    "\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12954,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have 12954 unique words\n",
    "\n",
    "np.unique(all_words).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcdff017990>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 most common words\n",
    "\n",
    "freq_dist.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only words which show up 10 or more times in tweets as tokens, discarding rest\n",
    "\n",
    "tokens = {k:v for k,v in freq_dist.items() if v >= 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so, we end up with 1599 words as tokens\n",
    "\n",
    "len(tokens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, converting each of words to be kept to its index - integer replacing its string\n",
    "\n",
    "# bit of cheating - using keras tokenizer. keras is much more user friendly library than torch :) \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# using 1599 most frequent words (tokens start from 1), and no filters since text is already filtered\n",
    "tok = Tokenizer(num_words = 1600, filters = '')\n",
    "\n",
    "tok.fit_on_texts(texts_lemmed)\n",
    "\n",
    "texts_tokenized = tok.texts_to_sequences(texts_lemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some tweets are reduced to 0 words after tokenizing (dropping out al non token words)\n",
    "# some others have just 1 word\n",
    "# removing those from both inputs and labels\n",
    "# i.e. tweets need to have at least 2 kept words to be used in model\n",
    "\n",
    "text_lens = []\n",
    "\n",
    "for i in texts_tokenized:\n",
    "    text_lens.append(len(i))\n",
    "    \n",
    "text_lens = np.array(text_lens)\n",
    "filter_short = np.where(text_lens>1)\n",
    "\n",
    "texts_tokenized_filtered = np.array(texts_tokenized)[filter_short]\n",
    "labels_filtered = labels[filter_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13447,), (13447,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized_filtered.shape, labels_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making each tweet torch tensor, for padding\n",
    "\n",
    "texts_tokenized_torch = []\n",
    "\n",
    "for i in texts_tokenized_filtered:\n",
    "    texts_tokenized_torch.append(torch.tensor(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([58, 82]),\n",
       " tensor([  4, 189,  99, 752, 328,   4,  57,   1,  81, 147, 170]),\n",
       " tensor([  65,  131,    1,  906,   13,   18, 1040,   61,   52,   12,  461]),\n",
       " tensor([ 10,  65,   6, 131, 374,  90, 262,  80,  17]),\n",
       " tensor([411,  77, 139, 269,   6,   5,   8,  83,  24, 189,  12,  25, 980,  65,\n",
       "         131,   3, 117,  90, 262,  80,  47]),\n",
       " tensor([ 166, 1274,  287,   35,    4,   47,   25,   44,  450]),\n",
       " tensor([ 148,    4,   30,    4,   19, 1210]),\n",
       " tensor([ 17,   2, 468,  10, 243,  33,  28, 227, 203, 172, 100,   1,  16]),\n",
       " tensor([  19,    7,   96,   24,    2,    3,  501,  412,   14, 1275, 1503]),\n",
       " tensor([   4, 1158,  595,   41,  173,  100,  155, 1210]),\n",
       " tensor([  25,    2,  508,    6,  114,  329,  202,  180,   80,   11,  555,  170,\n",
       "            1,   61,    4,  334,  130,   44,    9,   11,  330,  170,  237, 1159]),\n",
       " tensor([378,   2,  69, 876]),\n",
       " tensor([  41,    8,   11,  156,  687,  715,    5,  288,    1,  716,  115,  907,\n",
       "          228,   26,  114,  262,   80,  847, 1041]),\n",
       " tensor([   4,   47,   27,  476,    1,  367,  128,  197,   10,  317,  127,   13,\n",
       "           11,   83,  158,    1,  176, 1119,    9,  596, 1409,   14,   16,   39]),\n",
       " tensor([ 4, 47]),\n",
       " tensor([  7,  96,  58,  77,   2, 276,  74,   4, 119,   1,  47,  21, 117,   7]),\n",
       " tensor([  66,    2,   18,  156,  550,   13,  457,  101,  436,   35,  103,  155,\n",
       "          186, 1012,   60,   64,   83,    2,  299,    1,  832]),\n",
       " tensor([  4, 159,  25]),\n",
       " tensor([   4,  159,    3,    7,    2,    6,  397,  100, 1211]),\n",
       " tensor([ 45,   7,   2,  55, 788, 313, 462]),\n",
       " tensor([   7,   98,  589,   49,   11, 1504,    4, 1120,   83,   21,   11,  343,\n",
       "           10,    7,   98,  109,   11,   83,  450,    4,  119,  273, 1121]),\n",
       " tensor([308, 981, 809,   4, 810,  10,  65,   2, 436, 197,  42,  10, 141,  21,\n",
       "          22, 185]),\n",
       " tensor([  58,  225,   59,  405,  425,  278,   23,  356,   82,    9,  405,  352,\n",
       "           41,    4,   96,    4,  204,    2,  281,   59, 1042,  249,    8,  171,\n",
       "          300,  136,  443]),\n",
       " tensor([ 19,   7, 107,  16,  84, 590, 148,   2, 463, 151, 462]),\n",
       " tensor([468,   1,  16,  24,  31,  68,  15,  94, 753, 248,  27,   3]),\n",
       " tensor([365,   4,  37,   6, 489, 789, 170,  21,   7,  26,   4,  68, 282,  11,\n",
       "          22, 412,   4, 877,  11, 772, 301, 490,   5, 608, 126]),\n",
       " tensor([   2,    3,   28,   14, 1276,    8,    3,  571,   23,  367,   24,    2,\n",
       "          634,  194,  982]),\n",
       " tensor([  39,  110, 1043,    9,    5,  518,    1,  288,   99,   83,   22,   71,\n",
       "          195,  160,   23,  288]),\n",
       " tensor([  11,  331,   89,   42,   37,   77, 1343,    1,  149,   18,  194,  278]),\n",
       " tensor([  25,    2,  114,  811, 1041,  168,  261,    5,    1, 1277,  102,  437,\n",
       "           14,  244,  309]),\n",
       " tensor([  2,   3, 117, 112,   1,  47, 196, 163, 154, 489,  10]),\n",
       " tensor([ 19,  10,  19, 196,  75, 470, 728, 252]),\n",
       " tensor([  60,   29,    4,   93,   11,    5,    1, 1277]),\n",
       " tensor([  18, 1410,  635,    2,   20,  104,    9,   18,  352]),\n",
       " tensor([908,  14,   3, 636,  10, 609,  24,  13,   3]),\n",
       " tensor([ 438,  156,   35,  572,  171,  197, 1278,   26,   51,   12,    6,  491,\n",
       "           35,   15,   11,    5,  282,    1,   11,  406,   39]),\n",
       " tensor([833,  39,  16, 637,  11, 263,   8,  11,   5]),\n",
       " tensor([  4,  12,  33, 108,  26, 347,   1,   6, 152, 496, 212,   7,  84,  47,\n",
       "          62,  29,   4,  47,  21,   7, 188,  17, 729]),\n",
       " tensor([  2,   5, 110, 407,   8, 983,   9,  35, 773, 458]),\n",
       " tensor([ 51,   8,   6, 100, 370,   7, 626]),\n",
       " tensor([ 616,   25,   37, 1412,   11,  878]),\n",
       " tensor([ 87, 128, 230,   4, 180]),\n",
       " tensor([  2,   5,   9,  65, 112,   2, 310,   1,  81, 137, 269, 113, 272, 216,\n",
       "          69, 240,   9,  35,  20,  13,   5,  34]),\n",
       " tensor([ 64,   3, 112, 357,   2, 151,  22,   1]),\n",
       " tensor([617,   7,  47,  53,  14, 790, 462]),\n",
       " tensor([728, 252]),\n",
       " tensor([  45,    5,    2,  110,  407,    8,  471,    9, 1413]),\n",
       " tensor([365,  51,  41,  80,  18, 329,  26, 115,   2,  70,  59,  93, 205, 128,\n",
       "         197,  61,   3, 812, 120, 519, 340]),\n",
       " tensor([ 7, 96, 17, 57, 17,  9, 11]),\n",
       " tensor([ 152, 1279,  153,   56,   96,   58,    7,  180]),\n",
       " tensor([156,  26, 879,  16, 128, 230]),\n",
       " tensor([   4,   42,    6, 1505,  197,  272,   80,  282,  123,    5,   27,    1,\n",
       "           11,   69,  334,  240]),\n",
       " tensor([ 64,   2, 114,  26,   4,  12,   1,  44,  21]),\n",
       " tensor([319,  12,  17, 156]),\n",
       " tensor([ 159,   64,  436,   26,    7,  131,   68, 1212,    3]),\n",
       " tensor([   5, 1344,    1,  344, 1506,   70,    1,  105,   13,  168,   20,  308,\n",
       "           74]),\n",
       " tensor([  2,  70,   1,  15, 187,   8,  33,  28,  29, 169,  42,  16,  74]),\n",
       " tensor([365, 847,  51,   9,  48,   8, 113,   2,  72,  94, 227,   5,  27, 471,\n",
       "           1, 476, 231, 227, 155]),\n",
       " tensor([1122,    9,  637,    3,  551,    8,  196,  329,   27,   33,   75,   56]),\n",
       " tensor([552,   2, 591, 279,   7, 125,  11,  46]),\n",
       " tensor([  57,    1,   91,  174,   12,  847,  259,  371,   19,    4,   57,    1,\n",
       "            9,   89,    1, 1160,   91,  283,   85,   29,    4,   19,  194]),\n",
       " tensor([365,   4,  37,  93,   6,   5,  26,  57,   1, 282, 165,  62,  29,   4,\n",
       "          19,  25]),\n",
       " tensor([  18,   75,    2,  276,   26,   18,  288,   57,    1,  813,   49,   65,\n",
       "         1123,  464,    8, 1414,   10, 1213]),\n",
       " tensor([ 20, 590,  65,   2,   6, 114, 909,  13,   6, 152,  50,  21, 114, 164,\n",
       "          64,  75, 122,   2,  95,  25]),\n",
       " tensor([276,   4,  47, 419, 932, 229,  94, 112,  31,  29, 638,  11]),\n",
       " tensor([  85,  527,  198,   14,    3,  196, 1345,   13,    3,  715,   23, 1124]),\n",
       " tensor([156,  35,  47,   7,  64,  19,   7,  12,   6, 368,   8, 754,  46,  34]),\n",
       " tensor([ 58,   2,  44,   9,  21,  36,  32,   2,  72, 848,   1, 238,   1,   6,\n",
       "         513, 667,  63,   7]),\n",
       " tensor([ 58, 225,   1]),\n",
       " tensor([  66,   68,    7,    3, 1415,  618,   95,   10,   12,   36,   32,   95]),\n",
       " tensor([115, 810, 103, 116, 444,   1,   2,   6, 366,  14,   3, 164, 556]),\n",
       " tensor([ 203,    3,  196, 1507,    4,  149,   94,  186,   75,   51,   40,   10,\n",
       "           92,    5]),\n",
       " tensor([  4,  12,  22,  47,  21,   7,  87,  25,   4,  45,  38,   5,  11, 171,\n",
       "         774,   5,   4]),\n",
       " tensor([  17,    2,    6, 1161,  163,  303,   45,    2,  528,   21,  287,  292,\n",
       "          618,    4,  849]),\n",
       " tensor([ 12, 668, 282,  25,   5,  11, 384,  93,   1,  11, 406,  39]),\n",
       " tensor([ 68, 429,  49,  11, 174, 194, 149,   5,  93, 126, 910]),\n",
       " tensor([ 235,    3,   14,    4, 1280,   24,   12,    6,  528]),\n",
       " tensor([   4, 1158,   47,   26,  509,   10,    4,    2,   70,    1,   11,  170,\n",
       "           29,    7,  140,  812,   45,   20,  153,   16]),\n",
       " tensor([ 66,   2,   3, 352, 252,  60,  45,  17,   2,  78,  49]),\n",
       " tensor([  7, 252,  21, 627,   7,  96,  16]),\n",
       " tensor([ 365,    4,   19,   20,   15,  264,    9,   11,  406,    8,   11,  408,\n",
       "         1346,    5,   62,   19,    4,  282,    3,    5,   10,  264,    1,   11,\n",
       "          406]),\n",
       " tensor([  4,  95,   3, 597,  10, 911,  37, 647,  13, 274,  79,   5,  60, 186,\n",
       "           5,  44,  53,   1, 223,   9, 814]),\n",
       " tensor([ 37, 226,  13, 288,  33,  28,  87,   4, 122,  14,   2, 144,  18,  22,\n",
       "          92,   5,  46, 105,   2,  20, 292, 134, 730]),\n",
       " tensor([66,  2,  5]),\n",
       " tensor([  2,  17,  16,  85,   2,  18, 216, 252, 984,  18, 152, 216, 320,   6,\n",
       "         114, 163,  35,   8, 147]),\n",
       " tensor([  4,  68, 105,  13,  85, 282,   6,  46,  18, 216, 320, 104, 115,  70,\n",
       "         451,  10, 834]),\n",
       " tensor([ 153,   59,   13,  175,  110,    3,   50,  155,   88,  169,    1, 1508,\n",
       "          184,   46,   27,  330,  275, 1079]),\n",
       " tensor([ 58,   2,  18,  89, 160,   4,  68, 161, 177,   1,  42,  80,   6,   5,\n",
       "         174]),\n",
       " tensor([  2, 290,  19, 249,  72,  99, 216,   2, 985,  10,  22,  71,   2, 195,\n",
       "           3,  89]),\n",
       " tensor([  70,    1,  282,   11,    1,   11, 1509,   25, 1214,   27,  288]),\n",
       " tensor([ 66, 752,   6, 618, 107,   6,   5,   1,  92,   5, 105,   6,  46,   4,\n",
       "         107,  11, 229,  10,   7, 125,  11, 292]),\n",
       " tensor([ 105,   53,  152, 1162]),\n",
       " tensor([   6,  341,    5,   12,  658,   13,  557,  133, 1215,  237,  171,    1,\n",
       "           16,  335,    8,  557,    5]),\n",
       " tensor([ 18,  22,  92,   5,  46, 105,  37, 125,   7,  11, 292,   4, 107,   5,\n",
       "          10,   2, 436, 186, 135,   9,   5,  12, 215]),\n",
       " tensor([ 468,   36,   32,  106,   13, 1509,  698,    3,  196,  669]),\n",
       " tensor([ 42,  18,  32, 179,  10,   2, 232,  49,   9,  25,   2, 276]),\n",
       " tensor([ 18, 352,   2, 170,  51,  70,   1, 105,  13,  10,  51,  15,   3, 933,\n",
       "           4,   2,   1, 877,  94, 371, 239]),\n",
       " tensor([   4,    2,  378,    8,  367,   59, 1344,    5,   99,   91,    1,  158,\n",
       "          129,  145,   95,    5,   69,    9]),\n",
       " tensor([ 12, 329, 187, 457,  27, 337,  14, 489, 496]),\n",
       " tensor([ 12, 329, 187, 457,  27, 337,  14, 489, 496]),\n",
       " tensor([ 12, 329, 187, 457,  27, 337,  14, 489, 496]),\n",
       " tensor([ 12, 329, 187, 457,  27, 337,  14, 489, 496]),\n",
       " tensor([ 12,   6, 114, 197]),\n",
       " tensor([122,   4,   2, 659,  24,   4,   2,  80,   1,  47,   9,   6,  50,  24,\n",
       "          57,   1,   2,  40, 158,   1,   6, 313]),\n",
       " tensor([  2,   3, 196,  75,   4,  12,  47,   1,  91,  18, 934,  61,   6,  47,\n",
       "         163]),\n",
       " tensor([  10,  106,  147,  267, 1216,   18,  314,   41,   63,    7]),\n",
       " tensor([  18, 1281, 1282,    2,  252,  181,   30,   26,   17,    2,  489,    1,\n",
       "           69,   93,   11,  108,  321,   64,   18,    2]),\n",
       " tensor([159,   3, 314, 358,  76,  23, 471, 231,  43,   8,   6, 338,   5,  10,\n",
       "          52, 183, 262]),\n",
       " tensor([ 149,  147,  731,   61,    6, 1211,   21,    6,    9,  185,  206,   12,\n",
       "            6,  216]),\n",
       " tensor([ 10,  30,   3,   5,   5,  93, 126, 352,   2, 775, 252, 815,  58,   2,\n",
       "           3, 126]),\n",
       " tensor([  4,  95,   3,  36,  32,  26,   6, 464, 124,  40,  37,   8, 295, 175,\n",
       "         322, 172, 190]),\n",
       " tensor([ 34,   1,  18, 164, 177, 347,   1,  15,  16, 140,   1, 426, 231]),\n",
       " tensor([  7,  12,   3, 935, 196, 314,  10,  36,  32, 154, 287,  35,   4,  47,\n",
       "          21,   7,  51,  63,   7]),\n",
       " tensor([ 19,   7, 385, 263,   1, 156, 275,  67,  72,   2, 299,  83]),\n",
       " tensor([  4,  57,   1,  91,  11,   5, 167, 378,  13, 639,  28,  10, 124,  43,\n",
       "          35,   9,  89,  51,  42,  39]),\n",
       " tensor([670, 276, 163, 128, 393, 835,  34,   8, 508,  33, 276,   5,  10, 482,\n",
       "          35]),\n",
       " tensor([ 62,  29,   4, 527,   3,   9,  11,   5]),\n",
       " tensor([ 2,  5, 38, 79, 10, 58, 19,  4, 19, 67, 17,  2]),\n",
       " tensor([   7,    2,  452,   18,   36,  121,   18,  105,   13,  510,   19,   20,\n",
       "          430,    1,  688, 1347]),\n",
       " tensor([ 56, 172, 315,  75,  37, 109,  56,   6, 233, 160,  10,  82, 319]),\n",
       " tensor([ 12,   5, 160,  27, 367,   1, 426, 243, 237]),\n",
       " tensor([  18,  553,  304,   60,  118,   38,   79,   54,    5,    2,    1,  109,\n",
       "           56,    6,  233, 1283,    9,    7]),\n",
       " tensor([147, 338,   5]),\n",
       " tensor([   4,   57,    1,    6,   32, 1348,    8,    6,  156,  275,  108,   27,\n",
       "          367,  755,    3,   89, 1217,    2,   33,   28,   85,  190,  472,  986]),\n",
       " tensor([  7, 626,   8,  55,  17,  41,   4,  29, 527,   9,  11,   5]),\n",
       " tensor([477,   6, 936,   9,   7]),\n",
       " tensor([  66,   68,   31,   93,   83,    9,   18,    5,   60,   31,  335,  157,\n",
       "           85,  130,  490,  105,   13,   41,  173, 1044]),\n",
       " tensor([1125,  180,  139,   33,  325,  556,  420,    8,  146,  424, 1284,    7,\n",
       "          836,   33,  325,  728,   23]),\n",
       " tensor([196,  36,  32, 267,  13,   3, 558,  81,   3]),\n",
       " tensor([  74,  385,  308,    8,    5,    4,   68, 1045,   65,    9,   35,   86,\n",
       "            3,  912,    1,  129,  144,  407]),\n",
       " tensor([  7,  12, 699, 193,  61, 660, 316,  86,   4,  37, 358,   3,  52,  12,\n",
       "          16,  21]),\n",
       " tensor([   4,  139,    3, 1126,    1,   47,    7, 1127,    3,  715,    7,   38,\n",
       "            5,   11,    5,   10,  245,   22,  105,  283,   85,  263,  159,  689,\n",
       "         1040]),\n",
       " tensor([ 375,    2,   17,   20,  473,    1,   93,    6,   83,    8,   33, 1080,\n",
       "          648,   59,   65,   20,  109,   16,    3,  278,   26,   31,  119,    6,\n",
       "           83,    8,  483]),\n",
       " tensor([ 296,   12,   17,  463,  203, 1046,  420,  203,   41, 1046]),\n",
       " tensor([140,   1,  13,  78,   1]),\n",
       " tensor([  4,  84, 297,  66,   7,  57,   6, 162,   1, 109,  16,  33, 195,   9,\n",
       "          67,   7,  12,   6, 880, 146, 342]),\n",
       " tensor([ 19,  24, 328,   7,  84,  12,   6, 342,   8, 146]),\n",
       " tensor([   2,   72,  937,  553,   67,    4,  134, 1081,  339,   10,  207, 1080,\n",
       "          690,  445]),\n",
       " tensor([ 63,   7,   8, 105,  13, 108,   2, 520,  10,  36,   2, 348]),\n",
       " tensor([  2,  18, 216, 154, 178,  78, 194]),\n",
       " tensor([   2,    5,   27,  159,    1,  367,  958,   38,   79,    8,  535, 1413,\n",
       "         1047]),\n",
       " tensor([  2,   5,  53,  14, 573,   1, 265,   9,  35]),\n",
       " tensor([ 11,   2, 729, 102,   6, 461, 101,   6, 393,  29,   4,  47, 776, 229,\n",
       "         149,  11]),\n",
       " tensor([ 12, 126,   5,  93, 126,   9,   3, 912, 352, 183, 109,  16,  33, 492,\n",
       "          10,   1, 284, 102,  89,  89,   2, 269, 113,  43]),\n",
       " tensor([ 62,  19,   4, 439,  11,  38,  79,   5, 194,   3,  91,   2,  53]),\n",
       " tensor([  4,  26,  72,   2,   6,  43,   8, 756, 113,   4,  29,  93,   3, 215,\n",
       "         108, 187,   6, 256,  18, 352]),\n",
       " tensor([ 15,   6,   5,  31,   2,  88,   8,  11, 141,  10,  65,   8, 142,  25,\n",
       "           2, 386]),\n",
       " tensor([  54,    5,  217,  573,    2,   38,    5,    2,  218,   13,  407,    4,\n",
       "           42,    1,  439, 1349,    4,  168,   15,    6,    5,    8]),\n",
       " tensor([  66,   84,   94,   14,    3,  816, 1350,  117,    2,  245]),\n",
       " tensor([  2,   3, 216, 252]),\n",
       " tensor([ 18, 352, 322,   6, 461, 181,  30, 457, 119,   1,  12,   6, 145,  70,\n",
       "           9, 176,  22]),\n",
       " tensor([  51,  647,   24,    3,   97,   23,    3, 1218,  308,  105,   13,  179,\n",
       "          529,    1,  837,   64]),\n",
       " tensor([336,   1, 816, 732,   1,  65, 407, 554]),\n",
       " tensor([   2,   17, 1351,    1,  280,   22,  376,   27,  165]),\n",
       " tensor([  23, 1285,  111,   10,   43,    1,  502,    8,   11,    5,  502,  398,\n",
       "           20,  293,   66]),\n",
       " tensor([   1, 1286,  217,    3]),\n",
       " tensor([1212,  908,   81,    9,  817,  292, 1163]),\n",
       " tensor([  1,  11, 240,  11,   9, 535]),\n",
       " tensor([   1, 1013,   13, 1219]),\n",
       " tensor([1122,    7,   37,   15,   64,   11,  292,   27,  440,    1,  640,    7,\n",
       "            2,    3]),\n",
       " tensor([  4, 810, 101,  59, 197, 272, 334, 323,  78,  10,  51,  47,  25, 197,\n",
       "         850]),\n",
       " tensor([302, 159,   1,  96,  58,  18, 342,   2,   8, 880, 146]),\n",
       " tensor([ 63,   7,   8,   3, 199]),\n",
       " tensor([172, 298, 465,   7, 700,   3,  90,  75,  84, 130, 359,   1,  18]),\n",
       " tensor([1283,    9,    8,   55,  135,  453,  332,   13, 1510,  496,   60,  186,\n",
       "           75,    2,  226,   23,  223,  177,   45,  959,   16]),\n",
       " tensor([  4, 162,   7]),\n",
       " tensor([ 29,   7,  74,  12,   5,  13,   4,  12,  22, 733,  26,   1,  47, 387,\n",
       "           1, 791]),\n",
       " tensor([ 172,   90,    7,   82,   17,   81,  294,    1, 1220,   73,  309,   18,\n",
       "          454,  141,   60,    4,   87,  123,  197,    7,  291,  300,    1,  413,\n",
       "          197]),\n",
       " tensor([  5,  27, 441, 755, 471, 142,   2,  38,  79,  22, 717,  43,  35,   2,\n",
       "         207,  28,  45,   7, 268,   9, 147,  75]),\n",
       " tensor([117, 112,   1,  47]),\n",
       " tensor([  67,  117,    7,   98,   12,    5,   27, 1416]),\n",
       " tensor([   6,  337,   14,  465,    2, 1221,   53,    1,   36,   27,   58,    4,\n",
       "           29,  689,   34,    8,  228,   90,   75,  154]),\n",
       " tensor([  8,  64,  11,   5, 851, 409,  10,  19, 228,  80,  17,  12, 154]),\n",
       " tensor([ 12,  33, 138, 161,   6, 107, 734,   9,   6,  50,  29,   7,  39,  16,\n",
       "         161, 303, 111,  11,  50, 530,   1, 171]),\n",
       " tensor([  7,  45, 981,  11, 852, 308, 489]),\n",
       " tensor([849,  18, 308,   9, 147,  75, 263]),\n",
       " tensor([ 70,   1,  93,   6,   5,  21,   7,  98,  10,  18, 216, 204, 153,  16,\n",
       "          80,   1, 125,  11, 292]),\n",
       " tensor([  7, 305]),\n",
       " tensor([  37, 1128,  215,  138]),\n",
       " tensor([ 121,   31,  120,  274,  735,  701,   31,    2,  110,  236,   22,  278,\n",
       "            1,   47,   53,   14, 1159,  446,    1,  471,    8,    6, 1350, 1511,\n",
       "         1512,  236,  339]),\n",
       " tensor([ 70,   1,  93,   6,   5,  61,  18, 352,   2, 252]),\n",
       " tensor([  7,  12,  94,   5,  47, 217, 421, 142,   4,  57,   1,   2, 140,  10,\n",
       "           7,  38,  79,  11,   5,  10, 189,  19, 249]),\n",
       " tensor([  7,   5,  38,   5,  27,   1, 223,  10,  22, 717,  85,   1, 268, 850,\n",
       "         148]),\n",
       " tensor([   4,  159,   18,   98, 1279,    2,    1,   17,    8,   54,  545, 1164]),\n",
       " tensor([ 18, 216,   2, 252,  10,  51,  70,   1, 105,  13]),\n",
       " tensor([ 19,  63,   7,   8,   3, 521, 185, 661, 155, 127,   9,  48]),\n",
       " tensor([ 80,  11,   5,  27, 522,   1, 288,  15,  38,  79, 142,  37, 143,   7,\n",
       "           6, 162,   1,  39,  16]),\n",
       " tensor([ 489, 1222,   14,  147,   50,  137,   54,   58,    6,  352]),\n",
       " tensor([183,  49,   3, 114, 104]),\n",
       " tensor([  11,   18,  135,    2,  468,  648, 1287,   13,   74,   47,   16,    1,\n",
       "          853]),\n",
       " tensor([ 34,   8,   6, 114,   5,  27, 471,   1, 421, 250,  19,   6, 114, 360,\n",
       "         913,  13,   3, 394,  29,  31,  44,  78,   1, 471,  30]),\n",
       " tensor([  29,    7,   74,   15,   16,    1,    3,  152, 1417,  838,  188,  535,\n",
       "          881]),\n",
       " tensor([ 34,  41, 173,   8,   3, 276, 635,   7,  98, 626]),\n",
       " tensor([ 83,  13, 455, 413,  84, 122, 914,  24,   9,  18, 216]),\n",
       " tensor([  5,  40,  59,  28,  13, 471, 158,   1, 447, 126, 448,  95,  26,   7,\n",
       "         168,  12,  56,   6, 273, 649]),\n",
       " tensor([422, 314,   7,  98, 987,  17,   8, 439,  16, 667,  63,   7]),\n",
       " tensor([  7,  98, 260,  16, 556,   1, 439,   6,   5,  24,   2, 116,  38,   5,\n",
       "          10,   2,  30, 559,   1, 209,  17, 235,   3, 329]),\n",
       " tensor([ 650,   18,  216,   27,    9, 1129,  300,  322,    1,  104,    9,   10,\n",
       "         1418,   57, 1129,    1,  282,  938]),\n",
       " tensor([  18,  834,  352,    2,  399,  240, 1223,  160,  264,  204,  153,   16,\n",
       "          502]),\n",
       " tensor([  4,   2, 131, 145, 546,   1,  11,   5,  29,   7, 153,  16,  96,  60,\n",
       "          17,  45,   2, 439]),\n",
       " tensor([ 66, 274,   5,   5,  71,  65,  40,   9,  11,   1, 111,   3, 171,  65,\n",
       "         274, 141,  85,  42,  16,   1, 439]),\n",
       " tensor([  4,  19,  17,  26,  72,   2,   6, 126,  13,   3, 430,  27,   3, 141,\n",
       "           8, 502,  34]),\n",
       " tensor([  12,    1,   91,    1,  147,   75,    1,   15,    1,  522,   99,   66,\n",
       "            2,  281,    1,  226,   13,  522,   26,   20,    7,  423,   16,  702,\n",
       "         1082]),\n",
       " tensor([   4,    2,   41,  145,  546,    1,   11,  156,    5,   21,    7,   99,\n",
       "           26,   17,    2,   38,   79, 1048,   21,    3,   71]),\n",
       " tensor([  60,    2,    7,  234,  198,  114,  329,   27, 1288,    1,  854,   85,\n",
       "           27,  471,    1, 1288,  240,   16,   18,  159]),\n",
       " tensor([ 617,    4,   29, 1284,    1,   47,   21,    7,  171,  776,   44,   78,\n",
       "          140,  159,  552,   80,   18,   75]),\n",
       " tensor([ 62,   2,   7, 736,  12,   6, 329,  27, 407,   1, 522,  26,  22, 329,\n",
       "          27, 522,   1, 407]),\n",
       " tensor([ 37,   6, 628,  98]),\n",
       " tensor([ 48,  35,  23,  42, 915,   2,   6, 882, 173]),\n",
       " tensor([  7,  12,   3, 196,   5, 241, 154]),\n",
       " tensor([ 276,  420,  527,   23, 1124]),\n",
       " tensor([ 34,  41, 173]),\n",
       " tensor([ 70,   1,  11, 141, 120, 243,  39]),\n",
       " tensor([   3,  117,   75, 1014,   13]),\n",
       " tensor([151,  19]),\n",
       " tensor([ 145,  546,    1,  527,    3, 1165,    9,   11,    5,  140,  142,    4,\n",
       "          424,  130,   15,  353,    1,  649]),\n",
       " tensor([   2,    5,   27, 1224, 1225,    1,  223,   13,  853,   38,   79]),\n",
       " tensor([  7,  98,   2, 468,   4, 159,   7]),\n",
       " tensor([792,  95, 839]),\n",
       " tensor([ 94, 210,   9,   5,  27, 223, 755, 288]),\n",
       " tensor([  3,   9,  18, 352,   2,   6, 181,  30,  74, 256, 352]),\n",
       " tensor([ 817,  847, 1041]),\n",
       " tensor([365,  51,  70,   1,  19, 502,  26,   3, 216,   2,  20, 104,   4,  70,\n",
       "         123, 368,  10,   3, 126, 662]),\n",
       " tensor([ 34,   8,  18, 114,  36,  32,  99,  61,   8,  39,  16,  15,  64,  11,\n",
       "         134, 793,  53]),\n",
       " tensor([  34,   98, 1226,  554,  101,    3]),\n",
       " tensor([ 159,    3, 1162,   23,   76,   13,  361,   43,    8,    5,    1,  117,\n",
       "           67,    4,  168,   15,   33, 1083]),\n",
       " tensor([   3,  175,   13,  253,   24,   16,  663,   12,   47,    4, 1015,  221,\n",
       "          164,  598,  628,    1]),\n",
       " tensor([982,   9, 216, 240, 324,  60, 832, 431, 496]),\n",
       " tensor([ 146,    2, 1289,  178,  137,  165,  291,   13,  426,  146,   97,    4,\n",
       "          180,  345,   94,   39]),\n",
       " tensor([ 63,   7,   8,   3, 536, 818,   8, 129, 521,  61, 273]),\n",
       " tensor([  67, 1125,  159,    1,  132,  103, 1352,    2,    1, 1084,  250,  420,\n",
       "           54,  273, 1130,  883,   23]),\n",
       " tensor([ 34, 100,  35,  72,  10,  78,   3, 592]),\n",
       " tensor([1212,  528,   81,  137]),\n",
       " tensor([  94,  336,    1,  261,   47,  341,   27, 1344,    1,  854]),\n",
       " tensor([374, 236]),\n",
       " tensor([ 203,   19,    6,  114,  360,  282,  461,   24, 1166,    3,  248,  134,\n",
       "          163,   63,    7,  183,   17,   49]),\n",
       " tensor([ 414,  840,   83,   10,  466,  840,   26,   15,  218,   13,  772,   83,\n",
       "           20,    6,  100,  112,    1,  400, 1218]),\n",
       " tensor([ 25,   2,  58,   7, 107, 171, 170,   1,   3]),\n",
       " tensor([   4,  139,    8,  341,    5,    9,   20,    1,   12,    1,  313,    8,\n",
       "         1215,  916, 1227,   10,  228,    8,  703]),\n",
       " tensor([  72,    2,  353,  409,   21,    7,  216,   13, 1129]),\n",
       " tensor([ 34,   8,  76,  11, 165,   9,  18, 354,   5,  10, 109,  16, 227, 150,\n",
       "         172]),\n",
       " tensor([  8,   6,  20, 209,   6,  83, 263, 283,   4,  19,  20, 119,   1, 335,\n",
       "          13,   3, 156, 478]),\n",
       " tensor([ 528,    9, 1016, 1228,   99]),\n",
       " tensor([282, 346,  14,  83,  13, 156, 275]),\n",
       " tensor([  4, 132,  58,   7,  19,  72]),\n",
       " tensor([ 112,    1,   81, 1229,   14]),\n",
       " tensor([   7,   96,   51,   47,  847,    8,    3, 1290]),\n",
       " tensor([ 18, 737, 314,  55,   3, 163]),\n",
       " tensor([ 10, 154,  37,  60,   4, 180,   7,  98,  68,  15,  94, 100,   7,  37,\n",
       "          19]),\n",
       " tensor([347,  11,  83,  21,  22, 701, 148,  83,   2, 651, 832,  20, 884,   3,\n",
       "         455,   4, 850]),\n",
       " tensor([ 528,   49,    9, 1016]),\n",
       " tensor([  31,   12,    6, 1131,  250, 1226,  344,    1,  367]),\n",
       " tensor([  60,    2,    7, 1419,   44,    1,  261,   47,    1, 1353,  203]),\n",
       " tensor([  58,    2,   18,  342,    9,   47,   87, 1513,    4,    2,   69,   43,\n",
       "            8,  195,   41,    4,   29,   88,   16]),\n",
       " tensor([ 202,  165,   61,  143,  162,    2,  260,   16,    8,    3,   24,    2,\n",
       "           13,    3, 1132,  960, 1133]),\n",
       " tensor([63,  7]),\n",
       " tensor([  2,  72, 249,  44,   9,  21,   3, 216, 115,   2,  15,   6, 337,  14,\n",
       "         492, 433, 269, 113]),\n",
       " tensor([  4, 180,   4, 110, 353,   9,   3,  50, 304, 177,  19,   4]),\n",
       " tensor([ 57,   1, 261,  47,   1]),\n",
       " tensor([ 52,  88,   1, 105,  21,   3,  75, 156,  41,  24,   2,  66,   4, 284,\n",
       "           7]),\n",
       " tensor([   4,   12,   37,  105,   13,    5,    1,  367,   27,  288,   61,    2,\n",
       "           88,   86,   47,  571,  819,    4,   15,   22, 1420]),\n",
       " tensor([ 691,   10,    4,  855,  436,  649,  309,   11, 1085,   10,   52,  120,\n",
       "          178,  276]),\n",
       " tensor([   2,    7, 1419,   44,    1,  110,    3, 1049,    9,   64,    5,    7,\n",
       "           29,   42,   25]),\n",
       " tensor([  58,    2,   18,  342,    9,   47,   87, 1513]),\n",
       " tensor([ 634,  501, 1167]),\n",
       " tensor([988, 841,  18, 216,   2, 399,   7,  12, 107,  10,   9,   3, 502, 510,\n",
       "           4,  25]),\n",
       " tensor([ 77, 159,   1,  19, 103,   8, 847,  37,  95,   4,  19,   8]),\n",
       " tensor([   4,  810,    8,    6, 1421,   13,   10,    4,    2,  641,   67,    7,\n",
       "           98,  280,   11]),\n",
       " tensor([  6, 501, 244,  14, 704]),\n",
       " tensor([109,  26, 132]),\n",
       " tensor([ 51,  70,   1, 105, 217,  11,   5,   9,   3, 216,  10,  65,  20, 104,\n",
       "         198, 793,  14,  41]),\n",
       " tensor([129,  40, 755, 171, 484, 197]),\n",
       " tensor([105,   3, 216, 188,   7,  44,   1,   3, 111]),\n",
       " tensor([ 19,   7,  98,  96,  18, 502, 430,  27, 141,   2, 399]),\n",
       " tensor([ 250,   82,   31,  388,    6,  913,   13,  476,  158,    1,  198,   14,\n",
       "           80,  208, 1086,   61,  413]),\n",
       " tensor([159,  17,  68,  43,   8, 535, 331,   5,  37,   1, 527,   3, 737, 664,\n",
       "         911, 106]),\n",
       " tensor([125,  11, 146, 133,  73, 272,   9,   5,  27, 288,   1, 518,  61,  51,\n",
       "          42, 287,  73,  22, 109,  16,  78,  11, 851]),\n",
       " tensor([   3,    5,   93,  126,   14,   18,  216,  322,    1,    2,  399,    9,\n",
       "          424, 1291,  145,  217,   24]),\n",
       " tensor([365,  37, 119,   1, 132,  67,   7,  12,  94, 152, 554, 336,  25, 244,\n",
       "           8, 514, 159,  47,   7,  98,  10, 254,   1,  19,  41, 103]),\n",
       " tensor([  4, 328, 671, 361,   9, 150,  26,  65,   9]),\n",
       " tensor([348,   1, 453,   3,  73, 463, 153,  19,  25]),\n",
       " tensor([107,  11,   5,  62,  19, 578, 104]),\n",
       " tensor([ 52,   2, 151,  10,  39,  16,  53, 340]),\n",
       " tensor([ 429,   17,   64,    3,  112, 1127,    3,  715,   99,    4,  132]),\n",
       " tensor([ 63,   7,   4, 757,  45]),\n",
       " tensor([145,  95,   6, 856, 430,   8,  18]),\n",
       " tensor([  2,   7, 672, 153,  82,  17, 463,  99]),\n",
       " tensor([   3, 1017,  818,   14,   18,  216,  322,    1,    2,  399,    8,   16]),\n",
       " tensor([ 68, 105,  13,  18, 352, 145,  95,  25, 287,  35,  17, 519]),\n",
       " tensor([  29,  118,   39,   25, 1168,  401,  168,  118,   39,   21,    5]),\n",
       " tensor([ 457,  261,   32,    1, 1277,   27,   25,  244]),\n",
       " tensor([ 186, 1012,    2,  459,  155,  427,  493,    8,    6,  820,  170,  550,\n",
       "            4,    2]),\n",
       " tensor([ 758,    2,  225,   13, 1288,   92,    5,  883,  508,   24,   71,  112,\n",
       "           27,  367,    2]),\n",
       " tensor([282,  10,  51, 642]),\n",
       " tensor([  62,   80,  198,  273,  649,    9,    3,    5,   78,    8,    3,  273,\n",
       "         1422]),\n",
       " tensor([  74,  284,   16,   80,  110,    9,    5,   27,  223,    1,  367,   83,\n",
       "         1292,   57,   17,  331,   42]),\n",
       " tensor([ 39,   4,   2,   9,   5,  27, 231,  83, 110,  57,  17,  78]),\n",
       " tensor([983,  15,  16,   3,   8, 698,   6]),\n",
       " tensor([  11,  146,    2,   44,  115,  598,   11,  629,    6,   69,   22, 1018,\n",
       "           85,  185,   27,  146]),\n",
       " tensor([ 34,   8,  81, 213,  14,   9, 200,   5, 989]),\n",
       " tensor([  34,    8,    3, 1134,  908,  989,    1]),\n",
       " tensor([  4, 414,   6, 842,   8, 308, 718, 197, 272, 194,  26, 334, 323,  78,\n",
       "          62,  19,   4,  15,  39,  21,  25]),\n",
       " tensor([298,  34,   8,   3, 199, 145,   8,  94]),\n",
       " tensor([257, 908]),\n",
       " tensor([ 810,    8,  308,  981,    9,  773,  207,   15,  454,  141,  215,   73,\n",
       "           69,   22,  811,  357,    7,   98,   12,  477, 1169,   92]),\n",
       " tensor([  2,  11, 152,  44,   1,  75]),\n",
       " tensor([ 29,   7,  39,  13,  57,  14, 198,  39,  13]),\n",
       " tensor([  4,   7,  10,   2,  41, 145, 546,   1,  11,   5,   1, 732,  13, 176,\n",
       "         197]),\n",
       " tensor([  4,   2,  41, 560,  17,   2, 914,   4,  81,  11, 156, 847,   5,   6,\n",
       "         484, 244,  78,  10,  17,   2,   6, 163]),\n",
       " tensor([  5,  93, 126,   5,   1,  11, 308, 981,  19,   9, 108, 485,  86, 308,\n",
       "         264]),\n",
       " tensor([ 70,   1, 145,  95,  18, 352,   2, 252]),\n",
       " tensor([ 11, 789, 230,  21,   7,  15,  16, 140]),\n",
       " tensor([ 143,    6, 1135,  379,    1,    3,  141,    7,  385,   26,    1,   22,\n",
       "         1230,   45,   70,  106,  171,  244, 1231]),\n",
       " tensor([ 156,   35,   47,  847,   44,    1,   34,    8,    3,  909, 1423,   11,\n",
       "          152,   75]),\n",
       " tensor([ 20, 131,   3, 163,   4,   2, 503, 133,   4, 610,  59, 105,  13,   6,\n",
       "         759, 531,   9, 236, 228,  26, 574, 651, 673,   9, 150]),\n",
       " tensor([  2,  54, 146, 885,  23, 288]),\n",
       " tensor([   1, 1286,  217,    3]),\n",
       " tensor([   4,  238,   21,    6,  934,   24,  245,   22, 1019,    4,    2,    6,\n",
       "          599,   36,  177,   47,    9,   86,  148]),\n",
       " tensor([   4,    2,  582,   24,   18,  789, 1422,    2,   20,  810,    1,    6,\n",
       "          170,    4,   93,   73,  188,    4,  280,    3,  141]),\n",
       " tensor([  58,  225,    1,  341,    5,   27,  145,   13,  457,  117,  132,  295,\n",
       "         1133]),\n",
       " tensor([ 29,   7,  39, 110,  11,  13,  46,  23, 794, 455, 501,  83,  27, 181,\n",
       "          76, 288,   5,   1, 367]),\n",
       " tensor([990,  21,  86, 834,   1,  39, 834, 939]),\n",
       " tensor([  37,    3,    2,   64,   12,    6,  126,   21,  387,   10, 1514,  155,\n",
       "            3,  196]),\n",
       " tensor([159,   7,  98,  26, 472,  15, 198, 341, 554, 854,   1]),\n",
       " tensor([  4,  77,  95,  39,  21, 198,   5,  74]),\n",
       " tensor([523, 252,   8,  58]),\n",
       " tensor([ 14, 777,   4, 104,   8,  10,  51,  21,   3, 592, 847, 362]),\n",
       " tensor([377, 156,  35,  47,  21,   7, 231]),\n",
       " tensor([   3, 1049,  490,    3,    5,   27,  476,    1,  367,   37,   57,    6,\n",
       "          180,   80,   17]),\n",
       " tensor([ 19,  26,   4,  57,   3, 857, 667, 168,   7,  74,  39]),\n",
       " tensor([  4,  12,  10,  10,   1,   3,  71,   7,   2, 611, 149]),\n",
       " tensor([   9,   27,  223,    1,  471, 1414,   50,   20,   49,    1,   18, 1515]),\n",
       " tensor([   9,    5,  530,    1,  471,   27,  223, 1414,   50,    4,   12,  154,\n",
       "            2,    9,  689,    8,    6,  114,   75]),\n",
       " tensor([  15,   17,  450,  169,  380,   49,   86,  462,   86,    4,  285,  122,\n",
       "           12,  285, 1424]),\n",
       " tensor([  18, 1170,  662,  206,  104,    9,   18,  216,    1,   93,  460,   70,\n",
       "          133,   35,    9,   89,   25,  305]),\n",
       " tensor([ 611,   13,  113,  294,   14,    2,    9,   48,   21,  515,   32,   19,\n",
       "            4,   57,    1,   19,  249,    1,  282,    6, 1516,  579,    1,   11,\n",
       "          174]),\n",
       " tensor([282, 346,  14,  83,  13, 156, 275, 102]),\n",
       " tensor([ 14, 777,  12, 839,  34, 348, 152, 244]),\n",
       " tensor([961,   2,   6, 537,  74,  91, 228,  26, 126,  21,  25, 961]),\n",
       " tensor([  4,  37,  19,  62,  29,   4, 162,  19, 118,  12,   1, 266, 282,  16]),\n",
       " tensor([   8,   11,  191,   77, 1158,    6, 1293,   27,   18,    5,  164,  191,\n",
       "            2,    6, 1171,    8,   75]),\n",
       " tensor([ 37, 335, 795,   8, 407, 554,  34,   8, 282,  24, 159, 705,  75,  61,\n",
       "         705, 216,   2, 196, 352, 154]),\n",
       " tensor([ 109,    6,  259,    8,   11,   92,    5,    5,  304,  114,   32,  167,\n",
       "            6,  616, 1172]),\n",
       " tensor([  4,  57,   6, 857,   8,   6,   5,  91,  29,   7, 143,  71]),\n",
       " tensor([  4, 692,   6, 308, 981, 414,   6, 361,  78,  10,  69, 323,  47,   9,\n",
       "         535,  29,   7, 145]),\n",
       " tensor([ 12,  16,  23, 184, 664, 911, 159,  11, 156, 687, 715,   5]),\n",
       " tensor([ 24, 206, 145,   1,   1,  16,  17, 145]),\n",
       " tensor([ 593,   82,   61,  575,   12,   27,  917,  423, 1425]),\n",
       " tensor([  6,   2,  13, 421,  13,   8]),\n",
       " tensor([ 6, 13,  3]),\n",
       " tensor([ 6, 13,  3]),\n",
       " tensor([ 6, 13,  3]),\n",
       " tensor([1173,  835,  407,    1,  732,    9]),\n",
       " tensor([ 18,  50,   2, 131, 595,  37, 180, 118, 122,  96,  24]),\n",
       " tensor([  60,    2,    7,   47,    1, 1277]),\n",
       " tensor([  51,  821,   11,   53,   70,    1,   93,    6,    5,   21,  118,   18,\n",
       "          352,  206,  104,    9, 1129,   85,   12,    6,  504, 1133]),\n",
       " tensor([63,  7]),\n",
       " tensor([100,   1,   2, 140]),\n",
       " tensor([   4,  561,  130,  293,   11,   13,   83,   10,    4,  139,    6, 1126,\n",
       "            8,   25,  153,   16,   53,   14,  144]),\n",
       " tensor([  4,   2,  13,  83,  10,   4, 561, 130, 293,  11,  10,   4, 139, 325,\n",
       "           8,  25,  83]),\n",
       " tensor([  67,  117,    7,   98,    2,  261,  415,    5,   23,    3,  437,   14,\n",
       "            3,  393,  474,   69, 1426,  170,    9,  773]),\n",
       " tensor([ 34,   8,  24,   2,  57,   6, 112,   1,  55, 415, 732, 170,  27, 344,\n",
       "          10,  30, 524, 178, 187]),\n",
       " tensor([886, 152, 554,   1, 732,  27]),\n",
       " tensor([ 25,   2, 172, 489, 120,   2,   9, 405,  50,  26,  30,   4,  45]),\n",
       " tensor([114, 148, 940]),\n",
       " tensor([1174,    3,  141,  562,    7,   82,    1,  284,   13,  141,  206, 1175,\n",
       "          141]),\n",
       " tensor([308, 981,  59, 197,  12,  44, 102,  10,  22, 171, 197, 254, 253,  45,\n",
       "         485, 515, 887,  22,  39]),\n",
       " tensor([ 18, 216, 305,  37, 180,   7, 122,  96,  64, 196]),\n",
       " tensor([  7, 122,  69,  33, 311, 116,   7,  45,   2,  11, 991,  75]),\n",
       " tensor([  64, 1354,  303,    2,   66,    4,  139,    1,  527,  941,  597]),\n",
       " tensor([ 15,  17,  64, 674,  34]),\n",
       " tensor([ 22,  86,  25, 244]),\n",
       " tensor([ 117,  262,    4,  132,    9,  938,    2,  847,  834, 1087,   62,   19,\n",
       "            4]),\n",
       " tensor([  10,  847, 1041,    6,  981,   55,   13]),\n",
       " tensor([ 63, 266, 132,   7, 776]),\n",
       " tensor([  62,  178,    7,   84,   12,   33, 1129,  311,   69,  149,   10,   55,\n",
       "           16,  538, 1294]),\n",
       " tensor([ 18,  78,  14,  83, 906, 214,  19,  20, 760, 259, 371,  24,  12,  33,\n",
       "          13,   3]),\n",
       " tensor([  60,   45,  149,   64,  300,  573,  346,   14,  133,   99,  282,   55,\n",
       "           25,  459, 1136]),\n",
       " tensor([   2,   39,   16,  813,   49,   11, 1123]),\n",
       " tensor([   4,  817,  405,  135,   10,  207,  262,    2, 1232,   19,  118,  260,\n",
       "            8,   26,   20, 1427,   51,   20,    6]),\n",
       " tensor([  63,    7,  132,  419,  462,   51, 1278,    1,  132,    3,   14,  431,\n",
       "          415]),\n",
       " tensor([ 152,  835, 1050,   61]),\n",
       " tensor([282, 159, 554]),\n",
       " tensor([689,   1, 652,   7,  22, 643,  47, 367, 755, 306, 254,  17, 331]),\n",
       " tensor([ 29,   7, 285,  16,   3, 274, 283,   8,   6,   5,  85,  29,   4, 268,\n",
       "         648,  71,  14,  18,  67,  41, 177,   2]),\n",
       " tensor([  12,    3,  408, 1517,   36,   32,  115,  154,  163,   41]),\n",
       " tensor([ 30,  60,  45,  31, 132, 178,   1, 992, 306]),\n",
       " tensor([  2,   4,  19,   7, 131,  37, 293,  49,   6, 554, 583, 407,  10, 732,\n",
       "          10,  19,  25, 328, 539, 424,   2, 171]),\n",
       " tensor([1173,  286]),\n",
       " tensor([  1, 261,   5,  27,   1,   9, 962]),\n",
       " tensor([ 257,    1,  132,    7,   13, 1287,   26,   84,  706,   80,   56,  144,\n",
       "           13,    4,   77,  159,    1,  132,  103,    5,   53,   14,  144]),\n",
       " tensor([305,  11, 189, 104,   9,  11,   5,  52, 457, 119,   1, 145, 217,  24,\n",
       "           8, 693, 175]),\n",
       " tensor([ 151,  372,  163,  156,  504,  126,   30,   83,  218,  107,  858,   13,\n",
       "          426, 1088]),\n",
       " tensor([   1, 1051,    9,  554,  309]),\n",
       " tensor([  3, 554,  55,  11,  73]),\n",
       " tensor([276, 329,   8, 117, 563, 112]),\n",
       " tensor([  4, 107,   3,  13, 426]),\n",
       " tensor([ 159,   17,   81,    9,   13,  184,  637,   60, 1415]),\n",
       " tensor([  2,  47,  27, 159,   1, 732,  30,  24,   2, 408, 822, 811]),\n",
       " tensor([1122,    9,    3,  152,  554]),\n",
       " tensor([   4,   70,   24,    7,  245,    1,  260,   16,   33, 1089,  761,    8,\n",
       "            6,  152,  108,   85,    2,  381,  279,  330,   35,  128,   35]),\n",
       " tensor([  29,  118,   39,   21,    5,    1,   15,    6,  401,  177,   57, 1168,\n",
       "           13]),\n",
       " tensor([120,  12,   6,  90, 163, 188,  26,  25,  71,  81,   3,  30,   8, 531,\n",
       "           9, 734,  86, 148]),\n",
       " tensor([  12,    1,  453,  208,   28,  590,   24,  734,   13, 1176,   77,    2,\n",
       "          205,    4,  317,  531,  157,    9,   50,   85,   46]),\n",
       " tensor([  64,   14,  547,    2,   88,   72,    2,   22,  103,  516,   13,    3,\n",
       "         1079,   60,    4,   15,    9,    3,   50,    2,  516,    8,   23,  356,\n",
       "          133,   46,   13,   11,  455]),\n",
       " tensor([ 34,   8,  55,  11,   5,  27, 288,   1, 223,   6, 963, 102, 610,  16,\n",
       "           1, 105,  11, 531,   9,  46,  23,   3,  76, 207]),\n",
       " tensor([  4,  12, 337,  14,   5,   1,  93,  10,  18, 352,  17,  20, 104, 115,\n",
       "           2,   9,   3,  89,  43,   8, 101, 294, 113]),\n",
       " tensor([  19,  847, 1041,   47,  341,   27,  983,    1,  476,   85,  421]),\n",
       " tensor([ 51, 211,   6, 337,  14,  18,  10,   5,  44,   6, 337, 859, 155,  21,\n",
       "           6]),\n",
       " tensor([  30,   65,   37, 1355,  113,  279,   11,    6, 1218,  263,  840,  293]),\n",
       " tensor([778, 198,   8, 142,   2]),\n",
       " tensor([ 66,   2,  17,  81, 363, 244,   1,  47, 140,   1, 407,  15,  18, 675,\n",
       "         463]),\n",
       " tensor([ 571,  847,    2,  694,   13,  152, 1417]),\n",
       " tensor([ 77,  12,   2,   6, 170,  26,  31,   2,   9,   6,   5]),\n",
       " tensor([ 2, 24]),\n",
       " tensor([ 147, 1233,    5,   62,  178,    9,   18,   50,    3, 1295,   29,  449,\n",
       "          252,  186, 1012,   55,    7, 1177,  157]),\n",
       " tensor([257, 420,   3, 823,  14, 424,   2,  26,  31,  12, 277,  37,  82]),\n",
       " tensor([  4, 159,   3, 461, 489]),\n",
       " tensor([   4,  149,  938,    4,   69,  159,    7,  357, 1158,   37,  149,   11,\n",
       "          141,   13,    3,  693]),\n",
       " tensor([ 34,   8,   3, 273, 789, 264, 419,   2,  64, 181,  21,  16]),\n",
       " tensor([823,  14,  47,   1, 103, 496,  21, 103, 172]),\n",
       " tensor([ 34,  41, 173,   8, 528,  37, 282,  17,   1,  11, 352]),\n",
       " tensor([  4, 907, 221,  12,   6, 847, 834]),\n",
       " tensor([  7,  15,   5, 172]),\n",
       " tensor([ 9, 64, 18,  5]),\n",
       " tensor([1234,    9,    2,    3,  196,  676,   14,   25,  619]),\n",
       " tensor([  2,  72,  94, 336,   8,   6, 860,  75,  13,  77,  47,  21,   7,  98]),\n",
       " tensor([ 277,   10,  100, 1504]),\n",
       " tensor([ 62, 178,   2,   3, 117,  71,  14,   3,   7,  84,  12]),\n",
       " tensor([ 261,   11,    5,   21,    6,    8,  149,   33,  796, 1079,   24,    2,\n",
       "          116,  245,    1,    3,  307,   83,  171,    1,   16]),\n",
       " tensor([ 20, 117,   2,  17, 114,  26,   7, 331,  11,  42,   3,  73,  87, 317,\n",
       "         222,   8, 103]),\n",
       " tensor([ 361,  186,   75,  942,   38, 1052,    5,  217,  441,   10,   39,  184,\n",
       "           36,   15,  140,  847,    2,   82,  100,  762]),\n",
       " tensor([ 847,   36,  361,  203,  381,   13, 1509,    8,  123,   73,   61,  148,\n",
       "           19,    3,  151,  356,   31,   29,    1,  888,    7]),\n",
       " tensor([ 122,  149,   25,   13,  184,  171,   75, 1235,  564]),\n",
       " tensor([ 547,  847,   13,   21,    3,  889,   30,  441,  129,   12,  184, 1020,\n",
       "         1425,  120,    5,   93,  126,   21,  847,  106]),\n",
       " tensor([  86,   71,   14,    3,  618, 1296,  102,    3,  421,  653,   51, 1518,\n",
       "           23,  847,  695,  184,   36]),\n",
       " tensor([ 41,  22, 370,  86,   1,  66,  25,   2,   2,  72, 169, 368,   4, 122,\n",
       "         284,  85, 284,  16,   1,  15,   6, 195]),\n",
       " tensor([  70,    1,   55,    3,   91,   13, 1236,   20,   37,  458,   28,   17,\n",
       "          194,  227,   10,   17,  119, 1519,   13,   91,  283]),\n",
       " tensor([  94,  112,    1,   91,   27, 1137,  651,    1, 1137,  651,  832,    9,\n",
       "          215,    5,  312,  139,    6,   91,  283]),\n",
       " tensor([   7,   98,    2, 1233,   86,  296, 1158]),\n",
       " tensor([ 34, 419,  12, 198,  14,   3, 196,  36,  32, 110,  13,   3]),\n",
       " tensor([  29,    7,  109,   16, 1218,  308,    8,  363,  393]),\n",
       " tensor([ 131,  617, 1125,   47,   53,   14,  415,  550,    2]),\n",
       " tensor([1049,    9,   11,   83,   49,   11]),\n",
       " tensor([  11,  547,   15,  184,  274,  735,  283, 1160,   26,    4,   68,  121,\n",
       "           11,  108,    2,   93,    8,   18,  267,    2,   22,   39,  596]),\n",
       " tensor([  2,  72,  94, 636,  49,   1,  13]),\n",
       " tensor([  37,   15,    9,    3,   13,  514,  140,    1,  471,   18,  815,   23,\n",
       "          440,    2, 1517]),\n",
       " tensor([229,  67,   4,  12,   6, 375, 890, 264,  61,   5,  29,   4, 162,   7]),\n",
       " tensor([ 69,  43,   1, 132]),\n",
       " tensor([  47,  288,    1,  367,   10,   87,  145,   23,    3,  276, 1520,    4,\n",
       "          373,  617,    4,    2,    9,    6,  190]),\n",
       " tensor([ 93,  53,  14,  21, 550,  27]),\n",
       " tensor([ 34,   8,  81, 213,  14,  24, 348,  36]),\n",
       " tensor([ 69,  22, 209,  85, 584, 309, 162,  74, 576,  25, 138,  86,  18,  38,\n",
       "          79,   5,   2, 985,   1,  11, 170]),\n",
       " tensor([  40,  158,    1,  475,   14,  164,   10,   30,   40,  106,  121,   72,\n",
       "            6,  190,  179,    8, 1138,   69,   57,    1, 1166,   32,  861]),\n",
       " tensor([  7, 180,   7, 150,   5, 172, 227,   4, 180,  41]),\n",
       " tensor([   4,  297,   26,   65, 1237,   60,   72,    2,   22,  112,    1,   15,\n",
       "            1,    3,  111,  843, 1090,   14,   33,   65,    6,  493]),\n",
       " tensor([  76,   97, 1297,   16,   49,   21, 1298,    5,   67,    7,   12,    6,\n",
       "          112,    1, 1428,    3,  138,   24,   77,  626]),\n",
       " tensor([ 47,  13,   6, 484, 197,  62, 190,  19,  31,  12,   1,   2,  23, 111,\n",
       "           8, 188, 324,   8, 451, 532,  10, 891]),\n",
       " tensor([ 34,  17,   2,   9,   3, 215, 108]),\n",
       " tensor([ 66,  20,   2,  17,   6,  85,   6, 342]),\n",
       " tensor([   2,    3,   90,  156,  275,  108,  402,  121,   60,    7,  832,  184,\n",
       "          214, 1053, 1238]),\n",
       " tensor([ 41,   4,  29, 335, 795, 123,  73, 188,   5,  26,  68, 677,   3, 795,\n",
       "         993,  36,  32]),\n",
       " tensor([  4,  19, 261,   6, 291,  26, 197,   2,   2,   4, 131, 310,   1,  44,\n",
       "          24, 190,  21,  53,   6, 460,  83,   8,  11]),\n",
       " tensor([ 22,   4,  84,  26,  51, 211, 511,  12,  11, 239,   9,  65, 214]),\n",
       " tensor([ 67,   3, 460,  83,   2, 125, 122,  37, 959,  16,   8,   6, 152,  71,\n",
       "          25,   2,  20,   6,  14,  65,   6,   8,  11, 579]),\n",
       " tensor([ 37, 692,  11, 185,   9,   3, 430,   7, 143]),\n",
       " tensor([166, 143,  33, 141,  21,  25, 160,  10]),\n",
       " tensor([ 24, 775, 305,  11, 104,  23, 306,  82]),\n",
       " tensor([ 37, 119,   1, 153,   7,  96,  62, 797,   3,  76,  97,   2, 104,   5,\n",
       "           1, 153, 200,  96, 191]),\n",
       " tensor([ 166,    6, 1294,  270,   24,    4,   15,    9,  731]),\n",
       " tensor([  14,  773,    4,   42,  511,   52,   82,   52,   77,  143,  147,  270,\n",
       "          102, 1139,  120,   15,  249]),\n",
       " tensor([   3, 1121,    2,    6,  114,  262,    4,    2,  141,   13,   18,  349,\n",
       "          428,   52,   45,  359,    1,   16,   13,    6, 1429]),\n",
       " tensor([ 19,   4,  57,   1, 149,   6, 182, 571, 395,   8,  11, 401, 824,  85,\n",
       "          29, 221, 178,  13,  21,  16,   9,  11, 395]),\n",
       " tensor([ 10,  58,   2,   4, 310,   1,  19,  21,  24, 160]),\n",
       " tensor([167, 132, 438]),\n",
       " tensor([  4,  47,  78, 236, 186, 349, 205, 182, 189,  12,  33, 227,   5]),\n",
       " tensor([   4,  125,    6,  270,   24,    4,    2,  109,   13,  600,    9, 1299,\n",
       "            4,   19,   20,  149,   17]),\n",
       " tensor([  4,   2,  70,   1,  93, 551,   8,  10,  57,   5,   9,  26,  52,  45,\n",
       "          20, 240, 130, 236, 298, 551,  83]),\n",
       " tensor([  4, 211,  19,   4,  12,   1, 446,   6, 918,  14, 123,  28,   1,  15,\n",
       "          11, 497,  46, 302,  95,   1, 601,  24,  26,  22,  71, 119,   1, 246,\n",
       "           1,  16]),\n",
       " tensor([167,  95, 326, 213,  80, 719, 103, 155, 180,  51, 103,  13,  12,   6,\n",
       "         236, 720]),\n",
       " tensor([132,  31,   2,  88,  24,   3, 250,   2,  92,   5,  10, 183,  15,  92,\n",
       "         219,  87,  31, 150,  72,   2,   6, 138]),\n",
       " tensor([  66,   22, 1356,  993,  179,  862,   11,  688, 1347,  189,  821,    9,\n",
       "           11,  990,    5]),\n",
       " tensor([166,  74,   4,   2,  10,  70,   1, 210,  11, 128, 301,   9,   6, 532,\n",
       "           5,  17, 322,  41, 536,  26]),\n",
       " tensor([  62,   19,  182,  559,    1,    6, 1430, 1132,  270,   60,  184,   50,\n",
       "          189,   81,  137,  158,    1, 1239, 1054]),\n",
       " tensor([266, 490,   3, 358,   4,   2,   1,  19,   4,  11, 504]),\n",
       " tensor([166, 505,   2,  21,   3,  97,   8,   3, 128, 486, 113,  71,  14,   3,\n",
       "          97,  12,   2, 151, 247,  26,  12,   2, 257]),\n",
       " tensor([  12, 1178,   21,   33,  721,  136,  658,   23,  602,  490,    3,   73,\n",
       "           45,   52,   12,    1,  291,   61,  146,   85,   45,   17,    2,   81,\n",
       "          213,   14]),\n",
       " tensor([   4,    2,   70,    1,  161,   53,   67,    3,   83,    2,  152,   85,\n",
       "          149,    6,  460,   83,    2, 1521,    1,  664]),\n",
       " tensor([   4, 1179,    7,    3,  630]),\n",
       " tensor([ 602,    1,  469,  165,  291,  267,  669,  788, 1021,   36,  116,  919,\n",
       "           36]),\n",
       " tensor([  45,  266,  153,  157,   96,    3,  796, 1079,  101,   11,  455,    2,\n",
       "            4,  159,    6,  100]),\n",
       " tensor([ 34,   8,  18,  16,  58,   4,  57,  26,  65,  33, 138,  21,   4, 474,\n",
       "           4, 127, 643]),\n",
       " tensor([  4,  77,  12, 159,   1, 359,   1,  18, 216, 279,   4, 892,   3, 131,\n",
       "         190, 580,  13, 292,   3, 152,  83,   2,  90]),\n",
       " tensor([  6, 209,  10,   5, 270,  85, 147,   5,   9,   6, 368,  75,  23,  18,\n",
       "           8,  99, 413,  28, 446,   2, 151]),\n",
       " tensor([ 116,   66,   12,    4,   20,  280,   11,   42,   78,   65,    2,  123,\n",
       "           33, 1080,  460,   83,   62,    2,    4,  310,    1,   44,  893,   21,\n",
       "           11,  579]),\n",
       " tensor([ 34, 106,   8,  18, 659,   4,  45, 284,  36, 213,  54, 331,  27]),\n",
       " tensor([148, 127,   9,   3, 364,   9,  35,  26,  43,   8,   6]),\n",
       " tensor([ 111,  394,  183,   49,    3,  100,  104,  815,   25,    2,  212, 1084]),\n",
       " tensor([ 22,   4,  57,   7,  98,   1,  20, 101,  93,  50,  65,  20,   6, 659,\n",
       "         220,  37, 134,  21, 169, 525, 347, 546]),\n",
       " tensor([   6,  486,    2,   20,   62,    7,  242,  599,   36,   87,   52,   43,\n",
       "         1431,    9,    3,  382,  490, 1522]),\n",
       " tensor([ 60,  45, 141,   2, 299,  65,   2,   6, 361]),\n",
       " tensor([ 63,   7,   8,  24,   2,   4, 281,   1, 291,  94,  85,   2,   3, 423,\n",
       "          14,   3, 851,  49,   9,  16]),\n",
       " tensor([247, 247]),\n",
       " tensor([  66,   68,    4,   15,    6,  445,  395,    8,   11,   75,    5,  268,\n",
       "            6,  300,   28,  658,   61,    4,    2,  218, 1091]),\n",
       " tensor([   4,  280,    9,  186,    5,  861, 1140, 1432]),\n",
       " tensor([  37,   47,    1,  139,  556,   27,    6, 1240,  960,  303,  189,  130,\n",
       "           55,   17,    9,    3,   50,    8,    3,   32]),\n",
       " tensor([  11,   46,    2,   69,   13, 1225,    4,    2,   10,   12,    1,   33,\n",
       "          111,   10,  145,    8,   11,   46,   20,    6,  100]),\n",
       " tensor([1283,   24,  620,   22,    1,  108,  677, 1022,  130,   42,   27,  320,\n",
       "          434]),\n",
       " tensor([  22,  435,   82,   52,   84,  448,  165,   24,   55,   17,    1, 1225,\n",
       "           52,  109,   16,   33,  702,  160,    1,   42,   22,   39,   72,  596]),\n",
       " tensor([   7,   98,   57,  198, 1090, 1357,   13,   36,   32,  172,  298,  100,\n",
       "          278,    1,  234,   49,   21,    3,  112,    7,   98,  448,  405,  825]),\n",
       " tensor([355,   1, 344]),\n",
       " tensor([ 444,  221,  161,   53,   31,   12,    6,  126,  221, 1141,   16,   95,\n",
       "            3,    2,   88,   31,   68,  161,    6,  612]),\n",
       " tensor([  38,    5,    5,   13, 1236,   57,  295,    5,  439,   41,    3,  430,\n",
       "          320,   39,   39,  393,    1,  132,   16]),\n",
       " tensor([  4,  45,  20,   2,  47,   7, 106]),\n",
       " tensor([ 13,  11, 156,   5,   2,  40,  33,  28,  10,  51,  23,  11, 431, 413,\n",
       "         136,  92,   5]),\n",
       " tensor([ 38,   5,  54,   5, 189, 268,  56,   9,   5,  30,  12,   1, 446,  27,\n",
       "           6, 435,   1]),\n",
       " tensor([  18, 1023,    8, 1358,  150,  117,  562,   11, 1055,   16,    1,  134,\n",
       "           21,    6,  337,   14,  851,   19,    4]),\n",
       " tensor([  54,  134,   93,  533,  182,  547, 1092,  108,   97,  459,  155, 1093,\n",
       "            1,   39,   21,   54,  201,   13,  288]),\n",
       " tensor([1523,  707,   21,   18,   32,   60,    4,   88,   71,   14,   18,  271,\n",
       "            4,    2,  531,  994,  191,    2,  151,  247]),\n",
       " tensor([  8, 521, 376,  26,  84, 180,   7,  29, 837,  54, 943,  45,   2, 234,\n",
       "           1, 703,  99]),\n",
       " tensor([ 204,  677,    5,  108,    1,   33,  721,  705,  401,  177, 1300,  738,\n",
       "           12,    1,   12, 1056, 1513,  616]),\n",
       " tensor([ 416,  197,   92,  219,   10,    4,   69,   12,   20,  280,   11,  224,\n",
       "           27,    3, 1433,  371, 1094,  371,    4,  728,  101]),\n",
       " tensor([ 86,   6, 761,  51, 296, 503,   8]),\n",
       " tensor([  20,  237,    4, 1057,   80,    3,   98,  177,  105,   11,  146,   13,\n",
       "           86,  221,    2, 1221,    3,   46,  470,    4,  254]),\n",
       " tensor([108,  97, 459, 155, 316,  21,  54, 943, 547, 134, 126,  68, 161,   6,\n",
       "         612,   8,  39]),\n",
       " tensor([ 834,   57,   27,    3,  364,   49,    8,  563,   65, 1043,    1,   15,\n",
       "          181]),\n",
       " tensor([147, 452,   8,   3, 182, 108,  97,  13, 459, 155, 316,  10, 168, 213,\n",
       "         459,  80,  54, 126, 403, 144,  31, 178]),\n",
       " tensor([ 303,  266,   12,  207,  104,   13, 1058,  100,  262,   25, 1059,  226,\n",
       "         1180,   14,  378,    4,   12,    1,  149,    3]),\n",
       " tensor([  3, 320, 779, 102,  16,  26, 631, 311,   2, 152]),\n",
       " tensor([  4,  37, 143,  33, 141,   1,  36, 213,  88, 157,   4, 457,  12,   1,\n",
       "         399,  49,  21,   7,   4, 254,  52,  29,  39,  16]),\n",
       " tensor([ 51,  47, 654,  99,  18, 182, 571, 193,  10, 241,   2,  10, 920,  10,\n",
       "         296, 322, 863, 102, 815]),\n",
       " tensor([ 58,   2,  18,  89, 160,   4,  68, 161, 177,   1,  42,  80,   6,   5,\n",
       "         174]),\n",
       " tensor([ 148,    7,   68,  256,   16,  107,   11, 1293,  121,   14,   26,    7,\n",
       "           29,  894,    1,   55,   49,    8,   17]),\n",
       " tensor([ 66,   2,   4,   1, 498,  52,  45,  39,  60,  36,  32, 317,  95,   4,\n",
       "          82,   4, 119,   6, 160,   1, 169, 177,  29, 256,  58,   7,  19]),\n",
       " tensor([ 52,  39,  16,  23,   3, 165,  32, 398,  82, 321, 688,   2, 252,  13,\n",
       "         540,  20,  64,  46,  55,  17,  26,  46,  45,   2,  13, 440, 363]),\n",
       " tensor([   8,    3,  678,   23,  514,    2, 1134,   10,  316]),\n",
       " tensor([340,   8, 210]),\n",
       " tensor([63,  7]),\n",
       " tensor([162, 467]),\n",
       " tensor([235,   3, 264,  14, 222,   8, 630,  80,   6,  60,   7,  93,  67,  18,\n",
       "           5, 164, 206, 603, 157, 662]),\n",
       " tensor([  4,  70,  26,  22,  71,   2, 299,  13,  10, 389,   2, 247,  13, 539,\n",
       "           4,   2, 218,   8, 756,  28, 121,  14,   7,  98]),\n",
       " tensor([ 499,  471,    1,  518, 1506,  447,  126,  106,   81,  137,   12,    1,\n",
       "          226,    8,  256,   40,  106]),\n",
       " tensor([704,  11,  46,  20,  55,  17,   1, 514, 100, 141, 936, 210,  39]),\n",
       " tensor([ 235,   44,    9,   21,  499, 1524,    5,  128,    2,   40,   62,  190,\n",
       "           45,   25,   40,    2]),\n",
       " tensor([518,   1, 854, 447, 126, 479, 722,  40, 756,  28]),\n",
       " tensor([1181,   70,    1,  105,   13]),\n",
       " tensor([ 34,   8,   3, 239,   4, 202,  96]),\n",
       " tensor([  75,  668,   25,  826,   61,   20,   15,  100,   36,   32,  284,   31,\n",
       "         1018,    8,    7]),\n",
       " tensor([   9,    1, 1285,  150,  240,  158,    1,  288,  531,    9, 1079,  354,\n",
       "           14, 1525,   22,  516,    8,   46,  118,   57,    6,  100,  214]),\n",
       " tensor([63,  7]),\n",
       " tensor([ 16, 217, 139, 325,  85,  12,  11, 331, 108,  13, 426, 111, 315,  32,\n",
       "          27, 267]),\n",
       " tensor([  2,  72,  33, 141, 562,   4,  29, 512, 172, 190,   8,   6, 162]),\n",
       " tensor([647,  24, 118, 189, 895,  11, 556, 259, 109,   1,  16,   8, 405, 825,\n",
       "          81,  11, 292]),\n",
       " tensor([ 69,  43, 310,   1, 482]),\n",
       " tensor([  17,    2,  259,   27,   11,  128,  170,   24,  120,  178,   13,    3,\n",
       "         1139]),\n",
       " tensor([377,  65,  30,   2, 416, 393,  43,   1, 323,  27,  75,   4, 109, 157,\n",
       "           6, 882, 103, 155,   3, 269,  73, 414, 315,  32]),\n",
       " tensor([ 19,  25, 510, 154, 437,  69,  43,   8,   3, 376, 205,  59, 393, 669]),\n",
       " tensor([235,  44,   9,  21,  18, 216,  51,   5, 608, 126, 436, 108,  99,  10,\n",
       "         115,   2, 137,   3, 214,  35]),\n",
       " tensor([  62,   19,    4,   15,   11,  406,  160,   67,   18,  216,   82,  141,\n",
       "            2, 1434]),\n",
       " tensor([  41,   19,    4,   57,    1,   93,  176,   71,  112,   13,  855,    8,\n",
       "          200,    1,   47,   86,   33, 1359]),\n",
       " tensor([  4, 280, 207,  46, 128, 230,   4,   2,  69, 107,   3, 186,  71]),\n",
       " tensor([ 995,   57,    1,  263,    3,   83,  172,  130,   13, 1238,  506,   65,\n",
       "           95,  127,    9,    6]),\n",
       " tensor([ 472,   39,  798,   15,    3,  509,  778, 1513,  191,   57,   18]),\n",
       " tensor([555,   5, 266,  40,  22, 250,  26,  52, 150,   2,  41,  31,  29,  37,\n",
       "         127, 144]),\n",
       " tensor([ 102,    3,  112,    6, 1360,  465,   44,    6,  190,  112,  130,   67,\n",
       "           65,    6,   71,   65,   24,    7,   84,  213,   80,   16,   85,   11]),\n",
       " tensor([  25,  320,    6,   71,   35,  262,  596,   65,    6,   14, 1526,   10]),\n",
       " tensor([944, 687,  61,  65,  64, 151, 582,  21,  25, 163,  86, 188,  25,  31,\n",
       "           2, 373,  82,  31, 780, 149,   7]),\n",
       " tensor([  65,   33, 1142,  536,  256,   26,    7,   77,  631,  449,   13,   18,\n",
       "          361,    4,   15,  610,   53,   14,  864]),\n",
       " tensor([ 13,   7,  12, 708, 799,   8,  25,   7,  12,  33, 214,  24, 412, 126,\n",
       "          95,  25]),\n",
       " tensor([389, 470,  56,   2, 127,  21, 184, 343,  10, 362, 366,  52,  93, 184,\n",
       "         108,  13,  10,  31, 335]),\n",
       " tensor([  20,  211,   58,    7,    2,  246,   80,  191,    2,   44,    9,  835,\n",
       "            5, 1527,    1,  367,   10,  116,  367,    1,  440]),\n",
       " tensor([182,  17,  45,   2, 121,  51, 347,   1, 121,  14, 246,  22,  32]),\n",
       " tensor([ 74,   2, 100,   1,  16,  25, 679]),\n",
       " tensor([   4,  222,    6,  375,   80, 1523,  126,   10,   15,   78,   33,  945,\n",
       "            7,   29,   19,  100]),\n",
       " tensor([  58,   35,  177,   29,    4,   42,    4,   57,   11, 1528,    4,   45,\n",
       "           44,    1,    3,  111,   10,   15,  157,   22,  103,   13,  182]),\n",
       " tensor([  4, 132,   7,  98,   2,  23,  17, 106, 468,  62,  71, 349,  55, 825,\n",
       "         237, 452,   1,   2,  48,   8, 184, 492]),\n",
       " tensor([   6,  641,  660,   10,   14,    3,   23,   10,  941, 1529]),\n",
       " tensor([627, 319,  26, 620, 296,   6, 126,  21, 182,  10,   7,  12,  33, 532,\n",
       "           8,  12, 126]),\n",
       " tensor([419, 122, 671, 104,   9,  24]),\n",
       " tensor([ 26, 116, 106, 428,   3,  77, 213, 103,   1, 323,  58,  44,   9, 155,\n",
       "         921,   1, 138,   7, 412]),\n",
       " tensor([   4,  641,   67,  528,   64,   25,    9,   10,   77,    6,  160, 1435,\n",
       "         1143,  131, 1241,   11,  841,   88]),\n",
       " tensor([ 41, 203,  88,  16,  72,   2,  22, 160,   1,  42,  87,   2, 110,  13,\n",
       "          33, 111, 121,  14,   6, 250,  10, 193]),\n",
       " tensor([ 168,   25,  141,    2,   86,   17,  206, 1024,    1,   12,  243]),\n",
       " tensor([166,  74,  70,   1,  15,   1,  13, 514,  30]),\n",
       " tensor([  7,  12,   1, 199,  16,  13, 855,   8,  16,   1,   9,  30]),\n",
       " tensor([396, 182,   1,  55,  49,   8, 399, 906, 214,   9,   6,   5, 411]),\n",
       " tensor([ 41,  52, 189, 477,  11,  46, 827,  61,  30,  51, 110,   8,   6, 197,\n",
       "          25,   2,  66,   7,   2, 310,   1,  48,   9,   1,   3,  46]),\n",
       " tensor([  4,  19, 162,   3, 630,  26,  69,  22, 185,   4,  12,   1,  93,  99]),\n",
       " tensor([   4,   96,   25,    2,  671,    6,   22,   26,    2,   72,    6,  112,\n",
       "            1,   15,    6,  865, 1436,  108,   67,    3,    5,    2,  110,   13,\n",
       "            6,  484,   28]),\n",
       " tensor([ 29, 169,  74, 601,   3, 510,  14,  14,  58, 225,   1, 161,   9,   6,\n",
       "          50,  87, 175, 110,  23]),\n",
       " tensor([ 20, 281,   1, 162,   7,  11, 454, 160]),\n",
       " tensor([115, 143,   3, 379, 153,  16,  96,  67,   7,  15,  17,  51,  20, 151,\n",
       "         266,   2, 221, 131,  44,   1,   2, 218,   8]),\n",
       " tensor([ 151, 1060,   23,   22,  185,    1,  456,  141,    9,  555,  773,  480,\n",
       "           36,   32]),\n",
       " tensor([162,  19,  20, 104,  58,  19,   4,  19]),\n",
       " tensor([541,  77,  12,   2, 489,  19,  19,  20, 104, 220,  70, 106]),\n",
       " tensor([  31,    2,   20,  109,    3,  278,   14,  149,   54,  182,   13,    6,\n",
       "         1346,    5,   93,  126,   94,   39,   13,  149,   85,  467, 1301,   34]),\n",
       " tensor([ 183,   18, 1294,  104,  672,   10,   84,   40,   54,  858]),\n",
       " tensor([62, 80]),\n",
       " tensor([761,  10,  12, 126,  15,  53,  14, 540,   1, 602, 866, 162,   1,   7,\n",
       "          80,  55,  11, 201,  74, 153,  16,  96]),\n",
       " tensor([ 34,  37, 143]),\n",
       " tensor([ 51,  41, 946,  10, 121,  14,  25]),\n",
       " tensor([   2,    3,   71,  177,   55,   17, 1361,    8,   16]),\n",
       " tensor([  51,   20,    6,  579,   51,  169,  177,   12,   33,  138,   21,   47,\n",
       "           10, 1180,   14,   35,    1,    3,  412,  102,   50,    7]),\n",
       " tensor([ 62,  19,  17,  15,  38,  79, 294,  28, 188,  81, 137]),\n",
       " tensor([  25,  296,  225,   21,    7,   98,   10,   17,   55,  134, 1142,   10,\n",
       "            2,   24,  100,  292,    1,    7]),\n",
       " tensor([ 41,  58,  19, 169,  21,  19,  60,   3,  71, 307, 177,  29,  39, 483,\n",
       "         320, 171,   1, 483]),\n",
       " tensor([  51,    1,   44,   59, 1178,  321,  118,   68,   15,   16,   72,    4,\n",
       "           57,  209,    4,  723,   53,  580,   20,   17,  104,   67,  433,    2,\n",
       "           33]),\n",
       " tensor([ 12, 650,   1,  21,   5,   1,   3,  56,  27, 416, 941, 111,  21, 835,\n",
       "          85, 201]),\n",
       " tensor([ 93, 551, 795,   9,  26,  51,  20, 132,   6,   8, 157,  37,   3, 182,\n",
       "           5,  93,  29,   7,  15,  15,   3,   8,  16]),\n",
       " tensor([  4,  55,  11,   5,  25,  35,  26,   2,  41, 582,  21,   3, 475,  14,\n",
       "         565]),\n",
       " tensor([105,   1, 132,  66,   5,  15,  38,   5]),\n",
       " tensor([ 32,  41, 390,  12,   2,  31, 119,   1, 437,   3, 170,   9,   6, 545,\n",
       "         763, 474, 167,  20,  33, 278]),\n",
       " tensor([ 93,   6,   5, 140, 101, 416, 393, 272,  10, 414,  83, 463,   8,  11,\n",
       "          10,   4,  31,  15,  59, 772,  83, 386,   3]),\n",
       " tensor([  7,  98,   2, 383]),\n",
       " tensor([  66,   19,    4,   12,    1,  139, 1362,    8,  277,   21,   33,  532,\n",
       "          292,  108]),\n",
       " tensor([377,   1, 665, 262, 137, 524, 125,  11, 146, 168,   7,  15,  94,  90,\n",
       "         604]),\n",
       " tensor([ 896,    8,   20,   38, 1061,    5,   27,  265,   25,  229,  511, 1025,\n",
       "          156,    1]),\n",
       " tensor([ 10,  11, 146,  12,   2, 399,  49]),\n",
       " tensor([   2,    5,   27,  265,    1,  355,  611, 1242,    4,  132,   33,  947,\n",
       "           24,  265,  457,    2, 1296,  102,  129]),\n",
       " tensor([428,  71,  73, 995,   2,   3,  71,   9]),\n",
       " tensor([   5,   71, 1062,    1,  523,    3, 1530,    9,    5,  110]),\n",
       " tensor([147, 276, 152,  50,   5,  10, 724, 257, 948]),\n",
       " tensor([   1,  238,    1,    6,  494,  307,    1,   15,   25,  576,   10, 1026]),\n",
       " tensor([ 19,  46,  55,  17,   9,   3,   5,  53,  14, 518, 501,  73, 312, 739,\n",
       "           2, 595,   2, 595, 604]),\n",
       " tensor([287, 182,   5, 583,  10,   2,  33,   7, 120,  96,  60, 401,  50,  45,\n",
       "           2]),\n",
       " tensor([ 66, 115,   2, 222,   8,   3,  36,  32,  89, 160,  41,   4,  29, 238,\n",
       "           1,   6, 494, 307,   1,  15,  25, 793,  53]),\n",
       " tensor([  19,   54,   46,  110, 1531,  237,   24,   77,    2,  132,   86,   31,\n",
       "          110,   72,    6,   73,  272,  604]),\n",
       " tensor([ 41,  67,  51,  47, 330, 275,  37,  71, 566,   1, 417,  26,  20,   9,\n",
       "          11, 190,   5,   1,   2,   4,  69, 281,   1, 149,   3, 696,  13, 417]),\n",
       " tensor([1521,    1,   18,  162,   51,   20,    6,  209,   74,  457,    4,    2,\n",
       "          385,   21,    6,  284,  160,  188,    4,   44,    1,   11,  961,    1,\n",
       "          598,  291]),\n",
       " tensor([ 80, 123,  28, 272,   4,  57,   1, 104,  53,  67,  11,  46,  29,  55,\n",
       "          17,   1,  11, 233, 144,  13,  35,  85,  67,  17,  45,  57,   1,  44]),\n",
       " tensor([666,  63,   7]),\n",
       " tensor([115, 598,   3, 291,  26,  12,  22, 112,  14,  42,   8, 210,   2,  72,\n",
       "         147, 112,   1,  19,  25]),\n",
       " tensor([ 472, 1363,  781,   18,   97,  414,    1,  238,    1,  761,   36,   32,\n",
       "           61,    2,  677,    1,    6, 1302,  437,   20,  130,  293,   23,   25,\n",
       "          136]),\n",
       " tensor([  34,    8, 1062,    1,  519,   11,   46,  996,   11,  295,    5,  402,\n",
       "           43,    7,  706,  122,    2,  839,   21,   22,  739]),\n",
       " tensor([ 63,   7,   8,   3,  10,  14, 906, 278,  35,  37,  47, 102]),\n",
       " tensor([  36,   32,    2,    7,   12,   11,  134,  336,    7,   12,  125,   11,\n",
       "          146,   10,   17,    2, 1027,    1,  246,    1,    6,  513]),\n",
       " tensor([ 487,   23,  876,  122,   12,  425,  293,  188,   60,   72,    2,    5,\n",
       "           23,  176,   28,  227,   95, 1514,   68, 1042]),\n",
       " tensor([ 17,   2, 499,   5,  30,  51, 611, 218,  13, 121,   4, 107,  11, 909,\n",
       "         121,  14,   3, 123,  28,  40]),\n",
       " tensor([ 12,  20, 359,   1,  11, 414,   8, 284, 160,  19, 290,  96,   3, 941,\n",
       "          36,  32, 160,   8, 604]),\n",
       " tensor([ 62,  31, 145,   9,  15, 415,  46,   1]),\n",
       " tensor([168,   7, 210,  16,   9,   3, 960,  74,   3, 194,  10,  89,  88,  16,\n",
       "         228,   4,   2,  88, 302,  12,  17,  78, 304]),\n",
       " tensor([ 63,   7,   2,  70,   8, 176,  73,   1, 674,  25,  49]),\n",
       " tensor([ 37, 207, 128, 262, 118,  98, 663,   2, 260,   8, 649,   9,   6,   5]),\n",
       " tensor([1532,  709,  696,  443,   43,  327,  124,    8,  116,  110,    1,  161,\n",
       "          233,  118,   96,   62,  298,  175,  118,  531,  336]),\n",
       " tensor([695, 580,  26,  65,  94, 149, 499, 206, 213, 300,  73, 418,  45,  30,\n",
       "           2, 208, 211, 499, 204, 397,   8,  24]),\n",
       " tensor([958,   6,   4, 131, 180,  11,  46,   2, 125,  87,  17,   2, 143,   9,\n",
       "           1, 147, 111,  13,   3, 437,   4,   2,   6, 348,  36]),\n",
       " tensor([  41,  173,    7,  199,  187,   10,  141,   16,    6, 1437,  108,  270,\n",
       "          604,   52,   19,  213]),\n",
       " tensor([  25,   45,  958,    2,    6,  170,    1, 1062,  501,   14,    3,  156,\n",
       "            9,   83,  121,   17,  139,    1,    2,  599]),\n",
       " tensor([867,  52,  88,  56,  17,   2,  35,   8, 157,   1,  44, 140,  10,   1,\n",
       "         495,  23,   3, 111, 130, 357,  52,  56,  31,  77,  15,   6, 516]),\n",
       " tensor([  78,    8,    3, 1043,  221,  104,   64,  244,    1,  139,    8,   24,\n",
       "            7,  605,   31,  119,  680,   61,  391,  681,  585,   78]),\n",
       " tensor([ 34, 511,   4, 297,  24,  26, 221,  77, 373,  95, 391, 497,  46,  78,\n",
       "          58,  12,   7,  19,  21,  17, 221, 266, 119,   3, 332]),\n",
       " tensor([ 90,  36,  32, 154, 126,  45, 225,  62,   7, 329,   6, 349, 120, 106,\n",
       "         182]),\n",
       " tensor([  65,   69,    6,    5,   37,  322,    1,   40,    8,   92,    5, 1438,\n",
       "          164,  416,   28,   27,   30,   60,    3,   50,    2,  202,  144]),\n",
       " tensor([ 34,   8,   3, 475,  14,  39,  10,   3,  29, 185,  27,   3, 761, 398]),\n",
       " tensor([ 65, 172,  90, 499,  12,  12, 147, 138,   9,  11, 331,   5]),\n",
       " tensor([  4,  77,  95,   1,  96, 235,  44,   9, 188, 391, 982,   5, 226]),\n",
       " tensor([  67,    4,  139,    7,  396,   10,  756,    8,   11,  146,    1,    2,\n",
       "          507,   60,    4,  243,   66,  122,    4,   12,    1,   43,  123, 1089,\n",
       "           73,    8,   65, 1028]),\n",
       " tensor([  41,  413,  233,    8, 1355,  135,   26,  397,   95,   31,    2,    2,\n",
       "           48, 1533,  121,  169,   12,   54,  445,  621,   41,   31,   68,  110,\n",
       "          443]),\n",
       " tensor([  7,   2,  71, 114,  75]),\n",
       " tensor([1524,   59,   46, 1439,   46,  331,  140,  207,   46,  486,   58,    2,\n",
       "           18,   10,   66,    2,    4,  725,    1,    6,  513,   39, 1055]),\n",
       " tensor([ 31,  84,  95,   1, 323,   7,  12,   6, 372, 163,  74, 528, 630,  36,\n",
       "         213, 314]),\n",
       " tensor([  22,  274,   37,  110,   56,    1,    8,   60,  253,  178,   13,   92,\n",
       "            5,   15,    8,  123,  136,  563,  271,  828, 1182,  207]),\n",
       " tensor([  25,    2,   20,    6, 1440,  182,  160,    8,   58,    2,   18, 1440,\n",
       "          182,   75,  144,   13]),\n",
       " tensor([666, 161,  54, 146]),\n",
       " tensor([  3,  97,  24, 849,  56,  23,   3,  76,  82,  94, 138,   9,  77,  12,\n",
       "           1,   2,  81,  49, 194]),\n",
       " tensor([   4,  143,    7,   33,  379,  309,   74,  359,  667,  266,   22, 1440,\n",
       "          182,  318]),\n",
       " tensor([ 34,  45,   7,  98,   2,  15,   3, 462]),\n",
       " tensor([148, 132,  58,  31,  29,  19,  31,   2, 358, 408,  14,  25,  50,   2,\n",
       "         358,  34,   8,   3,  39]),\n",
       " tensor([166,  26,  69,  30, 195, 298,  12,  20,  12, 184, 146,   8, 123,  73,\n",
       "         386]),\n",
       " tensor([ 58,   2,  24,  44,   1,  19,   8,   7, 228,  37,  95,   7, 296,  19]),\n",
       " tensor([  4, 143,  13,  11, 868,  63,   7]),\n",
       " tensor([   7,    2,  245,   56,  413,  516,    8, 1355,  135,  443]),\n",
       " tensor([1355,  135,   15,  595,  922,   80,   22, 1303,    9, 1304,    3,  126,\n",
       "          506,  107,    6,   73,   14,  418,   10]),\n",
       " tensor([166,   4,  19]),\n",
       " tensor([   4,   81,   78,    3, 1305,   80,   18,  314,  144,  104,  491,    1,\n",
       "           39,   56,    6,   41,  390,   22, 1019,    8,    6,  233,   85,  425,\n",
       "           85,  249,  443]),\n",
       " tensor([   9,  243,  176,   28,   92,    5,  217,  392,   30,  127,    9,    3,\n",
       "          382,  361,   52,  347,    6,   50,   27,    3,   76, 1060,   36]),\n",
       " tensor([ 75,   2,   3, 935,  90,  52,  12,  22, 488,  58,  52,   2,  19, 829,\n",
       "         604]),\n",
       " tensor([  34,  424,  119,    1,  256,   25,  179,   54,   36,  213,  314,    2,\n",
       "          611,  359,    1,  408, 1183,  292,   73]),\n",
       " tensor([ 31,  37,  47,  21, 182,  27, 732,   1, 943, 196,   5, 154,   3,   2,\n",
       "          20, 172, 374,  20, 172, 759]),\n",
       " tensor([ 65, 740,  86,   6, 916, 572, 599, 205, 263, 139, 123,  35,  85, 103,\n",
       "           9, 665,  14, 520, 108]),\n",
       " tensor([  23,   65,   90,   68,  517,   62,    1,   50,  567,   49,  116,  291,\n",
       "           22,  516,   13,  426,    8,  381, 1441,  112,    1,   44]),\n",
       " tensor([ 133,  175,   87,    6,   59,   28,   40,    5, 1442,   21,   22,  233,\n",
       "           23,    3,  437,   14,    3,  230,  111,  758]),\n",
       " tensor([438,  66,  19,   3,   5,  27, 602,   1, 110,  41,  92,   5,  10,   3,\n",
       "          71,  78,   1, 602,  41, 227,   4, 631,  15,   1, 227]),\n",
       " tensor([ 125,   46,  510,    2,  399,   97,  629,   42,   61,   48,   11,   46,\n",
       "           60,  161,   30,  613,   16,   23,  236, 1028,  443]),\n",
       " tensor([   3,  135,   23,    3,  586,   12,    2,  151,  316,   86,    7,   29,\n",
       "          132, 1144,    2,   72,    5,    1,  732,   10,   69,  127,  144]),\n",
       " tensor([ 31,   1, 323,  25,  74, 153,  56,  96,  67,   7,  57, 553,   4,   2,\n",
       "         286, 281,   1,  11,  83, 340]),\n",
       " tensor([ 58,  35,  19, 105,  13, 293,   8,   5,  22,  27,   1, 514,  99]),\n",
       " tensor([100,   1,  96,   7,  45, 293,   3, 682,   8, 964, 175,  87, 664,   9,\n",
       "         338,   5]),\n",
       " tensor([162, 143]),\n",
       " tensor([1443,   15,   16,    1,  897,  202,   40,   64,   73,   21,    7,  135,\n",
       "           65]),\n",
       " tensor([ 67,  65,  94,  18, 193,   2,  37,  20,   3,  28,  40,   4,  21, 287,\n",
       "          71,  14,  11, 133,   5]),\n",
       " tensor([   5,   76,   10,   88,    4, 1534,   55,   17,    9,    1,    3,    5,\n",
       "           53,   14,  602,   10,  189,   12,    1,   43,    8,    3,   71]),\n",
       " tensor([ 167,    3,    2,   33,   10,   17,  145,   95,    6, 1444,  181,  187,\n",
       "            3,  764,   13,    3, 1222]),\n",
       " tensor([ 26,  34,   8, 222]),\n",
       " tensor([ 125,   46,   38,   79,    5,   42,  915,  372,  182,  193,   10, 1445,\n",
       "            7,  301,   17]),\n",
       " tensor([ 166,  206,   55,   24,  825,   94,  459, 1306,  206,   91,    3,  697,\n",
       "           24,   51,  151,  107,   11,  146,  231]),\n",
       " tensor([  51,   12,   21,  263,   61,  260,   13,  855,    1, 1428,    4,   12,\n",
       "            1,  139,   33]),\n",
       " tensor([ 13, 355,  43, 327, 124,  87, 164, 366, 110, 188,  76, 734, 178,   5,\n",
       "         241,  82, 100, 762,  10, 997, 450]),\n",
       " tensor([199,  16,  78,  74,  10, 220, 162,   7,   3, 430, 121, 302, 631,  20,\n",
       "         528,  11, 134, 336]),\n",
       " tensor([  7, 172]),\n",
       " tensor([  2,  11, 991,  75]),\n",
       " tensor([  7, 542]),\n",
       " tensor([ 31,  57, 157, 144, 667,  45,  52,  55,  17,   9,  99,   5]),\n",
       " tensor([  97, 1535,   49,   11,  174,   30,   68,  274,    5,   10,  209,  259,\n",
       "            8,   66]),\n",
       " tensor([  54,  418,   44,    1,    2,  605,  236,  123,   73,   14,    3,   91,\n",
       "          283,    8,   59,   14,   56,    2, 1274,  423,   14,  681,    5,   29,\n",
       "            7,   39]),\n",
       " tensor([ 66,  77,  52,  55,  16, 528,   6, 516]),\n",
       " tensor([ 42, 172,  26, 124,  43, 328, 965, 107, 278, 848]),\n",
       " tensor([  29,    7,  222,   18,   98,   21,    5,    1,  655,    1,   43,    8,\n",
       "           56,    1,   15,  137,    6,  338,    5,   27,  426, 1088,  595,   74]),\n",
       " tensor([  2,  69,  43,   1, 161,  53,  18, 267,   2, 104, 491, 408, 707,  80,\n",
       "          12,   1,  43,   1, 142, 710,   1,  15,   1]),\n",
       " tensor([   8,   33,  227,  253,    4,  180,    6,   42,    2,  166, 1536,   10,\n",
       "         1230,  279,  171,   73,  388,  354,  209]),\n",
       " tensor([  4, 297,  34]),\n",
       " tensor([106,   4, 222, 177,  29,   4,  42,   1,  15,  25, 285,  16, 375,   1,\n",
       "         117,  55, 262,  90,  89, 160,  74]),\n",
       " tensor([1184, 1184, 1184,  923,    9,    3,  382,    8,  101,   59,   28,   23,\n",
       "           44,    1,  107,   11,  909,   23,   39,   74,  861]),\n",
       " tensor([  65, 1307,    8,    7,    1,    6,    5,  102,  363,   83,   24,    4,\n",
       "          122,   11,  378,    8,   18]),\n",
       " tensor([148, 741, 287,  97, 188, 291,  52,   2, 742,   1,  39,  21, 552, 525,\n",
       "          66, 538, 103,  35,   1, 323,  42]),\n",
       " tensor([823,   4,  68,  43,   1,  93,  11, 108,  30,  63, 203,   6, 509]),\n",
       " tensor([ 898,  303,    4,  775,  297,   26,   60,    6, 1119,  160,   14,   56,\n",
       "            2, 1040,  333,   28,   14,   35,   10,  827,   38, 1446,   17,  322,\n",
       "           95]),\n",
       " tensor([ 253,   38,   79,   10,    4,   15,  141,    2,   58,  225,    1, 1308,\n",
       "           42,   12,    1,   93, 1095,   75,   61,  496]),\n",
       " tensor([ 148,  781,   18,  635,  193,   21,  741,   18,  315,  385,    6, 1275,\n",
       "         1243,  342]),\n",
       " tensor([ 148,    3,    2,  674,  917,    7,   98,    2,  131,  100,   23,    3,\n",
       "          465, 1123,   58,   45,   91,   60,   45,  118,   98,  652]),\n",
       " tensor([  11,  634,    2,   37,  103,   14, 1447,   51,    6,  916,  182,  572,\n",
       "           17,    2,    6, 1360,  207,   90,  206,    3]),\n",
       " tensor([   7,   98,  662,    1, 1537,   16,   13,  539]),\n",
       " tensor([  74,   39,    4,    2,   13,    6,  176,  244,  401,  579,   12,   33,\n",
       "         1175,  454,  318,   57,    1,  282,  579,    1,  174]),\n",
       " tensor([  18,  216,  940,    6,  152, 1282]),\n",
       " tensor([  34,    8,   49,   54,    2,  107,    6,  354,   73,   14, 1528,  158,\n",
       "            1,   18,  165,  314, 1244,   23]),\n",
       " tensor([  4, 254,  41, 172]),\n",
       " tensor([  97,   39,    3,  307,   13,  764,   14,   16, 1448,   49,   21,  157,\n",
       "           10,  116,  997,  450,    3,   98,  884,   16,    2,   86,   86,    4,\n",
       "            2]),\n",
       " tensor([ 201,   23,  355,    2,    9,    3, 1449,  215,   50,  106,  105, 1176,\n",
       "            2,  661,   81,  137,   61, 1442,   13,  417,  595,  404]),\n",
       " tensor([ 20,  24, 220,  12,  11, 231]),\n",
       " tensor([ 166,   19,  598,    6,  291,   86,  462,   86,    3, 1185,  313,  312,\n",
       "           11,   46,    9,   17,   15,   33,  141,   24,   65,   26,   20,    8,\n",
       "         1028]),\n",
       " tensor([ 33, 488, 842, 366, 134, 434,   1,  96,  60,  52,  91,  55,   3]),\n",
       " tensor([ 40, 121,  52,  12,   1, 877, 165, 765, 131, 800, 515,  32,  73,   8,\n",
       "          25]),\n",
       " tensor([ 66,  88,  56,   5,   2,  40, 116,  88,  56,  65,   9,  35, 106,  21,\n",
       "         327, 124,   1,  84,  82,  65, 338, 203, 211]),\n",
       " tensor([166,  13,  11, 474,   2,   3,  46, 120,  55,   3,  50,  23, 518]),\n",
       " tensor([212,   2,  11,   5, 270]),\n",
       " tensor([  92,    5,    1,  435,   92,    5,    1,   20,  130,   15,  217,    3,\n",
       "         1309,   24,    2,  105,   46,  386]),\n",
       " tensor([ 12, 444, 106, 153,  16, 252,  84, 180, 115, 154,  47,  21, 157,  10,\n",
       "          20,  12, 126,  90,  75]),\n",
       " tensor([ 166,    4,  598,    6,  291,   61,  254,    1,  280,  102,  146,  102,\n",
       "          404,   86,    4,   12,    1,  520,  734,    1,   44,    1,  495,   61,\n",
       "           22, 1450]),\n",
       " tensor([  46,    2,    2,  519,   92,    5,  248,  217,  651,   50,  397,   95,\n",
       "         1096,  263,  190,  255]),\n",
       " tensor([  5, 241, 120, 869,  16,  11,  10,  20, 444, 105,  49,   9,  16,  58,\n",
       "         109]),\n",
       " tensor([519, 214, 661, 252, 998,   9,  64, 861,  75,   5,   2,  25,   6]),\n",
       " tensor([ 87,  54, 313,  10, 107,  59, 295,   5,  31, 700, 140, 899, 145,   1,\n",
       "          54,  10,   6, 374]),\n",
       " tensor([1245, 1364,    1,    3,  632,   10,    7,   98,   44]),\n",
       " tensor([ 127,   23,  440, 1274,   33,   28,   87,  250,   82,  504,  252,   26,\n",
       "           22, 1310,   60,   31,   45,  110,   29,    7,   39]),\n",
       " tensor([ 41, 167,  17,  17,  37, 437,  72, 178,   9,   4, 134,   8, 782,  33,\n",
       "         325,  73,  10,   6, 427, 121,  14,  25]),\n",
       " tensor([ 55,   3, 263, 622,  45,  47, 330, 142,   8, 464, 124,   8,   3, 156,\n",
       "          35, 154]),\n",
       " tensor([ 34,   8,   3,  65,   2,   6, 839, 909]),\n",
       " tensor([  4, 280,  11, 146,  24, 266, 145,   1,   2, 110,  13,   3, 394,  60,\n",
       "           4, 243,  51, 222,   8,  64, 486, 135,   1,   2, 209]),\n",
       " tensor([ 210,  722,   12,  277,   10, 1451,  906,   26,   22, 1452,    4,   84,\n",
       "           15,   17,   62,   29,    4,  260, 1451]),\n",
       " tensor([   2,   22,   71,  583,    3,   10, 1145,    3,   50,    4,   37,  222,\n",
       "            3,  135,   13,  179,  470,   16,  212,    3,   50,    2,   44]),\n",
       " tensor([208,  76,  91, 176,  40, 130,   3, 164, 180,   3,  75, 305]),\n",
       " tensor([ 51, 151, 946,  10,  12, 538,  59,  73,  30, 158,   1,  18, 994, 870]),\n",
       " tensor([504,   2, 252,  26,   7, 313, 109, 210,  10,  81,  11,   5, 239, 137,\n",
       "           3, 311, 167,  37, 404, 183, 135, 210]),\n",
       " tensor([  65,    2,  333,   73,   10,  524,  245,   22,  185,   41,    4, 1538,\n",
       "          372, 1168,  102,   76,   97,    2,    3,   30]),\n",
       " tensor([298,  34, 145, 546,   1,   2,  78,   9, 499, 142,  12,   6, 114,   5,\n",
       "          49,   1]),\n",
       " tensor([  42,    1, 1539, 1016,   13,  949,   14,   48,   35,   61, 1540,   43,\n",
       "            1,  105,  910,  528,  550,  228,   35,  538, 1026]),\n",
       " tensor([ 65,  81, 123, 197,   8, 515, 213,   1, 359,   1, 585, 414,   6, 209,\n",
       "           8, 277,  20, 104, 212,  29,   4,  15,  33, 210]),\n",
       " tensor([   4,  242,   18, 1063,   15,   16,  140]),\n",
       " tensor([ 167,  453,   28,   70,    1,   93,  194,  117,    1,  280,   33,  492,\n",
       "           60, 1311,  966,  520,  363]),\n",
       " tensor([  99,    2,   20,   18,  591,   64,  168,   12,    2, 1428,  102,   71,\n",
       "           76,   97,  986,  500,  175]),\n",
       " tensor([ 58,   2,   3, 494, 329,  21,   3,  40,   9,   5, 499,  27, 435,   1,\n",
       "         791]),\n",
       " tensor([ 27, 243,  22,  97,  31, 143,   1,  10, 102, 123, 499, 271,   2, 247,\n",
       "          10, 920]),\n",
       " tensor([ 214,  870,  106,   90,    2,   95,   47,   33,  844,  620,   22,  508,\n",
       "          262,   86,   33, 1056,  967]),\n",
       " tensor([337,  14, 628,  14, 214, 870,  40,   5, 101,   3, 128, 197, 611, 127,\n",
       "           9,   3, 382,  23,   8, 101,  33,  28]),\n",
       " tensor([417, 214,  57,  86,  51, 922,  14, 127,   9,  50]),\n",
       " tensor([704, 201, 145,  95, 220,  15, 140, 231, 114, 360,   2, 919,  10,  44,\n",
       "           8,   6, 361]),\n",
       " tensor([900,   2, 670, 648,  18, 493,   2,  10,  69,   2,   9]),\n",
       " tensor([  3, 722,   1,  76,   2,   8,   3, 186,   5,  10,   3,  71,   1,  54,\n",
       "          76,   2,  44,   1, 417]),\n",
       " tensor([ 29,   7,  88,  16,  62,   1, 598,   6, 291,   8,  24,  12,   1,   2,\n",
       "         520]),\n",
       " tensor([  9,   3, 331,   5,  27,  72,   2, 176, 182,   5, 150,  23,  76,  10,\n",
       "          20, 924, 303,  50,   1, 150]),\n",
       " tensor([  31,   19,    4,  284,    7,    1, 1312,    6,  484,  372,  163,   21,\n",
       "           36,   32,   26,   77,  109,   17,    6, 1097]),\n",
       " tensor([ 499,   10,  587,  230,  871,   53,   20,   85,   26,   71, 1453]),\n",
       " tensor([  2,  70, 205,   1, 598,   6, 628]),\n",
       " tensor([  4, 143,  33, 141,  80,  11,  90, 163,  10,   7, 143,  78,   6, 185,\n",
       "         237, 147, 370,  66, 220, 120,  47,  21,   7, 106]),\n",
       " tensor([  11,  738,  110,  200,    9,    5,   99,  585,   21,    6, 1049,   83,\n",
       "           19,  290,  161,   17]),\n",
       " tensor([144,   2,   3, 108, 318,  74, 209,  11, 263, 283]),\n",
       " tensor([  2, 383,  52, 125,  54,  10, 388,  56,   1, 149,   6, 664,  82,  65,\n",
       "           1, 149,   6, 460,  83]),\n",
       " tensor([63,  7]),\n",
       " tensor([1186, 1186,  965,  159,    8,    7,    1,   70,   54,   32,   31,  245,\n",
       "          308,  981,  172]),\n",
       " tensor([ 57, 103, 239,   9,  24,  31,  12, 114,  20, 816,  31, 308, 981, 192]),\n",
       " tensor([  4,  84, 213,  24,   6, 430, 240,  16,   6, 409, 493,   9,  18,  18,\n",
       "         352,  61,   1]),\n",
       " tensor([  19,    7,   12,   94,    5,   21,  581, 1504,   27,    1, 1288,  470,\n",
       "            3,  587,   14,  883,  208]),\n",
       " tensor([   3,  165,  283,    2, 1160,    8,  964,  366,   74,  132,  235,    3,\n",
       "          264,   14]),\n",
       " tensor([797,  46, 291, 135, 286,  12,  11,  46,  26,  66,  19,   4, 743, 801,\n",
       "           5, 681,   5,  37, 226]),\n",
       " tensor([ 34, 148,   2,  13, 919]),\n",
       " tensor([ 34,   1,  23, 602,   8, 468,  36,  32, 161,  11, 720,  46, 125,   9,\n",
       "          55, 200,  73]),\n",
       " tensor([123,  73,  92, 219,  10,  11,  46,  12,  20, 110, 518, 511,   2,  20,\n",
       "          39,  23,  64, 389,  88,  16,   6, 368, 841]),\n",
       " tensor([ 365,   60,   19,  341,    5,   27,  539,    1, 1013,   84,  132,   94,\n",
       "           73,   13,  883]),\n",
       " tensor([ 95, 968]),\n",
       " tensor([ 29,   7, 837,  21, 982,   5, 308,   8,  53,  14, 265, 142,  23]),\n",
       " tensor([  62,   19,    7,  125,    6,   76,  105,   46,  656,    1,  355,  341,\n",
       "            5, 1082]),\n",
       " tensor([ 743,  801,    5,    1,  355,   76,  105,   46,   10,  524,  125,   17,\n",
       "           23, 1098,  681,    5,  226,   13]),\n",
       " tensor([ 166,   34,   41,  173,   31,  132,    7,  238,   21,   54,  174,  314,\n",
       "           10, 1541,    3,    5,   34]),\n",
       " tensor([ 948,    9,   14,    3,  764,  845, 1046,    9,  150,  120,  323,   24,\n",
       "          188,    4]),\n",
       " tensor([ 29,   7,  74, 199,   8,   6, 162,   9,   6,  46]),\n",
       " tensor([   1,    2,  924,    9,   11,  146, 1305,    4,    2,    3, 1064,    5,\n",
       "            1]),\n",
       " tensor([467,   2, 114, 550]),\n",
       " tensor([  4, 110,  33, 734,   9,   3,  50,  10,  12,   2,  42, 788, 313,  10,\n",
       "          22,  71,  12,   2, 195,  29,   7,  74,  39]),\n",
       " tensor([276, 220,  93,  11, 171,  25,  94, 186, 112,   7, 119,   1, 842, 506]),\n",
       " tensor([235,   6, 100, 160,   1,  42,   1, 238,  21, 169,  80,  62,   7,  29,\n",
       "         256,  58,   7,  19,   1, 486, 135,  10, 184, 146,   9, 814]),\n",
       " tensor([ 63, 118, 516,   8,   3, 230, 340,   1, 151, 316,  36,  32, 267, 899,\n",
       "           4,  63, 200,  29, 118,  59]),\n",
       " tensor([1542,   11,  999,   46]),\n",
       " tensor([148, 169, 122,  88,  24,   1,   3, 271,  23,   3, 435, 165, 291,  69,\n",
       "          22,  46]),\n",
       " tensor([499, 571, 366, 144,  94, 488,  67,   4,  29, 149,   3, 248, 696,  23,\n",
       "          47, 499, 142]),\n",
       " tensor([1187,   10,  107,   54,  295,    5,    2,   37,   88,   24,   11,   46,\n",
       "            2,    9,   65,  112,    1,   67,    7,  117,   12,  135,   24,  213]),\n",
       " tensor([  13,  471,  515,   60,  515,   81, 1365,   14,  483,   23,   76,   87,\n",
       "           97,  886,   68,   39,  268]),\n",
       " tensor([  31,   37,  119,    1,   44,  140,  231,   66,   19,    7,   38,    5,\n",
       "            3,  128,  566,   14,   54, 1543,   54]),\n",
       " tensor([1445,   10,  247,   97,  102,    5,   23,  718,  135,   20,  595,   25,\n",
       "            2]),\n",
       " tensor([ 226,   13,  421,   23,  639,  128,  230,    3,  333,   28,   14,  134,\n",
       "            2, 1099]),\n",
       " tensor([ 452,    7,   38,   79,   54,    5, 1246,   10,  116,  149,   54,  140,\n",
       "            1,  602,   27, 1247,    8,  543,   93,  126, 1543,   54]),\n",
       " tensor([ 12,  55,  11,  22,  47, 622, 186,  75,  43,  60,  92,   5, 923,  13,\n",
       "         602]),\n",
       " tensor([  41,    3,  329,   19,  118,  385,  270,    8,  827,   85,    2,    4,\n",
       "            9,    3, 1213,   23]),\n",
       " tensor([ 266,    3,  697,   24,    4,   12,    1,   44,  194,    1,  138,    6,\n",
       "           42,   10,  246,    1,  198, 1313,    2,   71,  100, 1248]),\n",
       " tensor([ 63,   7,   4,  47, 217, 514,  27]),\n",
       " tensor([   4,   12,    6,  679,   14,  329,   21,   18,  349,   24,   77,   82,\n",
       "         1366]),\n",
       " tensor([ 30,  58,   5,   2,  44,  60,   4,  15, 137,  50]),\n",
       " tensor([  3, 185, 319,   8,  18,  43,  58,   5, 318,   2,   7,   9,  41,  31,\n",
       "          29, 145, 217,   3, 138, 167,  62,  77, 448]),\n",
       " tensor([ 18,  36,  32,   2, 315, 123,  28,  22,   5,  10, 133,  28,  92, 219,\n",
       "          69,  22]),\n",
       " tensor([ 74,   3, 883, 906, 622,   9,  18, 216]),\n",
       " tensor([435, 532, 111]),\n",
       " tensor([  63,    7,    8,  359,   41, 1188,   21,    6,  316]),\n",
       " tensor([ 445,   35,  240,  756,  124,   10,   18,   76,   97,  261,   23,  410,\n",
       "          240,   49,   23, 1430,   10,   52,   12,    1,  105,   46]),\n",
       " tensor([  97,   13,  854,  153,  327,   36,   96,   52,   68,   39,  157,  268,\n",
       "           40,    5,    1,  656, 1544]),\n",
       " tensor([ 236,   11, 1447,   24,    5,    2,  802,  486, 1544]),\n",
       " tensor([ 10,  60,  24, 206, 104]),\n",
       " tensor([  19,    7,   12,  132,   11,  379,   99,   80,    6,  522,  294, 1425,\n",
       "            4,   45,  323,   17,   67,    7,  603,   17,   30]),\n",
       " tensor([  8, 842, 108,   1, 317, 161,   6, 925,  71,   2, 551,   4, 132,  62,\n",
       "           7, 980, 969, 224,  26,  68, 149, 157]),\n",
       " tensor([  5, 243, 269, 113, 227,  26, 116,  12,  31,   1,  43,   8,  33,  28,\n",
       "           8,  54,  46]),\n",
       " tensor([ 167,   20,    3,  138,    3,  697,   24,   22,   71,  130,   42,  704,\n",
       "          629,    1,  466,    3,   46, 1367,    2]),\n",
       " tensor([ 235,    6, 1352, 1189,   19,    1,   15,    6,    5,  301,   91,   60,\n",
       "          191,  335,   71,    8,    6,  328,   10,   57,    6,  170]),\n",
       " tensor([ 63,   7,  31,   2, 636,  49,   8, 717,  31, 527,  10,  43]),\n",
       " tensor([  69,   43,    1,  323,   78,   11,    2, 1249,   27,   71,   14,   18,\n",
       "           50,   41,   77,  242,    6, 1018,  144]),\n",
       " tensor([  4,  77, 159,  67, 169, 168,  15,  16,  78,   1, 732, 231,  10,   4,\n",
       "          19,  20, 617,   1,  43, 142, 229]),\n",
       " tensor([ 85,  12, 125,  11, 907, 368, 262,  27, 368, 271,  14,  12,  82, 228]),\n",
       " tensor([ 766,  180,   24,  224,   29, 1545,    3,  880,   19,   17,   45,    2,\n",
       "           67,   52,  134,   13,   10,    3,   90,    5,  154]),\n",
       " tensor([   4,   12,    6,    5,   53,   14,  265,    9,  644,   62,  390,   13,\n",
       "         1236,   45,    7,  109,  701,   67,   38,   79]),\n",
       " tensor([  4,   2, 636,  49,   8, 717,  25,   2,   3, 156, 170,   4,   2,  20,\n",
       "         210,   9,  20, 211,  66,  25, 225]),\n",
       " tensor([ 63,   7,  81, 213,  14, 552,  10,  55,  17, 181, 167,   3, 163,  51,\n",
       "         149,   1, 293,   3, 311,   1, 161,   5]),\n",
       " tensor([  24,    2,   20,   13,  179,   21,   18,  185,  144,   10,   30,   51,\n",
       "           43,  279,  142,  229,  121,   64,    3,    5,    2, 1190]),\n",
       " tensor([   4,   81,    3, 1449,  215,  722,   13,    1,  288,  123,   73,  272,\n",
       "           17,  970,   22,  126,    3,   97,   99,   88,  198,   80,    6,  342,\n",
       "           91]),\n",
       " tensor([ 18, 316,  97,  13, 571,  39,   4,   2,  37,  53, 165, 283,  10,   6,\n",
       "         230,  14,  11,  19, 292,  21]),\n",
       " tensor([120, 907,  14,  25]),\n",
       " tensor([206, 260, 108,  91, 283,  19,  52,  20,   3, 215, 423,  24,   7]),\n",
       " tensor([ 61, 568, 430,   1,   6, 634,  11, 134, 138]),\n",
       " tensor([  4,   2, 926,  15,   9,   3,  50, 843,  15,   3, 350,   1,  17, 970,\n",
       "          51,  20,   6, 603,  11]),\n",
       " tensor([ 167, 1100,    3,  264,   17,  970,   51,  964,  650,  150,  547,   59,\n",
       "           25,    2,    6,  331,  108,  115,    2,   19,   25,    8,  333,  705]),\n",
       " tensor([ 115,  120,  163,   90,   36,   32,  478,  828,    9,  990,   10,   20,\n",
       "         1538,    2,  386]),\n",
       " tensor([ 611,    9,  150,   41,   20,   30,  105,   13,    2,  315,  193,  247,\n",
       "         1043,  146, 1221,  470, 1101]),\n",
       " tensor([640,  49, 116,  11, 108,  10, 183,  11, 332,  20, 130,  33, 465,   4,\n",
       "          45, 120,  47,  21,  18,  75, 106, 604]),\n",
       " tensor([ 12,   3,  90,  36,  25, 267,  23,  42, 915, 752,   2,  11, 165, 125,\n",
       "          10, 620,  22,  39,  26]),\n",
       " tensor([ 122,   20,  642,  108,    8,    9,   12,  315,   32,   10,  499,  193,\n",
       "          561,  512, 1218]),\n",
       " tensor([  37,   15,   27,  819,   11,   15,  556,   14,    3, 1099,   72,    2,\n",
       "         1245,    8,  133]),\n",
       " tensor([63,  7]),\n",
       " tensor([ 60,  45, 341,   5,  27, 943,   1, 514,  27, 184, 826, 399,  34]),\n",
       " tensor([ 11, 991, 112,   1, 134,  63,   7]),\n",
       " tensor([ 166,   87,   25,  480,  129,   17, 1024,    4,   29,   15,  140]),\n",
       " tensor([ 166,  337,    7,   12,  315,   36,   32,   23,  514,   10,  704, 1177,\n",
       "            6,  456,   72,   31,    2, 1021,    3,  285]),\n",
       " tensor([1134,  152,   50,   27,  573,    1,  355,   26,   22,  950, 1452]),\n",
       " tensor([  4, 598,   6, 338,  46, 628,   9, 814,  11,   5,   2,  38,  79,  10,\n",
       "           4, 120,  44, 893]),\n",
       " tensor([  3, 307,   2, 611,  76,  10,  13, 288]),\n",
       " tensor([  4,  57,  17,  72, 188, 191, 226,  41, 191,  29,  12,   3, 440, 165,\n",
       "         291, 598,   1,  12,  17, 143,  26,   3, 271,  12,  20]),\n",
       " tensor([  1,   3,  90,   4, 254,  25,   2,   3, 128,  35,   4,  12,   1,  47,\n",
       "          21,   7]),\n",
       " tensor([ 63,   7,   8,   3, 521, 185,  26,   4, 561, 162,   7, 279,   7, 199,\n",
       "          16,  86, 148]),\n",
       " tensor([  4,  57,   3,  89, 160,   1, 165, 291,  13, 288,  11, 738, 110, 200,\n",
       "          89,  10, 169,  42,  82,  52,  77, 234,  17,  72,  26,   9]),\n",
       " tensor([  4,  19,  22, 185,  78]),\n",
       " tensor([25,  2, 36, 32]),\n",
       " tensor([ 45,  20,  12,   1, 895, 917, 825, 550]),\n",
       " tensor([ 40, 324,   1, 105,  46,  23,  76, 291, 673, 723,  10, 997,   9,   1,\n",
       "         293, 673,   6,  40]),\n",
       " tensor([  7,  38,   5,  54,   5,   8,  22, 370,  61,  30,  31,  12,   2,   9,\n",
       "           3,  89,   8,  33,  28,   9,  54, 418,  66]),\n",
       " tensor([167,  18, 185,  11, 530,  78,  10,  21,   6,   7,  29,  19,  36,  32,\n",
       "           1,  18, 465]),\n",
       " tensor([  34,   65,  224,   27,    1,    1,   19,    6,  767,  431,   41,   31,\n",
       "          168,  313,  101,   13,   56,    9,   78,  842, 1095]),\n",
       " tensor([  14,  777,    4,   19,    3,   46,  122,    2,  144,  102,   30, 1044]),\n",
       " tensor([   7,    2,    3,   90,    4,   45, 1141,    7,   95,    3]),\n",
       " tensor([  2,   3,  90,  75,  13,   3, 558]),\n",
       " tensor([ 169,   57,    1,  162,   16,   10,  576,   25,  724,  582,   21,    3,\n",
       "           32,    4,  280,  315, 1314]),\n",
       " tensor([ 964,  819,  398,   91,    5, 1160,  283,  109,   16,  409,    5,   30,\n",
       "           13,  559,    3,  215,   32, 1102]),\n",
       " tensor([  4,  45, 109,   7,  71, 262,   7,   2,  26, 803,   7,   2,  23,  20,\n",
       "          19,  18, 360, 148]),\n",
       " tensor([   4,   45,   26,  181,   30,   51,    1, 1102]),\n",
       " tensor([156,  35,  47,  21, 511, 266, 128,  35,  78,   1,   8,  16, 604]),\n",
       " tensor([   4,  149,    1,    2,    6,  572,  279,  951,    4, 1062,   30,   66,\n",
       "            4,  479,    1]),\n",
       " tensor([   3,  356,    7,  168,   19,    2,  245,   16,    6,  108,   13, 1058,\n",
       "          346,   14,   37,   38,    5,   11,  174,  121,   14,   18]),\n",
       " tensor([  51,   82,    4,   55,    3,    5,   26,   21,    8, 1132,   35,   61,\n",
       "          337,   14,  946,  572,  683,  470]),\n",
       " tensor([  4, 180, 162,  77,   2, 100]),\n",
       " tensor([  76, 1023,  768,   40,  158,    1,  526,  237,  311,   82,   92,    5,\n",
       "          243,  722,   88,    3]),\n",
       " tensor([   7,    2, 1423,    3,   90,  349,    4,   12,  154,  163,    7,   12,\n",
       "          125,  169, 1029,   61,    7,  317,  213,  459]),\n",
       " tensor([ 62,  29,  18, 311, 240, 243, 722,   2, 227,  26, 482,   5,   2,  40,\n",
       "         158,   1,  92,   5, 722]),\n",
       " tensor([202,  19,  24,  23,   3, 111,  10, 363, 136,  92, 219,  65,  69,  20,\n",
       "         144,   7,  98,   2, 131, 987,  16,  99,  70,   1, 449]),\n",
       " tensor([ 444,   32, 1103,  512,  415,   14,   85,  153,    2,  103,  116,  220,\n",
       "          741,   17,  106]),\n",
       " tensor([ 131,  169,   42,   13, 1000,   10,  116,  169,  706,    1,   42,    6,\n",
       "           30,   33,   28,   92,    5,    1,   81,  137]),\n",
       " tensor([ 222,    5,  241,   58,  680,   77,    2,   61,   82,   31,  424,   15,\n",
       "          273,  597, 1522]),\n",
       " tensor([  12,    2,  508,    6, 1447,   99, 1250,  234,  631,   21,  262,  611,\n",
       "            5,   40,   68,   43,    1,   37,   15,  140]),\n",
       " tensor([490,   3, 215, 820, 170,  11, 343,   2, 381, 442,   8, 363,  28, 563,\n",
       "          35, 408, 193, 366,   2, 247]),\n",
       " tensor([161,   6, 547,  14, 135, 177, 373, 135, 103, 155, 167, 181, 511,  75]),\n",
       " tensor([867, 997,  49,  61, 252,   3, 487,  61,  20,   6, 182,  97,   1,   2,\n",
       "         161, 240,  49, 128, 113,   1, 150,  56, 298, 135]),\n",
       " tensor([63,  7]),\n",
       " tensor([ 102,    3,   35,    4,  286,   15,    1,  407,    4,  168,   12,  446,\n",
       "           21,  459, 1191,   10,  865]),\n",
       " tensor([  51,   70,    1,   15,    1,   11,  966,  431,   31,   57,  680,   37,\n",
       "           80,  949,   14, 1029,   35,  538]),\n",
       " tensor([  24,   98,  131,   12,   22,   36,   32,   12,  453, 1063, 1079,    8,\n",
       "          346,   14,   13,  864]),\n",
       " tensor([221,  12,  22, 690,  10,  17]),\n",
       " tensor([ 74,   1,   2,   6, 964, 684]),\n",
       " tensor([ 62,  29,   7,  20, 234,  11,  46,   9,  50,   1, 983,   5,  43,  13,\n",
       "         179,   1, 246,   1, 169,  80,  11,  46, 308, 122, 744]),\n",
       " tensor([ 67,  52, 942,  33, 403, 349,   4,  77,  82,  25,   2, 114]),\n",
       " tensor([   4,  180,  221,  373,   19,   20,   95,   18, 1085]),\n",
       " tensor([661,  52,   2, 222, 327, 135,   1, 137, 150,   3,  29, 508,   6, 374,\n",
       "           2,  55]),\n",
       " tensor([  65,    6, 1283,  783,  861,  457,    2,    3, 1030,  583,   21, 1251,\n",
       "          343,   10,  120,  132,  157,  106, 1546]),\n",
       " tensor([365,  98,  19,   7,  12,   6, 141, 562,  74,  34]),\n",
       " tensor([ 37, 105,  13, 106,  58,   2,   3, 308,  14,  54, 291,  17,   2,  44,\n",
       "           9,  59, 393,  21,  22,   1,  25,  31,   2, 151, 707]),\n",
       " tensor([ 11,   5,   2,  40, 158,   1, 526,  13,  10, 412,  16,   1, 107,  11,\n",
       "         201,  23, 602,   1,  29,   7,  39]),\n",
       " tensor([604, 472, 256, 138,  12,   1, 139,  11, 497, 112,   1,  87,   5,  38,\n",
       "           5, 110,  56,  13,   3, 753,  13, 656]),\n",
       " tensor([603,  11, 132, 177,   4, 104,  21,   4,  12, 120,  25,  21,  18,  75,\n",
       "         188, 582,   2,  33]),\n",
       " tensor([  19,   36,  213,   12,  141,   85,    6,   89,  267,   24,    4,   29,\n",
       "          238,   21,   31,   12,   41,  298,  138,   52,   68,    2,  478,   13,\n",
       "         1143]),\n",
       " tensor([  63,    7,    4,   29, 1454,   81,    6,  145,   74,  199,   10,  162,\n",
       "           16,   18,  454,  160,    8,  553]),\n",
       " tensor([  13,    3,  510,   14,  184,  460, 1170, 1170,   13, 1192,   52,   42,\n",
       "          861,    8,   33, 1298,    5]),\n",
       " tensor([   4,    2,  335,   59, 1184,  497,   83,    9,  123,  566,   14,  943,\n",
       "          170,  460,   83, 1055,   67,   20,  116,  369,   29,  579,   69,  127,\n",
       "           87,  967]),\n",
       " tensor([  34,    8,  921,    4,  958,    2,   20,    3,  117,  307,   13,  179,\n",
       "          177,  180,   17,    2, 1306]),\n",
       " tensor([505,   2,  43,   9, 382,   8, 121, 661,   2,  61,  31, 331,   1,  76]),\n",
       " tensor([ 68, 110,   3, 382,  76,  97, 561,   9,   6, 530, 485, 327, 124,  30,\n",
       "         485,   6, 556, 135]),\n",
       " tensor([ 167,  494,   61,  659,   18,  465,   84,  256,    3,  138, 1547,   94,\n",
       "           14,    3, 1548,  138,  115,   12,  101,    3,  433,  300]),\n",
       " tensor([  16,   27,  157,  121,   52,   77,  631,    4, 1057,   80,  157,   13,\n",
       "            6, 1368]),\n",
       " tensor([ 377,    4,   37,  692,   34,    8,    3, 1549,    1,  109,  868]),\n",
       " tensor([374,  34,   1,   8, 837,  16, 101,   3,  89,  21,   6, 165, 291, 138,\n",
       "          99, 191, 131,  44,   3, 325, 224]),\n",
       " tensor([  93,    5,    8,   59,    8,    2,  260,  442,  328,    4,   68, 1065,\n",
       "         1001,  264, 1363,   77,   12,   44]),\n",
       " tensor([505,  12,   6,  14, 126,  21,  15,  54,  46,  10,  12,   2, 109,   3,\n",
       "         358, 470,   8,   6,  73, 235,  49,  21,  24]),\n",
       " tensor([  75, 1535,  784,   10,   11,  294,  705,  401,  720,  455,    9,    5,\n",
       "            1,  421]),\n",
       " tensor([  12,    2,   43,   59,   73,    8,   11, 1300,   46,   27,   33,  111,\n",
       "          123,   28,  450,   27,   16,  383]),\n",
       " tensor([243, 396, 113, 227,   2, 257,  26,  20,  67, 994, 320, 672,  43, 269,\n",
       "         113,   8, 146,  41, 390,  35,  53]),\n",
       " tensor([   2,   19,  494, 1414,   23,  288,  115,  120,    2,   27,   15,    9,\n",
       "            6,    5,   21,   11]),\n",
       " tensor([  51,  251,   30,   26,    3,  179,    2, 1519,  135]),\n",
       " tensor([ 182,    8,  415,  980, 1048,   23,  140]),\n",
       " tensor([166,  52,  82,  17,  81, 103, 155,  33,  28]),\n",
       " tensor([ 415, 1550,  139,    1,  373,   47,   21,    7,  101,  244,  940,  148,\n",
       "           32,  155,    6, 1001, 1315]),\n",
       " tensor([377,  63, 106,   8,  18,  39]),\n",
       " tensor([ 20,   6, 348, 572, 499,   5,  27, 367,   1, 614, 449,   8,  27]),\n",
       " tensor([ 34,  12,   6, 375,  80,   3,  43,  35,   8, 165,   9]),\n",
       " tensor([  34,   37,    6,  809, 1305,    3,  214, 1104,   83,  884,  563,  186,\n",
       "          130,  357,    2,  299,    4,   91,   17,   78]),\n",
       " tensor([ 327,  124,  103,   40,    1,  253,   23,  367,   59,  519,   59,  103,\n",
       "         1441,   55,   22,  745,   45,  381,  298,   14,   56,  827,   23,  355,\n",
       "          158,    1,  107]),\n",
       " tensor([530,  49,  31, 189, 105, 413,  46,  59,  31, 105, 243, 415, 569, 291,\n",
       "           8,  54,  59, 186, 135,  46]),\n",
       " tensor([  25,  752,    2,    6,   31,  297,   18, 1191,   54,   46,  314,    2,\n",
       "          104,  491,    1,   15,   18,   46,    1,    7]),\n",
       " tensor([ 91,  55,  13,  37, 101, 123,  28,   8, 353,  24, 122,  12,  81, 501,\n",
       "         194,   4,   2,  20, 159,   3,  97, 357]),\n",
       " tensor([   5,  241,  297,   20,  328,   52,    2,  313, 1369,    1,  157]),\n",
       " tensor([  20,    1,  222,   13, 1368,    3,  162,  563,  182,  271,  563,    6,\n",
       "          152,  195,   18,  510,    2,  508,    6,    4,   38,    5]),\n",
       " tensor([148, 167, 374,  14,   7,  26,   4,  84,  12, 545,  23,  25, 264]),\n",
       " tensor([ 65,  95, 203,  70,   1,  55,  16, 623,  18,  75, 283,   8, 563, 746,\n",
       "          46, 167, 120, 914,  13,   3, 108, 247,  97]),\n",
       " tensor([ 257,   18,  311,   82,   56,   40,  102,  129,  250,   82,   43,    9,\n",
       "         1215,   71,   13,  405,  779,   71,   20]),\n",
       " tensor([ 74, 155,  23, 440, 398,   8,  39,  16,  15,   9,   6,  33, 227,   5,\n",
       "         191,  19,   3, 104, 711,  34]),\n",
       " tensor([   4,    2, 1316,   70,    1,  528,  630,   26,    3,  430,   36,  163,\n",
       "          143,   16,  729]),\n",
       " tensor([131, 123, 136,  40, 133,  76,  91,  61,   7, 150,  56, 143,  56,  78,\n",
       "          49,  61, 150,  56, 106, 204,  91,  54,   5,  29,  31,  44,  30]),\n",
       " tensor([  4,  19,   3,  44,   9,   8,  80, 327, 113, 188, 331,   1,   3]),\n",
       " tensor([867,  69,  22,  71,  39,  16, 109,  49,   9, 182, 971]),\n",
       " tensor([23, 34]),\n",
       " tensor([  60,   33,   75,  412,    3,  952,  201,  118,   77,  180,   52,   77,\n",
       "           81, 1551,  813,    1,   24,  567,   49]),\n",
       " tensor([302,  63,   7,  26,   7, 189,  39,  81, 300,  28,   1, 376,  41,   4,\n",
       "          15,   6, 379,  13,   3, 772,  14,   3, 230, 320, 373, 316]),\n",
       " tensor([  5,   2, 217,  10,  31, 334, 110, 440, 237,   2,  25,  44,   1,  15,\n",
       "          94,  90]),\n",
       " tensor([   4,    2,   88,   17,    2,  158,    1,    2,    9,  303,   47,  341,\n",
       "            1,   41,   66,   19,   17,   44,    1, 1370,   25,    2,    6,  695]),\n",
       " tensor([ 410,  124,   23,  440,  165,  291, 1552]),\n",
       " tensor([  5, 608, 126,   8,   6, 134, 170,   4,   2,  10,  57,   1,   2, 348,\n",
       "          60,   4, 226,  19,   7,  12,   3, 192,  19]),\n",
       " tensor([ 26,   4,  84, 132, 192]),\n",
       " tensor([   9,    6,  578,    1,  435,  303,   12,    2,   40,   10,    6,  466,\n",
       "            1, 1550,    5,   12,    2,   38,    5,   64,   73, 1223]),\n",
       " tensor([166,  23,  30,  78,   9,   6,  50, 106,  10,  40, 106, 158,   1, 165,\n",
       "         138]),\n",
       " tensor([  23,   58, 1553,   19,  118,   37,   38,    5,  286,   15,  133,    5,\n",
       "           58,    6,   73]),\n",
       " tensor([  63,    7,    8,   18,   18,   97,   44, 1105,   61,  609,    1,   15,\n",
       "           11, 1510,  362,  140]),\n",
       " tensor([ 84, 132,   6, 423,   1,  15,   9,  33, 227,   5,  21,  83,  22,  75,\n",
       "         260,   1,  15, 184, 175,  13, 227]),\n",
       " tensor([ 49,   1, 717,   5, 347, 333, 136, 227,  55,   5, 116, 123, 136, 658,\n",
       "          13, 367, 119,   1, 503,   9, 227, 278]),\n",
       " tensor([   4,   45,   19,  338,  165,  291,   60,    4,  226,  747,    3,   46,\n",
       "          320,  399,  217,  880,   85,  125,   45, 1016,   13,  103,  456]),\n",
       " tensor([  19,  119,   16,    1,  143,    6, 1085, 1097,   14,    3,  501,   42,\n",
       "          303,    2,   30,   23,  101,  410,  113]),\n",
       " tensor([145,  23,  25, 522, 294, 182,  75]),\n",
       " tensor([ 34, 220, 723,  49,   3, 580,  86, 462,  86,   4, 226,   4,  84,  95,\n",
       "           2,  41,   4, 254,   7,  45, 242,  11, 868,  61,  45,   2, 100]),\n",
       " tensor([ 25,   2,   3, 179,  13, 435,   1, 268, 158,   1, 129, 138,  19, 100]),\n",
       " tensor([   3,   71,  177,    4,  297,   40,    4,   84,  297,   70, 1317,   49,\n",
       "            6,  510,   24,   12,    2,   40,    1,   25]),\n",
       " tensor([ 59,  38, 351,   5,  92, 219,  97, 291, 191, 234,  16,   9,   6, 152,\n",
       "           5,  26, 116,  38,   5,  17,  15,   9,   5,  30,  40,  30]),\n",
       " tensor([ 14,  26,  25,   2, 404,  18, 593, 291,   1,   2,  36, 237,  60,  40,\n",
       "         225,  50, 127,  10,  36,   2]),\n",
       " tensor([  4, 345, 222,   8,   6, 354, 209,  26,  40,  16, 123,  28,  10, 109,\n",
       "          22, 370, 122,   2, 434,   1, 109, 259]),\n",
       " tensor([  5,   2, 378,   8,  65,  10,  31, 334, 347,   4,  12, 120,   2,   9,\n",
       "           6,   5, 212, 389, 347, 312,   6, 745]),\n",
       " tensor([377, 340]),\n",
       " tensor([ 44,   1, 972]),\n",
       " tensor([ 205,   83,  561,   12,   46,    9, 1213,   66,   84,  118, 1120,  673,\n",
       "         1105,  415,   83,   13,    9,   20, 1455]),\n",
       " tensor([958,  45]),\n",
       " tensor([ 77,   2, 316,  67,   7, 168, 445,  35, 239,   9, 445, 621,   8, 338,\n",
       "           5]),\n",
       " tensor([1193,    5,   41,  390,   25,  244, 1106,   40,  816,   59,  274, 1446,\n",
       "           92,  370,  164,   57,  495,   13, 1087]),\n",
       " tensor([114,   1, 323,  41, 173, 242,  18, 376, 397, 173, 103,  30]),\n",
       " tensor([586,  97,  23, 769, 940,   6]),\n",
       " tensor([  3,  14,   3,  46,  40, 236,  45,  72,   2,   6,  85,  45, 191,   2,\n",
       "         610,   1,  44, 449]),\n",
       " tensor([   5,   76,   97,   70,    1, 1428,   16,   27,   81, 1031,    6,   46,\n",
       "          115,  149,    8,  333,  244,    5,  164,    2,  103]),\n",
       " tensor([ 63,   7, 782,  42,   8,  86,   4, 358,  49]),\n",
       " tensor([  66,   19,    7,   98, 1535,   49,    3,  260,    1,  259,  371,   55,\n",
       "           17,  103, 1043,    8,  135,    1,   47,   21,    7,   98,    9, 1553]),\n",
       " tensor([  17,    2,    9, 1220,  773,  264,    2,    5,   90,   55,  135,   43,\n",
       "          901,  361,    7, 1216,  157,  137,   87,  150,    2,   90]),\n",
       " tensor([ 167,   41,  173,    2,   17,  275,   86,  676,   14, 1176]),\n",
       " tensor([ 58,  76,   2, 110,  27]),\n",
       " tensor([ 63,   7,   8, 921,   1,  11,  10,  19,   3, 181, 262,   4, 242,   7,\n",
       "         104,  21,  16]),\n",
       " tensor([505,   2, 144, 205,  10, 524,  38,  79,  54,   5, 442]),\n",
       " tensor([ 22, 350,   4,  43,  13, 355,  64, 881,   8, 147,   5,  87,   7, 567,\n",
       "          16,  48]),\n",
       " tensor([  29,   43,    8,   16,   51,    9,    3,  364,   70,    1,   15,    1,\n",
       "            3,   76,   87,   31,    2,  347,    1,  657,   25,    2, 1354]),\n",
       " tensor([  27,  587,   26,   51,   15,    6,  500,    1, 1519, 1030,   13,   11,\n",
       "          187,   60,    1]),\n",
       " tensor([148,  37, 183, 201,  27, 355,   1,  24, 150,  13, 113, 293, 279,   4,\n",
       "          15, 137,   3,  50,  24,  37, 226,  33,  28,  92,   5]),\n",
       " tensor([  2,  72,   6, 182, 819, 160, 115,   2,   9,  48, 458, 113,  10, 180,\n",
       "           4, 457,   2, 125,  13,  12,   6, 819, 174,  39]),\n",
       " tensor([616,   7, 130, 195,  78, 276, 167,  36,  32, 927]),\n",
       " tensor([ 65,  20,  11, 156,  35,  47,   1,   3,  56,   4,  12, 239, 145,   8,\n",
       "          95,  11,  83, 369,   9]),\n",
       " tensor([ 402,   31,    2,  211,   65,   20,  336,   26,   17,  757,   65, 1025,\n",
       "            3,  117,    5,  167,   38,   79, 1163]),\n",
       " tensor([ 17,  64, 511,  36,   2,  37, 159,   7,   8,  17]),\n",
       " tensor([ 365,   51,   47,   11, 1050,   35,   13,  288,    2,    2,   17,  434,\n",
       "           35,   19,    4,   12,    1,   11,   46,   10,    9]),\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'to',\n",
       " 2: 'be',\n",
       " 3: 'the',\n",
       " 4: 'i',\n",
       " 5: 'flight',\n",
       " 6: 'a',\n",
       " 7: 'you',\n",
       " 8: 'for',\n",
       " 9: 'on',\n",
       " 10: 'and',\n",
       " 11: 'my',\n",
       " 12: 'have',\n",
       " 13: 'in',\n",
       " 14: 'of',\n",
       " 15: 'get',\n",
       " 16: 'me',\n",
       " 17: 'it',\n",
       " 18: 'your',\n",
       " 19: 'do',\n",
       " 20: 'not',\n",
       " 21: 'with',\n",
       " 22: 'no',\n",
       " 23: 'at',\n",
       " 24: 'that',\n",
       " 25: 'this',\n",
       " 26: 'but',\n",
       " 27: 'from',\n",
       " 28: 'hour',\n",
       " 29: 'can',\n",
       " 30: 'now',\n",
       " 31: 'we',\n",
       " 32: 'service',\n",
       " 33: 'an',\n",
       " 34: 'thanks',\n",
       " 35: 'time',\n",
       " 36: 'customer',\n",
       " 37: 'just',\n",
       " 38: 'cancel',\n",
       " 39: 'help',\n",
       " 40: 'delay',\n",
       " 41: 'so',\n",
       " 42: 'call',\n",
       " 43: 'wait',\n",
       " 44: 'go',\n",
       " 45: 'will',\n",
       " 46: 'bag',\n",
       " 47: 'fly',\n",
       " 48: 'hold',\n",
       " 49: 'up',\n",
       " 50: 'plane',\n",
       " 51: 'im',\n",
       " 52: 'they',\n",
       " 53: 'out',\n",
       " 54: 'our',\n",
       " 55: 'make',\n",
       " 56: 'us',\n",
       " 57: 'need',\n",
       " 58: 'what',\n",
       " 59: '2',\n",
       " 60: 'when',\n",
       " 61: 'amp',\n",
       " 62: 'how',\n",
       " 63: 'thank',\n",
       " 64: 'all',\n",
       " 65: 'its',\n",
       " 66: 'why',\n",
       " 67: 'if',\n",
       " 68: 'cant',\n",
       " 69: 'still',\n",
       " 70: 'try',\n",
       " 71: 'one',\n",
       " 72: 'there',\n",
       " 73: 'day',\n",
       " 74: 'please',\n",
       " 75: 'airline',\n",
       " 76: 'gate',\n",
       " 77: 'would',\n",
       " 78: 'back',\n",
       " 79: 'flightled',\n",
       " 80: 'about',\n",
       " 81: 'take',\n",
       " 82: 'say',\n",
       " 83: 'seat',\n",
       " 84: 'dont',\n",
       " 85: 'or',\n",
       " 86: 'as',\n",
       " 87: 'after',\n",
       " 88: 'tell',\n",
       " 89: 'phone',\n",
       " 90: 'bad',\n",
       " 91: 'change',\n",
       " 92: 'late',\n",
       " 93: 'book',\n",
       " 94: 'any',\n",
       " 95: 'like',\n",
       " 96: 'know',\n",
       " 97: 'agent',\n",
       " 98: 'guy',\n",
       " 99: 'today',\n",
       " 100: 'good',\n",
       " 101: 'over',\n",
       " 102: 'by',\n",
       " 103: 'more',\n",
       " 104: 'work',\n",
       " 105: 'check',\n",
       " 106: 'again',\n",
       " 107: 'miss',\n",
       " 108: 'ticket',\n",
       " 109: 'give',\n",
       " 110: 'leave',\n",
       " 111: 'airport',\n",
       " 112: 'way',\n",
       " 113: 'minute',\n",
       " 114: 'great',\n",
       " 115: 'ive',\n",
       " 116: 'then',\n",
       " 117: 'only',\n",
       " 118: 'u',\n",
       " 119: 'want',\n",
       " 120: 'never',\n",
       " 121: 'because',\n",
       " 122: 'should',\n",
       " 123: '3',\n",
       " 124: 'min',\n",
       " 125: 'lose',\n",
       " 126: 'problem',\n",
       " 127: 'sit',\n",
       " 128: 'last',\n",
       " 129: 'weather',\n",
       " 130: 'even',\n",
       " 131: 'really',\n",
       " 132: 'see',\n",
       " 133: '4',\n",
       " 134: 'travel',\n",
       " 135: 'people',\n",
       " 136: 'hr',\n",
       " 137: 'off',\n",
       " 138: 'issue',\n",
       " 139: 'pay',\n",
       " 140: 'home',\n",
       " 141: 'email',\n",
       " 142: 'tomorrow',\n",
       " 143: 'send',\n",
       " 144: 'here',\n",
       " 145: 'look',\n",
       " 146: 'luggage',\n",
       " 147: 'another',\n",
       " 148: 'well',\n",
       " 149: 'use',\n",
       " 150: 'board',\n",
       " 151: 'very',\n",
       " 152: 'new',\n",
       " 153: 'let',\n",
       " 154: 'ever',\n",
       " 155: 'than',\n",
       " 156: 'first',\n",
       " 157: 'them',\n",
       " 158: 'due',\n",
       " 159: 'love',\n",
       " 160: 'number',\n",
       " 161: 'find',\n",
       " 162: 'dm',\n",
       " 163: 'experience',\n",
       " 164: 'crew',\n",
       " 165: 'baggage',\n",
       " 166: 'yes',\n",
       " 167: 'thats',\n",
       " 168: 'could',\n",
       " 169: 'someone',\n",
       " 170: 'trip',\n",
       " 171: 'next',\n",
       " 172: 'too',\n",
       " 173: 'much',\n",
       " 174: 'reservation',\n",
       " 175: 'passenger',\n",
       " 176: 'two',\n",
       " 177: 'who',\n",
       " 178: 'come',\n",
       " 179: 'line',\n",
       " 180: 'think',\n",
       " 181: 'right',\n",
       " 182: 'united',\n",
       " 183: 'keep',\n",
       " 184: 'their',\n",
       " 185: 'response',\n",
       " 186: 'other',\n",
       " 187: 'through',\n",
       " 188: 'before',\n",
       " 189: 'didnt',\n",
       " 190: 'long',\n",
       " 191: 'she',\n",
       " 192: 'aa',\n",
       " 193: 'staff',\n",
       " 194: 'online',\n",
       " 195: 'answer',\n",
       " 196: 'best',\n",
       " 197: 'week',\n",
       " 198: 'some',\n",
       " 199: 'follow',\n",
       " 200: 'her',\n",
       " 201: 'connection',\n",
       " 202: 'already',\n",
       " 203: 'youre',\n",
       " 204: 'wont',\n",
       " 205: 'since',\n",
       " 206: 'doesnt',\n",
       " 207: '1',\n",
       " 208: '5',\n",
       " 209: 'refund',\n",
       " 210: 'update',\n",
       " 211: 'sure',\n",
       " 212: 'where',\n",
       " 213: 'care',\n",
       " 214: 'system',\n",
       " 215: 'same',\n",
       " 216: 'website',\n",
       " 217: 'into',\n",
       " 218: 'stick',\n",
       " 219: 'flightr',\n",
       " 220: 'ill',\n",
       " 221: 'he',\n",
       " 222: 'ask',\n",
       " 223: 'jfk',\n",
       " 224: 'mile',\n",
       " 225: 'happen',\n",
       " 226: 'land',\n",
       " 227: 'early',\n",
       " 228: 'nothing',\n",
       " 229: 'morning',\n",
       " 230: 'night',\n",
       " 231: 'tonight',\n",
       " 232: 'hang',\n",
       " 233: 'hotel',\n",
       " 234: 'put',\n",
       " 235: 'whats',\n",
       " 236: 'w',\n",
       " 237: 'yet',\n",
       " 238: 'speak',\n",
       " 239: 'info',\n",
       " 240: 'show',\n",
       " 241: 'attendant',\n",
       " 242: 'appreciate',\n",
       " 243: 'arrive',\n",
       " 244: 'year',\n",
       " 245: 'offer',\n",
       " 246: 'talk',\n",
       " 247: 'rude',\n",
       " 248: 'air',\n",
       " 249: 'anything',\n",
       " 250: 'pilot',\n",
       " 251: 'rebooked',\n",
       " 252: 'down',\n",
       " 253: 'flt',\n",
       " 254: 'hope',\n",
       " 255: 'fleet',\n",
       " 256: 'fix',\n",
       " 257: 'nice',\n",
       " 258: 'fleek',\n",
       " 259: 'credit',\n",
       " 260: 'charge',\n",
       " 261: 'start',\n",
       " 262: 'thing',\n",
       " 263: 'upgrade',\n",
       " 264: 'point',\n",
       " 265: 'dfw',\n",
       " 266: 'also',\n",
       " 267: 'rep',\n",
       " 268: 'rebook',\n",
       " 269: '30',\n",
       " 270: 'voucher',\n",
       " 271: 'employee',\n",
       " 272: 'ago',\n",
       " 273: 'free',\n",
       " 274: 'cancelled',\n",
       " 275: 'class',\n",
       " 276: 'awesome',\n",
       " 277: 'wifi',\n",
       " 278: 'option',\n",
       " 279: 'until',\n",
       " 280: 'receive',\n",
       " 281: 'able',\n",
       " 282: 'add',\n",
       " 283: 'fee',\n",
       " 284: 'contact',\n",
       " 285: 'tweet',\n",
       " 286: 'finally',\n",
       " 287: 'every',\n",
       " 288: 'lax',\n",
       " 289: 'jetblue',\n",
       " 290: 'anyone',\n",
       " 291: 'claim',\n",
       " 292: 'business',\n",
       " 293: 'open',\n",
       " 294: '10',\n",
       " 295: 'connect',\n",
       " 296: 'always',\n",
       " 297: 'understand',\n",
       " 298: 'many',\n",
       " 299: 'available',\n",
       " 300: '6',\n",
       " 301: 'name',\n",
       " 302: 'id',\n",
       " 303: 'which',\n",
       " 304: 'yesterday',\n",
       " 305: 'suck',\n",
       " 306: 'phl',\n",
       " 307: 'person',\n",
       " 308: 'status',\n",
       " 309: 'via',\n",
       " 310: 'suppose',\n",
       " 311: 'app',\n",
       " 312: 'without',\n",
       " 313: 'stop',\n",
       " 314: 'team',\n",
       " 315: 'terrible',\n",
       " 316: 'helpful',\n",
       " 317: 'couldnt',\n",
       " 318: '#',\n",
       " 319: 'sorry',\n",
       " 320: 'isnt',\n",
       " 321: 'bc',\n",
       " 322: 'seem',\n",
       " 323: 'hear',\n",
       " 324: 'departure',\n",
       " 325: 'extra',\n",
       " 326: 'almost',\n",
       " 327: '20',\n",
       " 328: 'mean',\n",
       " 329: 'deal',\n",
       " 330: '1st',\n",
       " 331: 'return',\n",
       " 332: 'money',\n",
       " 333: '15',\n",
       " 334: 'havent',\n",
       " 335: 'buy',\n",
       " 336: 'plan',\n",
       " 337: 'lot',\n",
       " 338: 'delayed',\n",
       " 339: 'kid',\n",
       " 340: 'thx',\n",
       " 341: 'direct',\n",
       " 342: 'policy',\n",
       " 343: 'friend',\n",
       " 344: 'dca',\n",
       " 345: 'wasnt',\n",
       " 346: 'instead',\n",
       " 347: 'move',\n",
       " 348: 'happy',\n",
       " 349: 'company',\n",
       " 350: 'chance',\n",
       " 351: 'flighted',\n",
       " 352: 'site',\n",
       " 353: 'something',\n",
       " 354: 'full',\n",
       " 355: 'ord',\n",
       " 356: 'least',\n",
       " 357: 'though',\n",
       " 358: 'run',\n",
       " 359: 'respond',\n",
       " 360: 'job',\n",
       " 361: 'while',\n",
       " 362: 'family',\n",
       " 363: '12',\n",
       " 364: 'ground',\n",
       " 365: 'hi',\n",
       " 366: 'member',\n",
       " 367: 'sfo',\n",
       " 368: 'different',\n",
       " 369: 'allow',\n",
       " 370: 'reason',\n",
       " 371: 'card',\n",
       " 372: 'poor',\n",
       " 373: 'actually',\n",
       " 374: 'big',\n",
       " 375: 'question',\n",
       " 376: 'reply',\n",
       " 377: 'ok',\n",
       " 378: 'schedule',\n",
       " 379: 'message',\n",
       " 380: 'pick',\n",
       " 381: 'strand',\n",
       " 382: 'tarmac',\n",
       " 383: 'horrible',\n",
       " 384: 'wife',\n",
       " 385: 'provide',\n",
       " 386: 'unacceptable',\n",
       " 387: 'southwest',\n",
       " 388: 'expect',\n",
       " 389: 'everyone',\n",
       " 390: 'far',\n",
       " 391: 'his',\n",
       " 392: 'clt',\n",
       " 393: 'month',\n",
       " 394: 'snow',\n",
       " 395: 'pas',\n",
       " 396: '25',\n",
       " 397: 'feel',\n",
       " 398: 'desk',\n",
       " 399: 'break',\n",
       " 400: 'treat',\n",
       " 401: 'old',\n",
       " 402: 'oh',\n",
       " 403: 'american',\n",
       " 404: 'ridiculous',\n",
       " 405: 'ur',\n",
       " 406: 'account',\n",
       " 407: 'dallas',\n",
       " 408: 'most',\n",
       " 409: 'wrong',\n",
       " 410: '45',\n",
       " 411: 'seriously',\n",
       " 412: 'cause',\n",
       " 413: '8',\n",
       " 414: 'request',\n",
       " 415: 'those',\n",
       " 416: '7',\n",
       " 417: 'chicago',\n",
       " 418: 'vacation',\n",
       " 419: 'yall',\n",
       " 420: 'rt',\n",
       " 421: 'boston',\n",
       " 422: 'twitter',\n",
       " 423: 'cost',\n",
       " 424: 'might',\n",
       " 425: 'food',\n",
       " 426: 'san',\n",
       " 427: 'half',\n",
       " 428: 'maybe',\n",
       " 429: 'bring',\n",
       " 430: 'link',\n",
       " 431: 'destination',\n",
       " 432: '#destinationdragons',\n",
       " 433: 'past',\n",
       " 434: 'enough',\n",
       " 435: 'denver',\n",
       " 436: 'three',\n",
       " 437: 'end',\n",
       " 438: 'hey',\n",
       " 439: 'reschedule',\n",
       " 440: 'ewr',\n",
       " 441: 'bos',\n",
       " 442: 'twice',\n",
       " 443: '#fail',\n",
       " 444: 'once',\n",
       " 445: 'boarding',\n",
       " 446: 'drive',\n",
       " 447: 'mechanical',\n",
       " 448: 'handle',\n",
       " 449: 'stay',\n",
       " 450: 'away',\n",
       " 451: 'both',\n",
       " 452: 'fail',\n",
       " 453: 'spend',\n",
       " 454: 'confirmation',\n",
       " 455: 'row',\n",
       " 456: 'complaint',\n",
       " 457: 'may',\n",
       " 458: '24',\n",
       " 459: 'less',\n",
       " 460: 'car',\n",
       " 461: 'little',\n",
       " 462: 'soon',\n",
       " 463: 'together',\n",
       " 464: '40',\n",
       " 465: 'apology',\n",
       " 466: 'confirm',\n",
       " 467: 'these',\n",
       " 468: 'amaze',\n",
       " 469: 'charlotte',\n",
       " 470: 'around',\n",
       " 471: 'la',\n",
       " 472: 'pls',\n",
       " 473: 'possible',\n",
       " 474: 'guess',\n",
       " 475: 'lack',\n",
       " 476: 'nyc',\n",
       " 477: 'drop',\n",
       " 478: 'place',\n",
       " 479: 'switch',\n",
       " 480: 'awful',\n",
       " 481: 'runway',\n",
       " 482: 'depart',\n",
       " 483: 'him',\n",
       " 484: 'few',\n",
       " 485: 'count',\n",
       " 486: '50',\n",
       " 487: 'terminal',\n",
       " 488: 'idea',\n",
       " 489: 'cool',\n",
       " 490: 'during',\n",
       " 491: 'hard',\n",
       " 492: 'error',\n",
       " 493: 'price',\n",
       " 494: 'real',\n",
       " 495: 'sleep',\n",
       " 496: 'city',\n",
       " 497: 'own',\n",
       " 498: 'believe',\n",
       " 499: 'ua',\n",
       " 500: '200',\n",
       " 501: 'second',\n",
       " 502: 'checkin',\n",
       " 503: 'hop',\n",
       " 504: 'computer',\n",
       " 505: 'weve',\n",
       " 506: 'plus',\n",
       " 507: 'deliver',\n",
       " 508: 'such',\n",
       " 509: 'life',\n",
       " 510: 'process',\n",
       " 511: 'unite',\n",
       " 512: 'reach',\n",
       " 513: 'human',\n",
       " 514: 'newark',\n",
       " 515: 'cust',\n",
       " 516: 'room',\n",
       " 517: 'figure',\n",
       " 518: 'iad',\n",
       " 519: 'load',\n",
       " 520: 'purchase',\n",
       " 521: 'quick',\n",
       " 522: 'dc',\n",
       " 523: 'turn',\n",
       " 524: 'youve',\n",
       " 525: 'else',\n",
       " 526: 'maintenance',\n",
       " 527: 'watch',\n",
       " 528: 'share',\n",
       " 529: 'close',\n",
       " 530: 'head',\n",
       " 531: 'carry',\n",
       " 532: 'international',\n",
       " 533: 'thru',\n",
       " 534: 'information',\n",
       " 535: 'monday',\n",
       " 536: 'easy',\n",
       " 537: 'joke',\n",
       " 538: 'waste',\n",
       " 539: 'houston',\n",
       " 540: 'fll',\n",
       " 541: 'jet',\n",
       " 542: 'wouldnt',\n",
       " 543: 'reflight',\n",
       " 544: 'phx',\n",
       " 545: 'high',\n",
       " 546: 'forward',\n",
       " 547: 'group',\n",
       " 548: 'philly',\n",
       " 549: 'disconnect',\n",
       " 550: 'fare',\n",
       " 551: 'award',\n",
       " 552: 'everything',\n",
       " 553: 'assistance',\n",
       " 554: 'route',\n",
       " 555: '2nd',\n",
       " 556: '100',\n",
       " 557: 'vega',\n",
       " 558: 'world',\n",
       " 559: 'refuse',\n",
       " 560: 'glad',\n",
       " 561: 'cannot',\n",
       " 562: 'address',\n",
       " 563: 'each',\n",
       " 564: 'lol',\n",
       " 565: 'communication',\n",
       " 566: 'leg',\n",
       " 567: 'screw',\n",
       " 568: 'frustrate',\n",
       " 569: 'arent',\n",
       " 570: 'airway',\n",
       " 571: 'club',\n",
       " 572: 'flyer',\n",
       " 573: 'lga',\n",
       " 574: 'empty',\n",
       " 575: '#jetblue',\n",
       " 576: 'resolve',\n",
       " 577: 'busy',\n",
       " 578: 'standby',\n",
       " 579: 'child',\n",
       " 580: 'form',\n",
       " 581: 'lie',\n",
       " 582: 'disappointed',\n",
       " 583: 'between',\n",
       " 584: 'word',\n",
       " 585: 'case',\n",
       " 586: 'counter',\n",
       " 587: 'date',\n",
       " 588: 'blue',\n",
       " 589: 'mess',\n",
       " 590: 'worry',\n",
       " 591: 'fine',\n",
       " 592: 'entire',\n",
       " 593: 'ceo',\n",
       " 594: 'usair',\n",
       " 595: 'pretty',\n",
       " 596: 'either',\n",
       " 597: 'tv',\n",
       " 598: 'file',\n",
       " 599: 'loyal',\n",
       " 600: 'miami',\n",
       " 601: 'explain',\n",
       " 602: 'iah',\n",
       " 603: 'read',\n",
       " 604: '#unitedairlines',\n",
       " 605: 'ruin',\n",
       " 606: 'sw',\n",
       " 607: 'swa',\n",
       " 608: 'booking',\n",
       " 609: 'beyond',\n",
       " 610: 'force',\n",
       " 611: 'currently',\n",
       " 612: 'supervisor',\n",
       " 613: 'theyre',\n",
       " 614: 'sunday',\n",
       " 615: 'fault',\n",
       " 616: 'wow',\n",
       " 617: 'wish',\n",
       " 618: 'traveler',\n",
       " 619: 'whole',\n",
       " 620: 'theres',\n",
       " 621: 'pass',\n",
       " 622: 'list',\n",
       " 623: 'hate',\n",
       " 624: 're',\n",
       " 625: 'live',\n",
       " 626: 'rock',\n",
       " 627: 'yeah',\n",
       " 628: 'report',\n",
       " 629: 'promise',\n",
       " 630: 'detail',\n",
       " 631: 'rather',\n",
       " 632: 'situation',\n",
       " 633: 'companion',\n",
       " 634: 'post',\n",
       " 635: 'support',\n",
       " 636: 'sign',\n",
       " 637: 'win',\n",
       " 638: 'correct',\n",
       " 639: '9',\n",
       " 640: 'fuck',\n",
       " 641: 'wonder',\n",
       " 642: 'sell',\n",
       " 643: 'longer',\n",
       " 644: 'tuesday',\n",
       " 645: 'flightlations',\n",
       " 646: 'airways',\n",
       " 647: 'disappoint',\n",
       " 648: 'under',\n",
       " 649: 'drink',\n",
       " 650: 'access',\n",
       " 651: 'cabin',\n",
       " 652: 'learn',\n",
       " 653: 'storm',\n",
       " 654: 'delta',\n",
       " 655: 'bwi',\n",
       " 656: 'den',\n",
       " 657: 'b',\n",
       " 658: 'layover',\n",
       " 659: 'concern',\n",
       " 660: 'super',\n",
       " 661: 'apparently',\n",
       " 662: 'continue',\n",
       " 663: 'shouldnt',\n",
       " 664: 'safety',\n",
       " 665: 'top',\n",
       " 666: 'okay',\n",
       " 667: 'asap',\n",
       " 668: 'trouble',\n",
       " 669: '#customerservice',\n",
       " 670: 'completely',\n",
       " 671: 'probably',\n",
       " 672: 'ready',\n",
       " 673: 'space',\n",
       " 674: 'set',\n",
       " 675: 'shit',\n",
       " 676: 'part',\n",
       " 677: 'transfer',\n",
       " 678: 'record',\n",
       " 679: 'weekend',\n",
       " 680: 'compensation',\n",
       " 681: 'original',\n",
       " 682: 'door',\n",
       " 683: 'stand',\n",
       " 684: 'platinum',\n",
       " 685: 'kind',\n",
       " 686: 'usairways',\n",
       " 687: 'cross',\n",
       " 688: 'tsa',\n",
       " 689: 'sad',\n",
       " 690: 'priority',\n",
       " 691: 'husband',\n",
       " 692: 'submit',\n",
       " 693: 'future',\n",
       " 694: 'bump',\n",
       " 695: 'complete',\n",
       " 696: 'lounge',\n",
       " 697: 'fact',\n",
       " 698: 'shes',\n",
       " 699: 'amazing',\n",
       " 700: 'r',\n",
       " 701: 'notice',\n",
       " 702: '800',\n",
       " 703: 'inconvenience',\n",
       " 704: 'despite',\n",
       " 705: 'yr',\n",
       " 706: 'forget',\n",
       " 707: 'upset',\n",
       " 708: 'zero',\n",
       " 709: 'arrival',\n",
       " 710: 'pm',\n",
       " 711: 'huge',\n",
       " 712: 'nashville',\n",
       " 713: 'orlando',\n",
       " 714: 'water',\n",
       " 715: 'country',\n",
       " 716: 'mco',\n",
       " 717: 'notification',\n",
       " 718: 'several',\n",
       " 719: 'ppl',\n",
       " 720: 'daughter',\n",
       " 721: '11',\n",
       " 722: 'aircraft',\n",
       " 723: 'fill',\n",
       " 724: 'extremely',\n",
       " 725: 'write',\n",
       " 726: 'crazy',\n",
       " 727: 'wall',\n",
       " 728: 'hand',\n",
       " 729: 'expire',\n",
       " 730: 'friendly',\n",
       " 731: '2015',\n",
       " 732: 'austin',\n",
       " 733: 'choice',\n",
       " 734: 'item',\n",
       " 735: 'flightlation',\n",
       " 736: 'gonna',\n",
       " 737: 'inflight',\n",
       " 738: 'mom',\n",
       " 739: 'clothes',\n",
       " 740: 'frustrating',\n",
       " 741: 'consider',\n",
       " 742: 'unable',\n",
       " 743: 'catch',\n",
       " 744: 'matter',\n",
       " 745: 'sense',\n",
       " 746: 'checked',\n",
       " 747: 'hopefully',\n",
       " 748: 'attitude',\n",
       " 749: 'notify',\n",
       " 750: 'letter',\n",
       " 751: 'dividend',\n",
       " 752: 'must',\n",
       " 753: 'cold',\n",
       " 754: 'medium',\n",
       " 755: 'gt',\n",
       " 756: '35',\n",
       " 757: 'absolutely',\n",
       " 758: 'wtf',\n",
       " 759: 'small',\n",
       " 760: 'accept',\n",
       " 761: '1k',\n",
       " 762: 'luck',\n",
       " 763: 'note',\n",
       " 764: 'front',\n",
       " 765: 'tag',\n",
       " 766: 'c',\n",
       " 767: 'multiple',\n",
       " 768: 'state',\n",
       " 769: 'rdu',\n",
       " 770: 'compensate',\n",
       " 771: '#usairways',\n",
       " 772: 'middle',\n",
       " 773: 'feb',\n",
       " 774: 'four',\n",
       " 775: 'totally',\n",
       " 776: 'friday',\n",
       " 777: 'course',\n",
       " 778: 'save',\n",
       " 779: 'control',\n",
       " 780: 'enjoy',\n",
       " 781: 'train',\n",
       " 782: 'literally',\n",
       " 783: 'choose',\n",
       " 784: 'myself',\n",
       " 785: 'cover',\n",
       " 786: 'social',\n",
       " 787: 'true',\n",
       " 788: 'non',\n",
       " 789: 'birthday',\n",
       " 790: 'atlanta',\n",
       " 791: 'vegas',\n",
       " 792: 'sound',\n",
       " 793: 'sort',\n",
       " 794: '3rd',\n",
       " 795: 'tix',\n",
       " 796: 'overhead',\n",
       " 797: 'wonderful',\n",
       " 798: 'baby',\n",
       " 799: 'excuse',\n",
       " 800: 'worst',\n",
       " 801: 'earlier',\n",
       " 802: 'worth',\n",
       " 803: 'unfortunately',\n",
       " 804: 'meal',\n",
       " 805: 'atl',\n",
       " 806: 'hasnt',\n",
       " 807: 'hello',\n",
       " 808: 'haha',\n",
       " 809: 'program',\n",
       " 810: 'apply',\n",
       " 811: 'news',\n",
       " 812: 'page',\n",
       " 813: 'step',\n",
       " 814: 'saturday',\n",
       " 815: 'folk',\n",
       " 816: 'include',\n",
       " 817: 'luv',\n",
       " 818: 'itinerary',\n",
       " 819: 'gold',\n",
       " 820: 'round',\n",
       " 821: 'pull',\n",
       " 822: 'excellent',\n",
       " 823: 'man',\n",
       " 824: 'son',\n",
       " 825: 'mistake',\n",
       " 826: 'winter',\n",
       " 827: 'overnight',\n",
       " 828: 'blame',\n",
       " 829: '#neveragain',\n",
       " 830: 'relation',\n",
       " 831: 'warm',\n",
       " 832: 'select',\n",
       " 833: 'plz',\n",
       " 834: 'mobile',\n",
       " 835: 'nonstop',\n",
       " 836: 'hire',\n",
       " 837: 'assist',\n",
       " 838: 'area',\n",
       " 839: 'fun',\n",
       " 840: 'window',\n",
       " 841: 'story',\n",
       " 842: 'mileage',\n",
       " 843: 'wo',\n",
       " 844: 'airplane',\n",
       " 845: 'office',\n",
       " 846: 'explanation',\n",
       " 847: 'virgin',\n",
       " 848: 'anyway',\n",
       " 849: 'meet',\n",
       " 850: '#disappointed',\n",
       " 851: 'stuff',\n",
       " 852: '#americanairlines',\n",
       " 853: 'ny',\n",
       " 854: 'las',\n",
       " 855: 'order',\n",
       " 856: 'broken',\n",
       " 857: 'receipt',\n",
       " 858: 'meeting',\n",
       " 859: 'fast',\n",
       " 860: 'short',\n",
       " 861: '#united',\n",
       " 862: 'anymore',\n",
       " 863: 'bother',\n",
       " 864: 'mine',\n",
       " 865: 'cheap',\n",
       " 866: 'sent',\n",
       " 867: 'nope',\n",
       " 868: 'feedback',\n",
       " 869: 'serve',\n",
       " 870: 'failure',\n",
       " 871: 'cut',\n",
       " 872: '90',\n",
       " 873: 'funeral',\n",
       " 874: 'volume',\n",
       " 875: 'fl',\n",
       " 876: 'mia',\n",
       " 877: 'enter',\n",
       " 878: 'mind',\n",
       " 879: 'lady',\n",
       " 880: 'damage',\n",
       " 881: 'afternoon',\n",
       " 882: 'bit',\n",
       " 883: 'march',\n",
       " 884: 'behind',\n",
       " 885: 'slow',\n",
       " 886: 'announce',\n",
       " 887: 'svc',\n",
       " 888: 'accommodate',\n",
       " 889: 'others',\n",
       " 890: 'regard',\n",
       " 891: 'domestic',\n",
       " 892: 'saw',\n",
       " 893: 'anywhere',\n",
       " 894: 'attempt',\n",
       " 895: 'honor',\n",
       " 896: 'kudos',\n",
       " 897: 'phoenix',\n",
       " 898: 'ice',\n",
       " 899: 'n',\n",
       " 900: 'however',\n",
       " 901: '1hr',\n",
       " 902: 'dollar',\n",
       " 903: 'fan',\n",
       " 904: 'clean',\n",
       " 905: 'reward',\n",
       " 906: 'entertainment',\n",
       " 907: 'heard',\n",
       " 908: 'view',\n",
       " 909: 'ride',\n",
       " 910: 'code',\n",
       " 911: 'video',\n",
       " 912: 'web',\n",
       " 913: 'landing',\n",
       " 914: 'mention',\n",
       " 915: 'center',\n",
       " 916: 'frequent',\n",
       " 917: 'low',\n",
       " 918: 'total',\n",
       " 919: 'touch',\n",
       " 920: 'unhelpful',\n",
       " 921: 'listen',\n",
       " 922: 'tire',\n",
       " 923: 'stuck',\n",
       " 924: 'clear',\n",
       " 925: 'single',\n",
       " 926: 'deny',\n",
       " 927: '#usairwaysfail',\n",
       " 928: 'none',\n",
       " 929: 'acceptable',\n",
       " 930: 'dragon',\n",
       " 931: 'automated',\n",
       " 932: 'sat',\n",
       " 933: 'text',\n",
       " 934: 'representative',\n",
       " 935: 'absolute',\n",
       " 936: 'track',\n",
       " 937: 'special',\n",
       " 938: 'passbook',\n",
       " 939: 'rate',\n",
       " 940: 'deserve',\n",
       " 941: 'uk',\n",
       " 942: 'werent',\n",
       " 943: 'intl',\n",
       " 944: 'finger',\n",
       " 945: 'flightd',\n",
       " 946: 'frustrated',\n",
       " 947: 'advisory',\n",
       " 948: 'captain',\n",
       " 949: '2hrs',\n",
       " 950: 'power',\n",
       " 951: 'merger',\n",
       " 952: 'missed',\n",
       " 953: 'surprise',\n",
       " 954: 'locate',\n",
       " 955: 'safe',\n",
       " 956: 'tmrw',\n",
       " 957: 'americanair',\n",
       " 958: 'definitely',\n",
       " 959: 'reimburse',\n",
       " 960: 'suitcase',\n",
       " 961: 'bank',\n",
       " 962: '#avgeek',\n",
       " 963: 'nightmare',\n",
       " 964: 'premier',\n",
       " 965: 'wed',\n",
       " 966: 'final',\n",
       " 967: 'takeoff',\n",
       " 968: 'fair',\n",
       " 969: 'earn',\n",
       " 970: 'fit',\n",
       " 971: '#badservice',\n",
       " 972: 'hell',\n",
       " 973: 'deplane',\n",
       " 974: 'realize',\n",
       " 975: 'sky',\n",
       " 976: 'push',\n",
       " 977: 'snack',\n",
       " 978: 'fantastic',\n",
       " 979: 'street',\n",
       " 980: 'play',\n",
       " 981: 'match',\n",
       " 982: 'current',\n",
       " 983: 'seattle',\n",
       " 984: 'btw',\n",
       " 985: 'useless',\n",
       " 986: 'advise',\n",
       " 987: 'kill',\n",
       " 988: 'funny',\n",
       " 989: '#travel',\n",
       " 990: 'partner',\n",
       " 991: 'favorite',\n",
       " 992: 'philadelphia',\n",
       " 993: 'security',\n",
       " 994: 'equipment',\n",
       " 995: 'youll',\n",
       " 996: 'onto',\n",
       " 997: 'walk',\n",
       " 998: 'major',\n",
       " 999: 'damn',\n",
       " 1000: 'sick',\n",
       " ...}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can lookup indices and words here, they are sorted by frequency\n",
    "\n",
    "tok.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet texts vary in length (no of words). trainloader requires that all data have same shape\n",
    "# so, padding with zeros, until all tweets get length of longest tweet\n",
    "\n",
    "texts_tokenized_torch = nn.utils.rnn.pad_sequence(texts_tokenized_torch, batch_first=True, \n",
    "                                                  padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58,  82,   0,  ...,   0,   0,   0],\n",
       "        [  4, 189,  99,  ...,   0,   0,   0],\n",
       "        [ 65, 131,   1,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 74, 429, 403,  ...,   0,   0,   0],\n",
       "        [  7,  12,  11,  ...,   0,   0,   0],\n",
       "        [ 31,  12, 413,  ...,   5,   0,   0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_tokenized_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts_tokenized_torch, labels_filtered, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making data loaders\n",
    "# batch size of 300 - roughly 3% of dataset\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(list(zip(X_train, y_train)), batch_size=300, shuffle=False)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(list(zip(X_test, y_test)), batch_size=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU = torch.device('cuda: 0')\n",
    "CPU = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (embedding): Embedding(1600, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 128, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Neural Network\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(1600, 128, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(128, 128, num_layers=3, batch_first=True, bidirectional=True, dropout=0.2)\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 3)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # needed for packing sequences\n",
    "        # finds out how many words (non padding) each input has - discards zeros\n",
    "        seq_lens = []\n",
    "        for i in x:\n",
    "            xx = i.to(CPU).numpy()\n",
    "            where = np.where(xx!=0)[0]\n",
    "            seq_lens.append(len(where))\n",
    "            \n",
    "        x = self.embedding(x)\n",
    "        # packing padded sequences to ensure LSTM skips zeros\n",
    "        # also, packing speeds training up\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, lengths=seq_lens, batch_first=True, enforce_sorted=False)\n",
    "        # keeping only last hidden state\n",
    "        _, x = self.lstm(x)\n",
    "        # keeping results from last of 3 lstm layers\n",
    "        # since it is bidirectional, keeping both outputs\n",
    "        # stacking them together, to have 256 dimensions in final lstm output\n",
    "        x = x[0][0:2]\n",
    "        x = torch.cat((x[0],x[1]), dim = 1)\n",
    "        # fc layers\n",
    "        x = F.leaky_relu(self.dropout(self.fc1(x)), 0.2)\n",
    "        x = F.leaky_relu(self.dropout(self.fc2(x)), 0.2)\n",
    "        x = F.log_softmax(self.fc3(x),1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "model = NN()\n",
    "\n",
    "model.to(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3563, 0.8022, 0.8415], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportions of class instances - to be used as weights in training\n",
    "\n",
    "class_weights = 1 - data['airline_sentiment'].value_counts()/len(data)\n",
    "\n",
    "class_weights = torch.Tensor(class_weights.values).to(GPU)\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss(weight=class_weights)\n",
    "\n",
    "# adding some L2 regularization to prevent overfitting \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training loop with early stopping if test loss does not improve after given no of epochs\n",
    "\n",
    "def train_neural_network(model, trainloader, testloader, epochs, earlystopping_epochs):\n",
    "\n",
    "    import time\n",
    "\n",
    "    time1 = time.time()\n",
    "    # this is where test losses are saved, to keep track of them and perform early stopping\n",
    "    all_test_losses = []\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # lists to store accuracy and loss in each training step in single epoch\n",
    "        train_loss = []\n",
    "        train_accuracy = []\n",
    "\n",
    "        # steps in each epoch\n",
    "        for inputs, labels in trainloader:\n",
    "            \n",
    "            # NN training\n",
    "            time2 = time.time()\n",
    "            inputs, labels = inputs.to(GPU), labels.to(GPU)\n",
    "            optimizer.zero_grad()   \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # saving train loss of each step\n",
    "            train_loss.append(float(loss))\n",
    "            \n",
    "            # calculating train accuracy in each step\n",
    "            preds = outputs.detach().to(CPU).numpy()\n",
    "            # converting model outputs to class labels (integers)\n",
    "            preds_class = []\n",
    "            for i in preds:\n",
    "                where = np.where(i==i.max())[0][0]\n",
    "                preds_class.append(where)\n",
    "            labels = labels.to(CPU).numpy()\n",
    "            preds_class = np.array(preds_class)\n",
    "            equals = preds_class == labels\n",
    "            # saving train_accuracy of each step\n",
    "            train_accuracy.append(np.mean(equals))\n",
    "\n",
    "\n",
    "        \n",
    "        # computing train accuracy and loss\n",
    "        with torch.no_grad():\n",
    "            test_loss = [] \n",
    "            test_accuracy = []\n",
    "            \n",
    "            for inputs, labels in testloader:\n",
    "                inputs = inputs.to(GPU)\n",
    "                labels = labels.to(GPU)   \n",
    "\n",
    "\n",
    "                # predictions, and test loss\n",
    "                preds = model.forward(inputs)\n",
    "                loss = float(criterion(preds, labels))\n",
    "                test_loss.append(loss)\n",
    "            \n",
    "                # making label array out of predictions\n",
    "                # and computing test accuracy for each step\n",
    "                preds = preds.to(CPU).numpy()\n",
    "                preds_class = []\n",
    "                for i in preds:\n",
    "                    where = np.where(i==i.max())[0][0]\n",
    "                    preds_class.append(where)\n",
    "                labels = labels.to(CPU).numpy()         \n",
    "                equals = preds_class == labels\n",
    "                test_accuracy.append(np.mean(equals))\n",
    "            \n",
    "            # saving testing loss of each epoch\n",
    "            all_test_losses.append(np.mean(test_loss))\n",
    "                \n",
    "            # minimum test loss\n",
    "            min_test_loss = min(all_test_losses)\n",
    "            # keeping weights after current epochs if its test loss is new minimum\n",
    "            if len(all_test_losses)>1:\n",
    "                prev_min_test_loss = min(all_test_losses[:-1])\n",
    "                if min_test_loss < prev_min_test_loss:\n",
    "                    weights = model.state_dict()\n",
    "                    \n",
    "            # index of minimum test loss - actually index of epoch in which that loss is achieved\n",
    "            min_test_loss_idx = all_test_losses.index(min_test_loss)\n",
    "                \n",
    "        \n",
    "        # early stopping - if min test loss has not decreased for given number of epochs\n",
    "        # stop training\n",
    "        # and load weights from best epoch\n",
    "        if (len(all_test_losses)-1) - min_test_loss_idx > earlystopping_epochs:       \n",
    "            print(f'Epoch {epoch+1}/{epochs}.. '\n",
    "                          f'Train loss: {np.round(np.mean(train_loss),4)}.. '\n",
    "                          f'Test loss: {np.round(np.mean(test_loss),4)}.. '\n",
    "                          f'Train accuracy: {np.round(np.mean(train_accuracy),3)}.. '\n",
    "                          f'Test accuracy: {np.round(np.mean(test_accuracy),3)}.. '\n",
    "                          f'Epoch time: {np.round(time.time()-time2,2)}'\n",
    "                          f'\\n\\n Early stopping after {epoch+1} epochs. '\n",
    "                          f'Weights from epoch {min_test_loss_idx+1} set to model.')\n",
    "            \n",
    "            model.load_state_dict(weights)\n",
    "            \n",
    "            break\n",
    "            \n",
    "\n",
    "\n",
    "       # printing stats of each epoch\n",
    "        print(f'Epoch {epoch+1}/{epochs}.. '\n",
    "                      f'Train loss: {np.round(np.mean(train_loss),4)}.. '\n",
    "                      f'Test loss: {np.round(np.mean(test_loss),4)}.. '\n",
    "                      f'Train accuracy: {np.round(np.mean(train_accuracy),3)}.. '\n",
    "                      f'Test accuracy: {np.round(np.mean(test_accuracy),3)}.. '\n",
    "                      f'Epoch time: {np.round(time.time()-time2,2)}')\n",
    "\n",
    "    # finally, printing total training time\n",
    "    print(f'\\n Total time: {np.round(time.time()-time1,1)} seconds '\n",
    "          f'({np.round((time.time()-time1)/60,2)} minutes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500.. Train loss: 1.0776.. Test loss: 1.0579.. Train accuracy: 0.638.. Test accuracy: 0.653.. Epoch time: 0.23\n",
      "Epoch 2/500.. Train loss: 1.0317.. Test loss: 1.0101.. Train accuracy: 0.656.. Test accuracy: 0.681.. Epoch time: 0.23\n",
      "Epoch 3/500.. Train loss: 0.9786.. Test loss: 0.9396.. Train accuracy: 0.685.. Test accuracy: 0.684.. Epoch time: 0.23\n",
      "Epoch 4/500.. Train loss: 0.9116.. Test loss: 0.9119.. Train accuracy: 0.695.. Test accuracy: 0.688.. Epoch time: 0.23\n",
      "Epoch 5/500.. Train loss: 0.8852.. Test loss: 0.9002.. Train accuracy: 0.701.. Test accuracy: 0.697.. Epoch time: 0.23\n",
      "Epoch 6/500.. Train loss: 0.8559.. Test loss: 0.8704.. Train accuracy: 0.711.. Test accuracy: 0.7.. Epoch time: 0.23\n",
      "Epoch 7/500.. Train loss: 0.8164.. Test loss: 0.8308.. Train accuracy: 0.716.. Test accuracy: 0.711.. Epoch time: 0.23\n",
      "Epoch 8/500.. Train loss: 0.7769.. Test loss: 0.8002.. Train accuracy: 0.725.. Test accuracy: 0.712.. Epoch time: 0.23\n",
      "Epoch 9/500.. Train loss: 0.754.. Test loss: 0.7921.. Train accuracy: 0.734.. Test accuracy: 0.715.. Epoch time: 0.23\n",
      "Epoch 10/500.. Train loss: 0.7407.. Test loss: 0.7809.. Train accuracy: 0.737.. Test accuracy: 0.732.. Epoch time: 0.23\n",
      "Epoch 11/500.. Train loss: 0.7294.. Test loss: 0.7676.. Train accuracy: 0.745.. Test accuracy: 0.706.. Epoch time: 0.23\n",
      "Epoch 12/500.. Train loss: 0.7198.. Test loss: 0.765.. Train accuracy: 0.745.. Test accuracy: 0.717.. Epoch time: 0.24\n",
      "Epoch 13/500.. Train loss: 0.7122.. Test loss: 0.7669.. Train accuracy: 0.75.. Test accuracy: 0.71.. Epoch time: 0.26\n",
      "Epoch 14/500.. Train loss: 0.7024.. Test loss: 0.757.. Train accuracy: 0.75.. Test accuracy: 0.712.. Epoch time: 0.24\n",
      "Epoch 15/500.. Train loss: 0.6991.. Test loss: 0.7623.. Train accuracy: 0.756.. Test accuracy: 0.714.. Epoch time: 0.25\n",
      "Epoch 16/500.. Train loss: 0.6889.. Test loss: 0.765.. Train accuracy: 0.754.. Test accuracy: 0.703.. Epoch time: 0.23\n",
      "Epoch 17/500.. Train loss: 0.6876.. Test loss: 0.7563.. Train accuracy: 0.756.. Test accuracy: 0.711.. Epoch time: 0.24\n",
      "Epoch 18/500.. Train loss: 0.6846.. Test loss: 0.7666.. Train accuracy: 0.757.. Test accuracy: 0.717.. Epoch time: 0.24\n",
      "Epoch 19/500.. Train loss: 0.6775.. Test loss: 0.759.. Train accuracy: 0.757.. Test accuracy: 0.723.. Epoch time: 0.23\n",
      "Epoch 20/500.. Train loss: 0.6689.. Test loss: 0.7569.. Train accuracy: 0.762.. Test accuracy: 0.723.. Epoch time: 0.23\n",
      "Epoch 21/500.. Train loss: 0.6656.. Test loss: 0.7524.. Train accuracy: 0.763.. Test accuracy: 0.715.. Epoch time: 0.23\n",
      "Epoch 22/500.. Train loss: 0.657.. Test loss: 0.7579.. Train accuracy: 0.763.. Test accuracy: 0.716.. Epoch time: 0.23\n",
      "Epoch 23/500.. Train loss: 0.6565.. Test loss: 0.7462.. Train accuracy: 0.767.. Test accuracy: 0.727.. Epoch time: 0.23\n",
      "Epoch 24/500.. Train loss: 0.6491.. Test loss: 0.7509.. Train accuracy: 0.767.. Test accuracy: 0.731.. Epoch time: 0.23\n",
      "Epoch 25/500.. Train loss: 0.6478.. Test loss: 0.7572.. Train accuracy: 0.769.. Test accuracy: 0.725.. Epoch time: 0.24\n",
      "Epoch 26/500.. Train loss: 0.6444.. Test loss: 0.7411.. Train accuracy: 0.773.. Test accuracy: 0.734.. Epoch time: 0.23\n",
      "Epoch 27/500.. Train loss: 0.6442.. Test loss: 0.7368.. Train accuracy: 0.77.. Test accuracy: 0.713.. Epoch time: 0.23\n",
      "Epoch 28/500.. Train loss: 0.638.. Test loss: 0.7405.. Train accuracy: 0.773.. Test accuracy: 0.716.. Epoch time: 0.23\n",
      "Epoch 29/500.. Train loss: 0.6423.. Test loss: 0.7432.. Train accuracy: 0.77.. Test accuracy: 0.707.. Epoch time: 0.23\n",
      "Epoch 30/500.. Train loss: 0.6415.. Test loss: 0.7404.. Train accuracy: 0.774.. Test accuracy: 0.708.. Epoch time: 0.23\n",
      "Epoch 31/500.. Train loss: 0.6387.. Test loss: 0.7365.. Train accuracy: 0.774.. Test accuracy: 0.704.. Epoch time: 0.23\n",
      "Epoch 32/500.. Train loss: 0.6357.. Test loss: 0.7393.. Train accuracy: 0.772.. Test accuracy: 0.709.. Epoch time: 0.23\n",
      "Epoch 33/500.. Train loss: 0.6389.. Test loss: 0.7285.. Train accuracy: 0.772.. Test accuracy: 0.71.. Epoch time: 0.23\n",
      "Epoch 34/500.. Train loss: 0.6334.. Test loss: 0.7435.. Train accuracy: 0.774.. Test accuracy: 0.704.. Epoch time: 0.23\n",
      "Epoch 35/500.. Train loss: 0.6337.. Test loss: 0.7266.. Train accuracy: 0.772.. Test accuracy: 0.709.. Epoch time: 0.23\n",
      "Epoch 36/500.. Train loss: 0.6278.. Test loss: 0.7299.. Train accuracy: 0.777.. Test accuracy: 0.723.. Epoch time: 0.23\n",
      "Epoch 37/500.. Train loss: 0.6254.. Test loss: 0.728.. Train accuracy: 0.777.. Test accuracy: 0.721.. Epoch time: 0.23\n",
      "Epoch 38/500.. Train loss: 0.6272.. Test loss: 0.7274.. Train accuracy: 0.776.. Test accuracy: 0.716.. Epoch time: 0.23\n",
      "Epoch 39/500.. Train loss: 0.6221.. Test loss: 0.7266.. Train accuracy: 0.777.. Test accuracy: 0.727.. Epoch time: 0.23\n",
      "Epoch 40/500.. Train loss: 0.621.. Test loss: 0.7278.. Train accuracy: 0.777.. Test accuracy: 0.726.. Epoch time: 0.23\n",
      "Epoch 41/500.. Train loss: 0.617.. Test loss: 0.7299.. Train accuracy: 0.776.. Test accuracy: 0.722.. Epoch time: 0.23\n",
      "Epoch 42/500.. Train loss: 0.6172.. Test loss: 0.7221.. Train accuracy: 0.778.. Test accuracy: 0.726.. Epoch time: 0.23\n",
      "Epoch 43/500.. Train loss: 0.6233.. Test loss: 0.7275.. Train accuracy: 0.776.. Test accuracy: 0.729.. Epoch time: 0.24\n",
      "Epoch 44/500.. Train loss: 0.6167.. Test loss: 0.7207.. Train accuracy: 0.778.. Test accuracy: 0.719.. Epoch time: 0.23\n",
      "Epoch 45/500.. Train loss: 0.6135.. Test loss: 0.7202.. Train accuracy: 0.78.. Test accuracy: 0.718.. Epoch time: 0.23\n",
      "Epoch 46/500.. Train loss: 0.6105.. Test loss: 0.724.. Train accuracy: 0.782.. Test accuracy: 0.725.. Epoch time: 0.24\n",
      "Epoch 47/500.. Train loss: 0.6088.. Test loss: 0.7247.. Train accuracy: 0.782.. Test accuracy: 0.719.. Epoch time: 0.24\n",
      "Epoch 48/500.. Train loss: 0.6054.. Test loss: 0.7121.. Train accuracy: 0.778.. Test accuracy: 0.717.. Epoch time: 0.23\n",
      "Epoch 49/500.. Train loss: 0.6073.. Test loss: 0.7054.. Train accuracy: 0.781.. Test accuracy: 0.714.. Epoch time: 0.23\n",
      "Epoch 50/500.. Train loss: 0.6048.. Test loss: 0.7163.. Train accuracy: 0.781.. Test accuracy: 0.724.. Epoch time: 0.24\n",
      "Epoch 51/500.. Train loss: 0.5991.. Test loss: 0.7095.. Train accuracy: 0.783.. Test accuracy: 0.73.. Epoch time: 0.23\n",
      "Epoch 52/500.. Train loss: 0.5963.. Test loss: 0.7183.. Train accuracy: 0.784.. Test accuracy: 0.727.. Epoch time: 0.23\n",
      "Epoch 53/500.. Train loss: 0.5989.. Test loss: 0.7135.. Train accuracy: 0.786.. Test accuracy: 0.718.. Epoch time: 0.23\n",
      "Epoch 54/500.. Train loss: 0.5966.. Test loss: 0.7073.. Train accuracy: 0.784.. Test accuracy: 0.733.. Epoch time: 0.23\n",
      "Epoch 55/500.. Train loss: 0.5888.. Test loss: 0.7022.. Train accuracy: 0.788.. Test accuracy: 0.73.. Epoch time: 0.23\n",
      "Epoch 56/500.. Train loss: 0.5858.. Test loss: 0.6962.. Train accuracy: 0.789.. Test accuracy: 0.728.. Epoch time: 0.23\n",
      "Epoch 57/500.. Train loss: 0.5807.. Test loss: 0.6959.. Train accuracy: 0.79.. Test accuracy: 0.732.. Epoch time: 0.23\n",
      "Epoch 58/500.. Train loss: 0.5808.. Test loss: 0.6932.. Train accuracy: 0.794.. Test accuracy: 0.729.. Epoch time: 0.23\n",
      "Epoch 59/500.. Train loss: 0.5778.. Test loss: 0.6963.. Train accuracy: 0.793.. Test accuracy: 0.735.. Epoch time: 0.23\n",
      "Epoch 60/500.. Train loss: 0.5674.. Test loss: 0.7026.. Train accuracy: 0.798.. Test accuracy: 0.724.. Epoch time: 0.24\n",
      "Epoch 61/500.. Train loss: 0.5704.. Test loss: 0.6899.. Train accuracy: 0.796.. Test accuracy: 0.732.. Epoch time: 0.23\n",
      "Epoch 62/500.. Train loss: 0.5632.. Test loss: 0.695.. Train accuracy: 0.797.. Test accuracy: 0.742.. Epoch time: 0.24\n",
      "Epoch 63/500.. Train loss: 0.5608.. Test loss: 0.6856.. Train accuracy: 0.803.. Test accuracy: 0.741.. Epoch time: 0.24\n",
      "Epoch 64/500.. Train loss: 0.5563.. Test loss: 0.6927.. Train accuracy: 0.803.. Test accuracy: 0.748.. Epoch time: 0.23\n",
      "Epoch 65/500.. Train loss: 0.5546.. Test loss: 0.6957.. Train accuracy: 0.805.. Test accuracy: 0.749.. Epoch time: 0.23\n",
      "Epoch 66/500.. Train loss: 0.5535.. Test loss: 0.6863.. Train accuracy: 0.802.. Test accuracy: 0.752.. Epoch time: 0.23\n",
      "Epoch 67/500.. Train loss: 0.5485.. Test loss: 0.7027.. Train accuracy: 0.804.. Test accuracy: 0.756.. Epoch time: 0.23\n",
      "Epoch 68/500.. Train loss: 0.5458.. Test loss: 0.6772.. Train accuracy: 0.805.. Test accuracy: 0.767.. Epoch time: 0.23\n",
      "Epoch 69/500.. Train loss: 0.5437.. Test loss: 0.6817.. Train accuracy: 0.81.. Test accuracy: 0.754.. Epoch time: 0.23\n",
      "Epoch 70/500.. Train loss: 0.5397.. Test loss: 0.6627.. Train accuracy: 0.812.. Test accuracy: 0.745.. Epoch time: 0.24\n",
      "Epoch 71/500.. Train loss: 0.5308.. Test loss: 0.6639.. Train accuracy: 0.816.. Test accuracy: 0.74.. Epoch time: 0.24\n",
      "Epoch 72/500.. Train loss: 0.5191.. Test loss: 0.6727.. Train accuracy: 0.821.. Test accuracy: 0.733.. Epoch time: 0.23\n",
      "Epoch 73/500.. Train loss: 0.5148.. Test loss: 0.6666.. Train accuracy: 0.822.. Test accuracy: 0.743.. Epoch time: 0.23\n",
      "Epoch 74/500.. Train loss: 0.5075.. Test loss: 0.6673.. Train accuracy: 0.825.. Test accuracy: 0.755.. Epoch time: 0.23\n",
      "Epoch 75/500.. Train loss: 0.5075.. Test loss: 0.6733.. Train accuracy: 0.824.. Test accuracy: 0.762.. Epoch time: 0.23\n",
      "Epoch 76/500.. Train loss: 0.5055.. Test loss: 0.6692.. Train accuracy: 0.821.. Test accuracy: 0.764.. Epoch time: 0.23\n",
      "Epoch 77/500.. Train loss: 0.5001.. Test loss: 0.6778.. Train accuracy: 0.826.. Test accuracy: 0.758.. Epoch time: 0.23\n",
      "Epoch 78/500.. Train loss: 0.5005.. Test loss: 0.6706.. Train accuracy: 0.828.. Test accuracy: 0.768.. Epoch time: 0.23\n",
      "Epoch 79/500.. Train loss: 0.4943.. Test loss: 0.6677.. Train accuracy: 0.827.. Test accuracy: 0.772.. Epoch time: 0.24\n",
      "Epoch 80/500.. Train loss: 0.4971.. Test loss: 0.6781.. Train accuracy: 0.827.. Test accuracy: 0.77.. Epoch time: 0.23\n",
      "Epoch 81/500.. Train loss: 0.4851.. Test loss: 0.6639.. Train accuracy: 0.835.. Test accuracy: 0.768.. Epoch time: 0.23\n",
      "Epoch 82/500.. Train loss: 0.4852.. Test loss: 0.6724.. Train accuracy: 0.832.. Test accuracy: 0.763.. Epoch time: 0.23\n",
      "Epoch 83/500.. Train loss: 0.4821.. Test loss: 0.6601.. Train accuracy: 0.833.. Test accuracy: 0.756.. Epoch time: 0.23\n",
      "Epoch 84/500.. Train loss: 0.4694.. Test loss: 0.6661.. Train accuracy: 0.842.. Test accuracy: 0.759.. Epoch time: 0.23\n",
      "Epoch 85/500.. Train loss: 0.4673.. Test loss: 0.6652.. Train accuracy: 0.841.. Test accuracy: 0.752.. Epoch time: 0.23\n",
      "Epoch 86/500.. Train loss: 0.4662.. Test loss: 0.6711.. Train accuracy: 0.843.. Test accuracy: 0.752.. Epoch time: 0.23\n",
      "Epoch 87/500.. Train loss: 0.4668.. Test loss: 0.6722.. Train accuracy: 0.841.. Test accuracy: 0.773.. Epoch time: 0.23\n",
      "Epoch 88/500.. Train loss: 0.4688.. Test loss: 0.6631.. Train accuracy: 0.841.. Test accuracy: 0.774.. Epoch time: 0.23\n",
      "Epoch 89/500.. Train loss: 0.4672.. Test loss: 0.6465.. Train accuracy: 0.843.. Test accuracy: 0.766.. Epoch time: 0.23\n",
      "Epoch 90/500.. Train loss: 0.4595.. Test loss: 0.6954.. Train accuracy: 0.844.. Test accuracy: 0.778.. Epoch time: 0.23\n",
      "Epoch 91/500.. Train loss: 0.4585.. Test loss: 0.6808.. Train accuracy: 0.847.. Test accuracy: 0.773.. Epoch time: 0.23\n",
      "Epoch 92/500.. Train loss: 0.4755.. Test loss: 0.6522.. Train accuracy: 0.838.. Test accuracy: 0.764.. Epoch time: 0.23\n",
      "Epoch 93/500.. Train loss: 0.4629.. Test loss: 0.689.. Train accuracy: 0.841.. Test accuracy: 0.788.. Epoch time: 0.23\n",
      "Epoch 94/500.. Train loss: 0.4615.. Test loss: 0.6503.. Train accuracy: 0.844.. Test accuracy: 0.781.. Epoch time: 0.23\n",
      "Epoch 95/500.. Train loss: 0.45.. Test loss: 0.6697.. Train accuracy: 0.846.. Test accuracy: 0.763.. Epoch time: 0.23\n",
      "Epoch 96/500.. Train loss: 0.4497.. Test loss: 0.6656.. Train accuracy: 0.851.. Test accuracy: 0.777.. Epoch time: 0.23\n",
      "Epoch 97/500.. Train loss: 0.4557.. Test loss: 0.666.. Train accuracy: 0.847.. Test accuracy: 0.773.. Epoch time: 0.23\n",
      "Epoch 98/500.. Train loss: 0.447.. Test loss: 0.6792.. Train accuracy: 0.849.. Test accuracy: 0.771.. Epoch time: 0.23\n",
      "Epoch 99/500.. Train loss: 0.4413.. Test loss: 0.6975.. Train accuracy: 0.849.. Test accuracy: 0.777.. Epoch time: 0.23\n",
      "Epoch 100/500.. Train loss: 0.4462.. Test loss: 0.6625.. Train accuracy: 0.848.. Test accuracy: 0.779.. Epoch time: 0.23\n",
      "Epoch 101/500.. Train loss: 0.4473.. Test loss: 0.6803.. Train accuracy: 0.85.. Test accuracy: 0.771.. Epoch time: 0.23\n",
      "Epoch 102/500.. Train loss: 0.436.. Test loss: 0.6776.. Train accuracy: 0.853.. Test accuracy: 0.776.. Epoch time: 0.23\n",
      "Epoch 103/500.. Train loss: 0.4433.. Test loss: 0.6679.. Train accuracy: 0.854.. Test accuracy: 0.76.. Epoch time: 0.23\n",
      "Epoch 104/500.. Train loss: 0.4423.. Test loss: 0.6802.. Train accuracy: 0.851.. Test accuracy: 0.777.. Epoch time: 0.23\n",
      "Epoch 105/500.. Train loss: 0.4351.. Test loss: 0.6875.. Train accuracy: 0.851.. Test accuracy: 0.778.. Epoch time: 0.24\n",
      "\n",
      " Early stopping after 105 epochs. Weights from epoch 89 set to model.\n",
      "\n",
      " Total time: 180.9 seconds (3.01 minutes)\n"
     ]
    }
   ],
   "source": [
    "# early stopping set to 10 epochs\n",
    "\n",
    "train_neural_network(model=model, trainloader=trainloader, testloader=testloader,\n",
    "                    epochs=500, earlystopping_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10757,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating scores\n",
    "\n",
    "# train predictions\n",
    "\n",
    "preds_train = []\n",
    "out_train = model.forward(torch.tensor(X_train).to(GPU)).to(CPU).detach().numpy()\n",
    "\n",
    "for i in out_train:\n",
    "    where = np.where(i == i.max())[0][0]\n",
    "    preds_train.append(where)\n",
    "\n",
    "preds_train = np.array(preds_train)\n",
    "preds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/anaconda/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2690,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test predictions \n",
    "\n",
    "preds_test = []\n",
    "out_test = model.forward(torch.tensor(X_test).to(GPU)).to(CPU).detach().numpy()\n",
    "\n",
    "for i in out_test:\n",
    "    where = np.where(i == i.max())[0][0]\n",
    "    preds_test.append(where)\n",
    "\n",
    "preds_test = np.array(preds_test)\n",
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.8748721762573208\n",
      "test accuracy:  0.774721189591078\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy: ', accuracy_score(y_train, preds_train))\n",
    "print('test accuracy: ', accuracy_score(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train cm\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_train, preds_train), annot=True, fmt='g',\n",
    "            annot_kws={'size':20}, cmap='Blues')\n",
    "plt.xlabel('PREDICTED')\n",
    "plt.ylabel('TRUE')\n",
    "plt.xticks([0.5,1.5,2.5],\n",
    "           ['negative', 'neutral', 'positive'],\n",
    "          rotation = 90)\n",
    "plt.yticks([0.5,1.5,2.5],\n",
    "           ['negative', 'neutral', 'positive'],\n",
    "          rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.889951</td>\n",
       "      <td>0.921587</td>\n",
       "      <td>7006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.676703</td>\n",
       "      <td>0.860287</td>\n",
       "      <td>0.757531</td>\n",
       "      <td>2090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.874921</td>\n",
       "      <td>0.829621</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>1661.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision    recall        f1  support\n",
       "negative   0.955556  0.889951  0.921587   7006.0\n",
       "neutral    0.676703  0.860287  0.757531   2090.0\n",
       "positive   0.874921  0.829621  0.851669   1661.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train scores\n",
    "\n",
    "scores = prf(y_train, preds_train)\n",
    "\n",
    "df = pd.DataFrame(np.empty((3,4)), columns=['precision','recall','f1','support'])\n",
    "for i in range(0,len(scores[0])):\n",
    "    df.iloc[i,:] = [x[i] for x in scores]\n",
    "df.index = ['negative', 'neutral', 'positive']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test cm\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, preds_test), annot=True, fmt='g', \n",
    "            annot_kws={'size':20}, cmap = 'Blues')\n",
    "plt.xlabel('PREDICTED')\n",
    "plt.ylabel('TRUE')\n",
    "plt.xticks([0.5,1.5,2.5],\n",
    "           ['negative', 'neutral', 'positive'],\n",
    "          rotation = 90)\n",
    "plt.yticks([0.5,1.5,2.5],\n",
    "           ['negative', 'neutral', 'positive'],\n",
    "          rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.883777</td>\n",
       "      <td>0.830489</td>\n",
       "      <td>0.856305</td>\n",
       "      <td>1758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.529052</td>\n",
       "      <td>0.678431</td>\n",
       "      <td>0.594502</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.723958</td>\n",
       "      <td>0.658768</td>\n",
       "      <td>0.689826</td>\n",
       "      <td>422.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision    recall        f1  support\n",
       "negative   0.883777  0.830489  0.856305   1758.0\n",
       "neutral    0.529052  0.678431  0.594502    510.0\n",
       "positive   0.723958  0.658768  0.689826    422.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test scores\n",
    "\n",
    "scores = prf(y_test, preds_test)\n",
    "\n",
    "df = pd.DataFrame(np.empty((3,4)), columns=['precision','recall','f1','support'])\n",
    "for i in range(0,len(scores[0])):\n",
    "    df.iloc[i,:] = [x[i] for x in scores]\n",
    "df.index = ['negative', 'neutral', 'positive']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "\n",
    "torch.save(model.state_dict(), \n",
    "           '/home/ksaver/Desktop/faks/deep learning/projekt/tweets_model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on scores\n",
    "\n",
    "Model does overfit even though both dropout and regularization have been added. However, greater regularization and dropout would lead to model underfitting greatly.\n",
    "\n",
    "In terms of accuracy score, model has mostly similar scores as other models available on Kaggle. Best of them reach 80% accuracy on validation data. However, this model beats them in terms of F1 score. This means it does better at classifying underrepresented classes (neutral and positive reviews) correctly.\n",
    "\n",
    "# Trying out some of the actual tweets and seeing how they perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tweet:  @united UA1023 sitting on Tarmac at ORD when there are visibly gates open. Reassign our gate. \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united Apart from being on hold for over 2 hours and having talked to 5 people and the problem still not resolved! \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united I havent booked yet, Im asking before I book \n",
      " true sentiment:  neutral \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united are there any upgrades avail to get us all on the same flight \n",
      " true sentiment:  neutral \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united just called and did it. Should have earlier because Im being sent to DCA first and THEN to pvd. We may rent a car instead. \n",
      " true sentiment:  neutral \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united Well, to the degree that he could... Just to know, after this experience Im Cancelled Flighting my miles card. Thank god for @Delta \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united arrived in YYZ to take our flight to Taiwan. Reservation missing our ticket numbers. Slow agent Sukhdeep caused us to miss our flt. \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united Will never fly with you again! Terrible service!! Ruined our entire vacation!! #lostsuitcase #noreimbursement \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @lindaSWC @united: We dont like to hear you had a poor experience. Please share details w/our Customer Care team http://t.co/HIsc4NdMgZ. \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @VirginAmerica had me at their safety video . . . http://t.co/CqMm7nuE9m LOVED my first cross country flight. #livewelltraveled #sytycd \n",
      " true sentiment:  positive \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united It is also inappropriate to lie to passengers to induce them into accepting a voucher by telling them you have availability on Late Flightr \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united please be good to me this weekend! \n",
      " true sentiment:  neutral \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united Thats correctâ€”Ive spent hours trying to book online only to receive an error when clicking final purchase button. (1/2) \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united I took care of it myself. Had to rent a car and drive 3 hours to retrieve my belongings. Due to united errors. \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united why are your agents working so slowly to rebook people who are on #UA1481. We have all wasted an entire day at STT. \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @VirginAmerica On all your flights? \n",
      " true sentiment:  neutral \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united by the time I finally get to Dallas I could have driven with less frustration and cheaper. \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united, you just caused a riot on the airplane. Never seen anything like this \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @VirginAmerica Cant bring up my reservation online using Flight Booking Problems code \n",
      " true sentiment:  neutral \t predicted sentiment:  negative \n",
      "\n",
      "\n",
      "Original tweet:  @united iah to charlotte. Baggage claim rep latrice h. #customerservice non existent, Ignored customer then inappropriately touched customer \n",
      " true sentiment:  negative \t predicted sentiment:  negative \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand = np.random.randint(0,len(tweets), 20)\n",
    "\n",
    "label_dict = {0: 'negative',\n",
    "              1: 'neutral',\n",
    "              2: 'positive'}\n",
    "\n",
    "for i in rand:\n",
    "    \n",
    "    tweet = texts[filter_short][i]\n",
    "    \n",
    "    tweet_processed = texts_tokenized_torch[i]\n",
    "    \n",
    "    label = labels_filtered[i]\n",
    "    \n",
    "    pred = model(tweet_processed.reshape(1,31).to(GPU))\n",
    "    \n",
    "    pred = pred.detach().to(CPU).numpy()\n",
    "    \n",
    "    pred = np.where(pred == pred.max())[0][0]\n",
    "    \n",
    "    \n",
    "    print('Original tweet: ', tweet, '\\n true sentiment: ', label_dict[label],\n",
    "          '\\t predicted sentiment: ', label_dict[pred], '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
